{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TabPFN Relational Benchmark**\n",
    "This notebook benchmarks the performance of TabPFN models on datasets from RelBench in two scenarios:\n",
    "1. **Single Table** – Using only the target entity table.\n",
    "2. **Merged Table** – Using a naively denormalized table obtained by joining related tables.\n",
    "\n",
    "It automates dataset loading, preprocessing (including date feature engineering), vectorization, model training, prediction, and evaluation for all compatible tasks within a chosen RelBench dataset. The results allow comparing model performance between single-table and merged-table configurations.\n"
   ],
   "id": "7ab5a9bf5466de0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "ac93e97c56d4b905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.117330Z",
     "start_time": "2025-08-16T10:52:07.468367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- PyTorch and PyTorch Geometric ---\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "# --- Skrub and Sentence Transformers ---\n",
    "from skrub import TableVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- RelBench ---\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task, get_task_names\n",
    "from relbench.base import TaskType\n",
    "import relbench.metrics\n",
    "from relbench.modeling.utils import get_stype_proposal\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "\n",
    "# --- TabPFN ---\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n"
   ],
   "id": "57624fe02c838842",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set Global Configuration",
   "id": "7154198e21fe2a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.292051Z",
     "start_time": "2025-08-16T10:52:11.290048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device preference\n",
    "#if torch.backends.mps.is_available():\n",
    "#    DEVICE = \"mps\"\n",
    "#elif torch.cuda.is_available():\n",
    "#    DEVICE = \"cuda\"\n",
    "#else:\n",
    "#    DEVICE = \"cpu\"\n",
    "\n",
    "DEVICE = \"cpu\" # Force CPU for compatibility with all environments\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define global dataset variable (any available dataset from relbench.datasets)\n",
    "# \"rel-f1\" is the default, but can be overridden by setting DATASET variable\n",
    "DATASET = \"rel-f1\"\n",
    "\n",
    "# Global configuration variables with defaults\n",
    "SEED   = globals().get(\"SEED\", 42)\n",
    "N_ESTIMATORS = globals().get(\"N_ESTIMATORS\", 16) # number of TabPFN estimators\n",
    "TABPFN_MAX = globals().get(\"TABPFN_MAX\", 10000)  # hard ceiling for TabPFN"
   ],
   "id": "c5959e09ecd4c20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook Configuration and Dataset Selection\n",
    "\n",
    "\n",
    "Sets the dataset name (`DATASET`) and download flag (`DOWNLOAD`), then discovers all available tasks for the selected dataset using RelBench’s APIs. Filters tasks to only those compatible with TabPFN (classification and regression).\n"
   ],
   "id": "a86eaa89573fdf63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.304381Z",
     "start_time": "2025-08-16T10:52:11.299661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reuse existing config if present, otherwise set defaults\n",
    "DATASET = globals().get(\"DATASET\", \"rel-f1\")\n",
    "DOWNLOAD = globals().get(\"DOWNLOAD\", True)\n",
    "\n",
    "# Discover tasks and keep only entity-level cls/reg tasks TabPFN can handle\n",
    "def _is_tabpfn_friendly(task):\n",
    "    return task.task_type in (\n",
    "        TaskType.BINARY_CLASSIFICATION,\n",
    "        TaskType.MULTICLASS_CLASSIFICATION,\n",
    "        TaskType.MULTILABEL_CLASSIFICATION,\n",
    "        TaskType.REGRESSION,\n",
    "    )\n",
    "\n",
    "_all = get_task_names(DATASET)  # shown in tutorials\n",
    "TASKS = []\n",
    "for tname in _all:\n",
    "    try:\n",
    "        t = get_task(DATASET, tname, download=DOWNLOAD)\n",
    "        if _is_tabpfn_friendly(t):\n",
    "            TASKS.append(tname)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {tname}: {e!s}\")\n",
    "\n",
    "print(f\"{DATASET}: {len(TASKS)} TabPFN-friendly tasks -> {TASKS}\")\n"
   ],
   "id": "d94075cf88bf6806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel-f1: 3 TabPFN-friendly tasks -> ['driver-position', 'driver-dnf', 'driver-top3']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Patch RelBench Metrics (Optional)",
   "id": "affc15acb6a0f8aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.311891Z",
     "start_time": "2025-08-16T10:52:11.310239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text Embedding Configuration",
   "id": "5629815fd3214b7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.319197Z",
     "start_time": "2025-08-16T10:52:11.317448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a text embedding class using GloVe embeddings from Sentence Transformers.\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))"
   ],
   "id": "78e9b5ef45024fb3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions for Dataset Loading and Table Processing\n",
   "id": "2d748a1a5dea1d28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Date Feature Engineering and Optional Graph Build\n",
    "\n",
    "Processes all tables in the dataset to detect and parse date columns, replacing missing values and generating engineered date-related features (e.g., year, month, weekday, cyclical encodings).\n",
    "Also includes a step to construct a hetero-temporal graph for GNN experiments using text embeddings.\n"
   ],
   "id": "76f494f170e324f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:11.380417Z",
     "start_time": "2025-08-16T10:52:11.324427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset and its database\n",
    "dataset = get_dataset(DATASET)\n",
    "db = dataset.get_db()\n",
    "\n",
    "# Helper function to convert any table-like object to a pandas DataFrame\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Convert all tables to pandas DataFrames\n",
    "tables = {name: to_pandas(tbl) for name, tbl in db.table_dict.items()}\n",
    "\n",
    "# Date feature engineering\n",
    "# This will modify the tables in-place, adding new date-related features.\n",
    "for name, df in tables.items():\n",
    "    # Drop duplicate columns and force a copy\n",
    "    df = df.loc[:, ~df.columns.duplicated()].copy()\n",
    "    date_cols = [col for col in df.columns if \"date\" in col.lower()]\n",
    "    if not date_cols:\n",
    "        tables[name] = df\n",
    "        continue\n",
    "\n",
    "    # Compute cleaned dates and all features in memory\n",
    "    dt_clean = {}\n",
    "    feats = {}\n",
    "    for col in date_cols:\n",
    "        dt = pd.to_datetime(df[col], errors=\"coerce\", utc=True)\n",
    "        dt_filled = dt.fillna(dt.min())\n",
    "        dt_clean[col] = dt_filled.dt.tz_localize(None)\n",
    "        feats.update({\n",
    "            f\"{col}_year\":            dt_filled.dt.year,\n",
    "            f\"{col}_month\":           dt_filled.dt.month,\n",
    "            f\"{col}_day\":             dt_filled.dt.day,\n",
    "            f\"{col}_weekday\":         dt_filled.dt.weekday,\n",
    "            f\"{col}_quarter\":         dt_filled.dt.quarter,\n",
    "            f\"{col}_is_month_start\":  dt_filled.dt.is_month_start.astype(int),\n",
    "            f\"{col}_is_month_end\":    dt_filled.dt.is_month_end.astype(int),\n",
    "            f\"{col}_is_weekend\":      (dt_filled.dt.weekday >= 5).astype(int),\n",
    "            f\"{col}_month_sin\":       np.sin(2 * np.pi * dt_filled.dt.month / 12),\n",
    "            f\"{col}_month_cos\":       np.cos(2 * np.pi * dt_filled.dt.month / 12),\n",
    "            f\"{col}_weekday_sin\":     np.sin(2 * np.pi * dt_filled.dt.weekday / 7),\n",
    "            f\"{col}_weekday_cos\":     np.cos(2 * np.pi * dt_filled.dt.weekday / 7),\n",
    "            f\"{col}_elapsed_days\":    (dt_filled - dt_filled.min()).dt.days,\n",
    "        })\n",
    "\n",
    "    # Drop original date columns and concatenate new ones in a single op\n",
    "    df = df.drop(columns=date_cols)\n",
    "    new_cols_df = pd.DataFrame({**dt_clean, **feats}, index=df.index)\n",
    "    df = pd.concat([df, new_cols_df], axis=1)\n",
    "\n",
    "    tables[name] = df\n",
    "\n",
    "# Update the database with modified DataFrames\n",
    "for name, df in tables.items():\n",
    "    db.table_dict[name].df = df\n",
    "\n",
    "# Patch infer_series_stype to handle \"truth value of a Series is ambiguous\" errors\n",
    "import torch_frame.utils.infer_stype as ts\n",
    "_orig_infer = ts.infer_series_stype\n",
    "def infer_series_stype_safe(ser):\n",
    "    try:\n",
    "        return _orig_infer(ser)\n",
    "    except ValueError as e:\n",
    "        if \"truth value of a Series\" in str(e):\n",
    "            return _orig_infer(ser.dropna())\n",
    "        else:\n",
    "            raise\n",
    "ts.infer_series_stype = infer_series_stype_safe"
   ],
   "id": "d37c8ff4b032ae52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /Users/michaelflppv/Library/Caches/relbench/rel-f1/db...\n",
      "Done in 0.01 seconds.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:17.526865Z",
     "start_time": "2025-08-16T10:52:11.403953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a hetero-temporal graph for experiments\n",
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=torch.device(DEVICE)), batch_size=256\n",
    ")\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=text_embedder_cfg,\n",
    "    cache_dir=None,\n",
    ")"
   ],
   "id": "b97398387d79f5ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 854.72it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 757.44it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 860.06it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 830.35it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 859.27it/s]\n",
      "/Users/michaelflppv/PycharmProjects/TabPFN/.venv1/lib/python3.10/site-packages/torch_frame/data/stats.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ser = pd.to_datetime(ser, format=time_format)\n",
      "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 556.81it/s]\n",
      "/Users/michaelflppv/PycharmProjects/TabPFN/.venv1/lib/python3.10/site-packages/torch_frame/data/mapper.py:291: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ser = pd.to_datetime(ser, format=self.format, errors='coerce')\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 547.34it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 539.74it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 561.79it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1007.04it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 721.04it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 775.86it/s]\n",
      "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 598.50it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fetch Dataset Splits\n",
    "\n",
    "Utility functions to load a task’s splits (`train`, `val`, `test`), convert them to pandas DataFrames, and extract features (`X`) and targets (`y`). Includes functions to build:\n",
    "- **Single-table frames** directly from the target entity table.\n",
    "- **Merged-table frames** by performing a one-hop foreign key → primary key join to denormalize data.\n"
   ],
   "id": "1a35d633effdd263"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:17.545296Z",
     "start_time": "2025-08-16T10:52:17.540444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetches the task and its splits from the dataset, returning a task object and a dictionary of DataFrames for each split.\n",
    "def fetch_splits(dataset_name: str, task_name: str, download: bool = True):\n",
    "    task = get_task(dataset_name, task_name, download=download)\n",
    "    # keep original columns (tutorial shows mask_input_cols flag)\n",
    "    splits = {\n",
    "        split: task.get_table(split, mask_input_cols=False)\n",
    "        for split in (\"train\", \"val\", \"test\")\n",
    "    }\n",
    "    return task, splits\n",
    "\n",
    "# Converts a DataFrame to feature matrix (X) and target vector (y) based on the specified target column.\n",
    "def to_Xy(df: pd.DataFrame, target_col: str):\n",
    "    y = df[target_col].to_numpy()\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y\n",
    "\n",
    "# Infers the primary key column from a table object and its DataFrame. It checks for common attribute names first, then falls back to finding the first unique column.\n",
    "def _infer_pk(table_obj, df: pd.DataFrame):\n",
    "    # best-effort: check common attribute names first, then infer by uniqueness\n",
    "    for attr in (\"primary_key_col\", \"pkey\", \"pk\", \"primary_key\", \"id_col\"):\n",
    "        if hasattr(table_obj, attr):\n",
    "            cand = getattr(table_obj, attr)\n",
    "            if isinstance(cand, str) and cand in df.columns:\n",
    "                return cand\n",
    "    # fallback: take the first unique column if exists\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            if df[c].is_unique:\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# Denormalizes a single-hop foreign key relationship by left-joining the non-key attributes from the related table to the base DataFrame. It uses the primary key column to perform the join, ensuring that the resulting DataFrame contains all attributes from both tables.\n",
    "def denormalize_one_hop(dataset, base_df: pd.DataFrame):\n",
    "    try:\n",
    "        db = dataset.get_db()\n",
    "    except Exception:\n",
    "        return base_df\n",
    "\n",
    "    tables = getattr(db, \"tables\", None)\n",
    "    if not isinstance(tables, dict):\n",
    "        return base_df\n",
    "\n",
    "    # Build a map: PK column name -> (table_name, table_df, pk_col)\n",
    "    pkmap = {}\n",
    "    for name, tbl in tables.items():\n",
    "        df = getattr(tbl, \"df\", None)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            pk = _infer_pk(tbl, df)\n",
    "            if pk and pk in df.columns:\n",
    "                pkmap.setdefault(pk, []).append((name, df, pk))\n",
    "\n",
    "    df_out = base_df.copy()\n",
    "    # For each column in base that matches a PK in the DB, left join the non-key attributes\n",
    "    for fk_col in list(df_out.columns):\n",
    "        if fk_col in pkmap:\n",
    "            for (tname, tdf, pk) in pkmap[fk_col]:\n",
    "                right = tdf.drop(columns=[pk], errors=\"ignore\").copy()\n",
    "                if right.empty:\n",
    "                    continue\n",
    "                # prefix joined columns to avoid collisions\n",
    "                right = right.add_prefix(f\"{tname}__\")\n",
    "                # attach the join key back (unprefixed) for merge\n",
    "                right[fk_col] = tdf[pk]\n",
    "                try:\n",
    "                    df_out = df_out.merge(right, on=fk_col, how=\"left\")\n",
    "                except Exception:\n",
    "                    # keep going; some keys may be non-joinable due to dtype issues\n",
    "                    pass\n",
    "    return df_out\n",
    "\n",
    "# Builds frames for each split of a task, either using the original target table (single-table mode) or by denormalizing the data (merged-table mode). Returns a dictionary with split names as keys and tuples of (X, y, original_df) as values.\n",
    "def build_single_table_frames(task, splits):\n",
    "    frames = {}\n",
    "    for split, table in splits.items():\n",
    "        df = table.df.copy()\n",
    "        # IMPORTANT: do not touch column masking/order; just drop the target to form X\n",
    "        X, y = to_Xy(df, task.target_col)\n",
    "        frames[split] = (X, y, df)  # keep original df for evaluation alignment\n",
    "    return frames\n",
    "\n",
    "# Builds frames for each split of a dataset in merged-table mode. It denormalizes the base DataFrame by performing a one-hop foreign key join, then extracts features (X) and targets (y) for each split. Returns a dictionary with split names as keys and tuples of (X, y, merged_df) as values.\n",
    "# This allows for a more comprehensive view of the data by combining related attributes from different tables.\n",
    "def build_merged_table_frames(dataset, task, splits):\n",
    "    frames = {}\n",
    "    for split, table in splits.items():\n",
    "        base_df = table.df.copy()\n",
    "        merged_df = denormalize_one_hop(dataset, base_df)\n",
    "        X, y = to_Xy(merged_df, task.target_col)\n",
    "        frames[split] = (X, y, merged_df)\n",
    "    return frames\n"
   ],
   "id": "1cfbaca7c6d3b12c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorization Wrapper (Version-Safe)\n",
    "\n",
    "Initializes a `TableVectorizer` with only supported arguments for the installed `skrub` or `dirty_cat` version, ensuring compatibility. Transforms `train`, `val`, and `test` splits into numerical feature matrices, converting them to dense format if necessary.\n"
   ],
   "id": "f7cf59b1861625f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper Functions for Vectorization",
   "id": "ff99875cd0db904d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:17.558162Z",
     "start_time": "2025-08-16T10:52:17.555391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This function creates a `TableVectorizer` instance with version-specific arguments.\n",
    "def _make_table_vectorizer():\n",
    "    sig = inspect.signature(TableVectorizer.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    tv_kwargs = {}\n",
    "\n",
    "    # Only set kwargs that actually exist in the installed version\n",
    "    if \"cardinality_threshold\" in allowed:\n",
    "        tv_kwargs[\"cardinality_threshold\"] = globals().get(\"CARDINALITY_THRESHOLD\", 1000)\n",
    "\n",
    "    # Some versions expose this; others don't, guard it\n",
    "    if \"high_cardinality_transformer\" in allowed:\n",
    "        tv_kwargs[\"high_cardinality_transformer\"] = globals().get(\"HIGH_CARD_TRANSFORMER\", \"hashing\")\n",
    "\n",
    "    # Optional knobs if you define them globally and the version supports them\n",
    "    if \"text_separator\" in allowed and \"TEXT_SEPARATOR\" in globals():\n",
    "        tv_kwargs[\"text_separator\"] = globals()[\"TEXT_SEPARATOR\"]\n",
    "    if \"numerical_transformer\" in allowed and \"NUMERICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"numerical_transformer\"] = globals()[\"NUMERICAL_TRANSFORMER\"]\n",
    "    if \"categorical_transformer\" in allowed and \"CATEGORICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"categorical_transformer\"] = globals()[\"CATEGORICAL_TRANSFORMER\"]\n",
    "\n",
    "    return TableVectorizer(**tv_kwargs)\n",
    "\n",
    "# Converts a sparse matrix to a dense NumPy array, handling cases where the input is already dense or does not support `.toarray()`.\n",
    "def _to_dense(X):\n",
    "    try:\n",
    "        # scipy sparse matrices have .toarray()\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "    except Exception:\n",
    "        return X\n",
    "\n",
    "# Vectorizes the training, validation, and test splits using a `TableVectorizer`. It initializes the vectorizer, fits it on the training data, and transforms all splits into dense NumPy arrays. Returns the vectorizer and the transformed matrices.\n",
    "def vectorize_splits(X_train, X_val, X_test):\n",
    "    # Fit only on training data to prevent data leakage\n",
    "    tv = _make_table_vectorizer()\n",
    "    Xt = _to_dense(tv.fit_transform(X_train))\n",
    "    Xv = _to_dense(tv.transform(X_val))\n",
    "    Xs = _to_dense(tv.transform(X_test))\n",
    "    return tv, Xt, Xv, Xs\n"
   ],
   "id": "ffb43a27c3ac51cb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:17.570922Z",
     "start_time": "2025-08-16T10:52:17.568314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This function subsamples the training data to a maximum size defined by `TABPFN_MAX`. If the dataset is smaller than this cap, it returns the full dataset; otherwise, it randomly samples without replacement.\n",
    "def _subsample(X, y, cap=TABPFN_MAX, seed=SEED):\n",
    "    if len(X) <= cap:\n",
    "        return X, y, np.arange(len(X))\n",
    "    idx = np.random.RandomState(seed).choice(len(X), size=cap, replace=False)\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        Xs = X.iloc[idx]\n",
    "    else:\n",
    "        Xs = X[idx]\n",
    "    ys = y[idx]\n",
    "    return Xs, ys, idx\n",
    "\n",
    "# Fits a TabPFN model (either classifier or regressor) based on the task type. It initializes the model with the specified device and number of estimators, then fits it to the provided training data.\n",
    "def _fit_tabpfn(task, Xt, yt):\n",
    "    if task.task_type == TaskType.REGRESSION and TabPFNRegressor is not None:\n",
    "        model = TabPFNRegressor(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    else:\n",
    "        model = TabPFNClassifier(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    model.fit(Xt, yt)\n",
    "    return model\n",
    "\n",
    "# Helper function to make predictions for a given task using the fitted model. It handles different task types (regression, binary classification, multiclass/multilabel) and returns the appropriate prediction format.\n",
    "def _predict_for_task(task, model, X):\n",
    "    # align with RelBench evaluators: AUROC expects probabilities for the positive class\n",
    "    if task.task_type == TaskType.REGRESSION:\n",
    "        return model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    if task.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "        return proba[:, 1]\n",
    "    else:\n",
    "        # multiclass/multilabel: pass full probability matrix\n",
    "        return proba"
   ],
   "id": "5c53f649ce01b948",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run TabPFN on Selected Tasks\n",
    "\n",
    "Runs TabPFN on a specified dataset and task, handling both single-table and merged-table modes. It vectorizes the data, fits the model, makes predictions, and evaluates performance using RelBench’s evaluators. Returns a dictionary with results."
   ],
   "id": "21448305df117a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:52:17.583440Z",
     "start_time": "2025-08-16T10:52:17.580724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tabpfn_on_task(dataset_name: str, task_name: str, mode: str = \"single\") -> Dict[str, Any]:\n",
    "    # Load dataset and task splits\n",
    "    dataset = get_dataset(dataset_name, download=DOWNLOAD)\n",
    "    task, splits = fetch_splits(dataset_name, task_name, download=DOWNLOAD)\n",
    "\n",
    "    # Ensure the task is compatible with TabPFN\n",
    "    if mode == \"single\":\n",
    "        frames = build_single_table_frames(task, splits)\n",
    "    elif mode == \"merged\":\n",
    "        frames = build_merged_table_frames(dataset, task, splits)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'single' or 'merged'\")\n",
    "\n",
    "    # Extract features and targets for each split\n",
    "    (Xtr, ytr, _dftr) = frames[\"train\"]\n",
    "    (Xva, yva, dfva)  = frames[\"val\"]\n",
    "    (Xte, yte, dfte)  = frames[\"test\"]\n",
    "\n",
    "    # Vectorize\n",
    "    tv, Xt, Xv, Xs = vectorize_splits(Xtr, Xva, Xte)\n",
    "\n",
    "    # Respect TabPFN's sample cap\n",
    "    Xt_cap, yt_cap, _ = _subsample(Xt, ytr, cap=TABPFN_MAX, seed=SEED)\n",
    "\n",
    "    # Fit\n",
    "    model = _fit_tabpfn(task, Xt_cap, yt_cap)\n",
    "\n",
    "    # Predict & Evaluate with RelBench evaluators\n",
    "    val_pred  = _predict_for_task(task, model, Xv)\n",
    "    test_pred = _predict_for_task(task, model, Xs)\n",
    "\n",
    "    # Align predictions with original DataFrame indices for evaluation\n",
    "    val_metrics  = task.evaluate(val_pred,  splits[\"val\"])\n",
    "    test_metrics = task.evaluate(test_pred, splits[\"test\"])\n",
    "\n",
    "    # Convert metrics to a dictionary, ensuring all values are floats\n",
    "    out = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"task\": task_name,\n",
    "        \"mode\": mode,\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"n_train_used\": len(Xt_cap),\n",
    "        \"n_train_total\": len(Xt),\n",
    "        \"n_val\": len(Xv),\n",
    "        \"n_test\": len(Xs),\n",
    "    }\n",
    "    return out"
   ],
   "id": "52860c3ba39daf4c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Orchestrator for Benchmark Runs\n",
    "\n",
    "Iterates over all discovered tasks and runs TabPFN in both **single** and **merged** modes. Collects performance metrics for validation and test splits into a results table, handling failures gracefully. Sorts results for easier comparison.\n"
   ],
   "id": "1390db1f75d264ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:34:02.293077Z",
     "start_time": "2025-08-16T10:52:17.593930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODES = globals().get(\"MODES\", [\"single\", \"merged\"])\n",
    "\n",
    "records = []\n",
    "failures = []\n",
    "\n",
    "# Run TabPFN on all tasks in both modes and collect results\n",
    "for task_name in TASKS:\n",
    "    for mode in MODES:\n",
    "        try:\n",
    "            res = run_tabpfn_on_task(DATASET, task_name, mode=mode)\n",
    "            # Flatten metrics for val and test, one metric per row\n",
    "            for split in [\"val\", \"test\"]:\n",
    "                metrics = res.get(f\"{split}_metrics\") or {}\n",
    "                for metric_name, metric_value in metrics.items():\n",
    "                    # Only add rows with non-empty metric_value\n",
    "                    if metric_value is not None and not (isinstance(metric_value, float) and np.isnan(metric_value)):\n",
    "                        records.append({\n",
    "                            \"dataset\": res.get(\"dataset\", DATASET),\n",
    "                            \"task\": res.get(\"task\", task_name),\n",
    "                            \"split\": split,\n",
    "                            \"mode\": res.get(\"mode\", mode),\n",
    "                            \"method\": \"TabPFN_experimental_v1.0\",\n",
    "                            \"metric\": metric_name,\n",
    "                            \"score\": metric_value,\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            msg = f\"[{DATASET} | {task_name} | {mode}] failed: {e!s}\"\n",
    "            print(msg)\n",
    "            failures.append(msg)\n",
    "\n",
    "# Convert collected records into a DataFrame\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# If no successful runs were recorded, display a message and create an empty DataFrame\n",
    "if results_df.empty:\n",
    "    print(\"No successful runs were recorded. Check the failure messages above.\")\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"dataset\", \"task\", \"split\", \"mode\", \"method\", \"metric\", \"score\"]\n",
    "    )\n",
    "else:\n",
    "    # Ensure required sort keys exist even if some rows missed them\n",
    "    for col in [\"task\", \"mode\"]:\n",
    "        if col not in results_df.columns:\n",
    "            results_df[col] = pd.NA\n",
    "    # Sort only by the columns that exist to avoid KeyError\n",
    "    sort_keys = [c for c in [\"task\", \"mode\", \"metric\"] if c in results_df.columns]\n",
    "    if sort_keys:\n",
    "        results_df = results_df.sort_values(sort_keys)\n",
    "\n",
    "display(results_df)\n"
   ],
   "id": "be6242da806a8050",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rel-f1 | driver-position | single] failed: got an unexpected keyword argument 'squared'\n",
      "Loading Database object from /Users/michaelflppv/Library/Caches/relbench/rel-f1/db...\n",
      "Done in 0.01 seconds.\n",
      "[rel-f1 | driver-position | merged] failed: got an unexpected keyword argument 'squared'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   dataset         task split    mode                    method  \\\n",
       "9   rel-f1   driver-dnf   val  merged  TabPFN_experimental_v1.0   \n",
       "13  rel-f1   driver-dnf  test  merged  TabPFN_experimental_v1.0   \n",
       "8   rel-f1   driver-dnf   val  merged  TabPFN_experimental_v1.0   \n",
       "12  rel-f1   driver-dnf  test  merged  TabPFN_experimental_v1.0   \n",
       "10  rel-f1   driver-dnf   val  merged  TabPFN_experimental_v1.0   \n",
       "14  rel-f1   driver-dnf  test  merged  TabPFN_experimental_v1.0   \n",
       "11  rel-f1   driver-dnf   val  merged  TabPFN_experimental_v1.0   \n",
       "15  rel-f1   driver-dnf  test  merged  TabPFN_experimental_v1.0   \n",
       "1   rel-f1   driver-dnf   val  single  TabPFN_experimental_v1.0   \n",
       "5   rel-f1   driver-dnf  test  single  TabPFN_experimental_v1.0   \n",
       "0   rel-f1   driver-dnf   val  single  TabPFN_experimental_v1.0   \n",
       "4   rel-f1   driver-dnf  test  single  TabPFN_experimental_v1.0   \n",
       "2   rel-f1   driver-dnf   val  single  TabPFN_experimental_v1.0   \n",
       "6   rel-f1   driver-dnf  test  single  TabPFN_experimental_v1.0   \n",
       "3   rel-f1   driver-dnf   val  single  TabPFN_experimental_v1.0   \n",
       "7   rel-f1   driver-dnf  test  single  TabPFN_experimental_v1.0   \n",
       "25  rel-f1  driver-top3   val  merged  TabPFN_experimental_v1.0   \n",
       "29  rel-f1  driver-top3  test  merged  TabPFN_experimental_v1.0   \n",
       "24  rel-f1  driver-top3   val  merged  TabPFN_experimental_v1.0   \n",
       "28  rel-f1  driver-top3  test  merged  TabPFN_experimental_v1.0   \n",
       "26  rel-f1  driver-top3   val  merged  TabPFN_experimental_v1.0   \n",
       "30  rel-f1  driver-top3  test  merged  TabPFN_experimental_v1.0   \n",
       "27  rel-f1  driver-top3   val  merged  TabPFN_experimental_v1.0   \n",
       "31  rel-f1  driver-top3  test  merged  TabPFN_experimental_v1.0   \n",
       "17  rel-f1  driver-top3   val  single  TabPFN_experimental_v1.0   \n",
       "21  rel-f1  driver-top3  test  single  TabPFN_experimental_v1.0   \n",
       "16  rel-f1  driver-top3   val  single  TabPFN_experimental_v1.0   \n",
       "20  rel-f1  driver-top3  test  single  TabPFN_experimental_v1.0   \n",
       "18  rel-f1  driver-top3   val  single  TabPFN_experimental_v1.0   \n",
       "22  rel-f1  driver-top3  test  single  TabPFN_experimental_v1.0   \n",
       "19  rel-f1  driver-top3   val  single  TabPFN_experimental_v1.0   \n",
       "23  rel-f1  driver-top3  test  single  TabPFN_experimental_v1.0   \n",
       "\n",
       "               metric     score  \n",
       "9            accuracy  0.779152  \n",
       "13           accuracy  0.705128  \n",
       "8   average_precision  0.816068  \n",
       "12  average_precision  0.821835  \n",
       "10                 f1  0.875869  \n",
       "14                 f1  0.827068  \n",
       "11            roc_auc  0.537995  \n",
       "15            roc_auc  0.654575  \n",
       "1            accuracy  0.779152  \n",
       "5            accuracy  0.705128  \n",
       "0   average_precision  0.816068  \n",
       "4   average_precision  0.821835  \n",
       "2                  f1  0.875869  \n",
       "6                  f1  0.827068  \n",
       "3             roc_auc  0.537995  \n",
       "7             roc_auc  0.654575  \n",
       "25           accuracy  0.794218  \n",
       "29           accuracy  0.792011  \n",
       "24  average_precision  0.290635  \n",
       "28  average_precision  0.191116  \n",
       "26                 f1  0.153846  \n",
       "30                 f1  0.038217  \n",
       "27            roc_auc  0.597732  \n",
       "31            roc_auc  0.567308  \n",
       "17           accuracy  0.794218  \n",
       "21           accuracy  0.792011  \n",
       "16  average_precision  0.290635  \n",
       "20  average_precision  0.191116  \n",
       "18                 f1  0.153846  \n",
       "22                 f1  0.038217  \n",
       "19            roc_auc  0.597732  \n",
       "23            roc_auc  0.567308  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>split</th>\n",
       "      <th>mode</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.816068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.821835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.875869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.827068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.537995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.654575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.816068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.821835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.875869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.827068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.537995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.654575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.794218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.792011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.290635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.191116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.597732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.567308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.794218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.792011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.290635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.191116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.597732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-top3</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experimental_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.567308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Results to CSV",
   "id": "63c64e43fa5f49a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:34:02.319784Z",
     "start_time": "2025-08-16T11:34:02.315244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify output directory\n",
    "out_dir = globals().get(\"OUT_DIR\", \"outputs\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Change timestamp format to \"dd.mm.yyyy-hh:mm\"\n",
    "timestamp = time.strftime(\"%d.%m.%Y-%H:%M\")\n",
    "csv_name = f\"tabpfn_{DATASET}_{timestamp}.csv\"\n",
    "csv_path = os.path.join(out_dir, csv_name)\n",
    "\n",
    "# Round all numerical results to 4 decimal places before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(results_df[\"score\"]):\n",
    "        results_df[\"score\"] = results_df[\"score\"].round(4)\n",
    "    else:\n",
    "        # Optionally, try to convert to numeric first\n",
    "        results_df[\"score\"] = pd.to_numeric(results_df[\"score\"], errors=\"coerce\").round(4)\n",
    "\n",
    "# Filter out rows with empty score values before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    results_df = results_df[results_df[\"score\"].notnull()]\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved results to: {csv_path}\")\n"
   ],
   "id": "aa929637db7d0d54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: outputs/tabpfn_rel-f1_16.08.2025-13:34.csv\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
