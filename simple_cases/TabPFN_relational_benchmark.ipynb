{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.154337Z",
     "start_time": "2025-08-14T20:19:34.252968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm  # Add tqdm for progress bar\n",
    "from itertools import product\n",
    "\n",
    "# RelBench\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "import relbench.metrics\n",
    "import inspect\n",
    "from skrub import TableVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# Device preference\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define global dataset variable\n",
    "DATASET = \"rel-f1\"\n"
   ],
   "id": "57624fe02c838842",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.234164Z",
     "start_time": "2025-08-14T20:19:37.231696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.343695Z",
     "start_time": "2025-08-14T20:19:37.240412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = time.perf_counter()\n",
    "    yield lambda: time.perf_counter() - start\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        out[\"roc_auc\"] = np.nan\n",
    "    return out\n",
    "\n",
    "def regression_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    # Accepts y_prob for compatibility, but ignores it\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "dataset = get_dataset(DATASET)\n",
    "db = dataset.get_db()\n",
    "\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Convert all tables to pandas DataFrames\n",
    "tables = {}\n",
    "for name in db.table_dict:\n",
    "    tables[name] = to_pandas(db.table_dict[name])\n",
    "\n",
    "for t in tables.values():\n",
    "    for col in t.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            t[col] = pd.to_datetime(t[col], errors=\"coerce\")"
   ],
   "id": "4da5c0d65181834d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /Users/michaelflppv/Library/Caches/relbench/rel-f1/db...\n",
      "Done in 0.08 seconds.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.357257Z",
     "start_time": "2025-08-14T20:19:37.354430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- NEW CELL: skrub preprocessing helpers ---\n",
    "\n",
    "def build_tv():\n",
    "    \"\"\"\n",
    "    TableVectorizer turns mixed (numeric + categorical + text + datetime) columns\n",
    "    into a numeric feature matrix. We keep defaults to match the tutorials’ simplicity.\n",
    "    \"\"\"\n",
    "    return TableVectorizer()\n",
    "\n",
    "def fit_transform_splits(tv, X_train_df, X_val_df=None, X_test_df=None):\n",
    "    \"\"\"\n",
    "    Fit TV on train only; transform val/test. Cast to float32 for TabPFN.\n",
    "    \"\"\"\n",
    "    # Ensure no NaN or infinite values before vectorizing\n",
    "    X_train_df = X_train_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    if X_val_df is not None:\n",
    "        X_val_df = X_val_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    if X_test_df is not None:\n",
    "        X_test_df = X_test_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    Xt_train = tv.fit_transform(X_train_df).astype(np.float32)\n",
    "    Xt_val   = tv.transform(X_val_df).astype(np.float32) if X_val_df is not None else None\n",
    "    Xt_test  = tv.transform(X_test_df).astype(np.float32) if X_test_df is not None else None\n",
    "    return Xt_train, Xt_val, Xt_test, tv\n",
    "\n",
    "def _get_df(table):\n",
    "    # Your tutorial-style accessor: works whether object has `.df` or `.to_pandas()`\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    raise ValueError(\"Unknown table type for conversion to DataFrame.\")\n"
   ],
   "id": "2ec47853dd80bd98",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.369173Z",
     "start_time": "2025-08-14T20:19:37.365023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- REPLACE the whole function: run_single_table_experiment ---\n",
    "\n",
    "def run_single_table_experiment(task_name: str):\n",
    "    \"\"\"\n",
    "    Apply TabPFN to the single base table provided by the task.\n",
    "    Uses skrub.TableVectorizer to encode all non-numerical columns.\n",
    "    \"\"\"\n",
    "    global prob_val, prob_test\n",
    "\n",
    "    # Load task and splits (tutorial API)\n",
    "    task = get_task(DATASET, task_name)\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table   = task.get_table(\"val\")\n",
    "    test_table  = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    # Convert to pandas (tutorial style)\n",
    "    df_train = _get_df(train_table).copy()\n",
    "    df_val   = _get_df(val_table).copy()\n",
    "    df_test  = _get_df(test_table).copy()\n",
    "\n",
    "    # Optional subsampling to keep parity with your original notebook\n",
    "    df_train = df_train.sample(n=min(1000, len(df_train)), random_state=42)\n",
    "    df_val   = df_val.sample(n=min(1000, len(df_val)), random_state=42)\n",
    "\n",
    "    # Target column name taken from the task object (tutorials use task.target_col)\n",
    "    target_col = task.target_col\n",
    "\n",
    "    # Split X/y; keep ALL feature columns (skrub will encode mixed types)\n",
    "    X_train_df = df_train.drop(columns=[target_col])\n",
    "    y_train    = df_train[target_col]\n",
    "\n",
    "    X_val_df = df_val.drop(columns=[target_col])\n",
    "    y_val    = df_val[target_col]\n",
    "\n",
    "    X_test_df = df_test.drop(columns=[target_col])\n",
    "    y_test    = df_test[target_col]\n",
    "\n",
    "    # Build + fit TableVectorizer on train only; transform val/test\n",
    "    tv = build_tv()\n",
    "    Xt_train, Xt_val, Xt_test, tv = fit_transform_splits(tv, X_train_df, X_val_df, X_test_df)\n",
    "\n",
    "    # Decide model family (simple rule compatible with the tutorials)\n",
    "    is_regression = pd.api.types.is_float_dtype(y_train) and y_train.nunique() > 10\n",
    "\n",
    "    if is_regression:\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    # Fit + time it\n",
    "    with elapsed_timer() as t_fit:\n",
    "        model.fit(Xt_train, y_train)\n",
    "    fit_time = t_fit()\n",
    "\n",
    "    # Predict + time\n",
    "    with elapsed_timer() as t_pred_val:\n",
    "        y_val_pred = model.predict(Xt_val)\n",
    "        prob_val = None\n",
    "        if not is_regression and hasattr(model, \"predict_proba\"):\n",
    "            prob_val = model.predict_proba(Xt_val)\n",
    "    pred_time_val = t_pred_val()\n",
    "\n",
    "    with elapsed_timer() as t_pred_test:\n",
    "        y_test_pred = model.predict(Xt_test)\n",
    "        prob_test = None\n",
    "        if not is_regression and hasattr(model, \"predict_proba\"):\n",
    "            prob_test = model.predict_proba(Xt_test)\n",
    "    pred_time_test = t_pred_test()\n",
    "\n",
    "    # Primary metric to mirror RelBench style: accuracy for clf, MAE for reg\n",
    "    if is_regression:\n",
    "        primary_metric_val  = mean_absolute_error(y_val,  y_val_pred)\n",
    "        primary_metric_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    else:\n",
    "        primary_metric_val  = accuracy_score(y_val,  y_val_pred)\n",
    "        primary_metric_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "f430cf6e11811564",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.404438Z",
     "start_time": "2025-08-14T20:19:37.376521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create features for drivers based on their past performance\n",
    "# This function creates features like average position, points, DNF rate, and average laps\n",
    "def engineer_driver_features():\n",
    "    # Extract the race dates and results\n",
    "    results = tables[\"results\"].merge(\n",
    "        tables[\"races\"][[\"raceId\", \"date\"]],\n",
    "        on=\"raceId\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"results columns after merge:\", results.columns.tolist())\n",
    "    print(\"Number of rows after merge:\", results.shape[0])\n",
    "    results = results.dropna(subset=[\"driverId\", \"date_y\"])\n",
    "    print(\"Number of rows after dropna:\", results.shape[0])\n",
    "\n",
    "    # Create a did not finish (DNF) flag as indicator for future race outcomes\n",
    "    results[\"dnf_flag\"] = (~results[\"positionOrder\"].isna()).astype(int)\n",
    "    # For each driver, calculate the average position, points, DNF rate, and average laps\n",
    "    # Only the information before the current race is used\n",
    "    feats = results.groupby(\"driverId\").expanding().agg({\n",
    "        \"positionOrder\": \"mean\",\n",
    "        \"points\": \"mean\",\n",
    "        \"dnf_flag\": \"mean\",\n",
    "        \"laps\": \"mean\"\n",
    "    }).reset_index()\n",
    "    feats = feats.rename(columns={\n",
    "        \"positionOrder\": \"avg_position\",\n",
    "        \"points\": \"avg_points\",\n",
    "        \"dnf_flag\": \"dnf_rate\",\n",
    "        \"laps\": \"avg_laps\"\n",
    "    })\n",
    "    feats[\"date\"] = results[\"date_y\"].values\n",
    "    return feats\n",
    "\n",
    "driver_feats = engineer_driver_features()"
   ],
   "id": "de1f9fe2a4bd02ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results columns after merge: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionOrder', 'points', 'laps', 'milliseconds', 'fastestLap', 'rank', 'statusId', 'date_x', 'date_y']\n",
      "Number of rows after merge: 20323\n",
      "Number of rows after dropna: 20323\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:19:37.422675Z",
     "start_time": "2025-08-14T20:19:37.413595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- REPLACE the whole function: run_merged_table_experiment ---\n",
    "\n",
    "def run_merged_table_experiment(task_name: str):\n",
    "    \"\"\"\n",
    "    Build a merged, wide table using the schema:\n",
    "      results ← races ← circuits\n",
    "      results ← drivers\n",
    "      results ← constructors\n",
    "      results ← standings (driver-level)\n",
    "      results ← constructor_results\n",
    "      results ← constructor_standings\n",
    "      results ← qualifying\n",
    "    Then apply TabPFN with skrub.\n",
    "    \"\"\"\n",
    "    global prob_val, prob_test\n",
    "\n",
    "    # Load task and splits\n",
    "    task = get_task(DATASET, task_name)\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table   = task.get_table(\"val\")\n",
    "    test_table  = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    # Convert to pandas\n",
    "    base_train = _get_df(train_table).copy()\n",
    "    base_val   = _get_df(val_table).copy()\n",
    "    base_test  = _get_df(test_table).copy()\n",
    "\n",
    "    # Optional subsampling (to match your original)\n",
    "    base_train = base_train.sample(n=min(1000, len(base_train)), random_state=42)\n",
    "    base_val   = base_val.sample(n=min(1000, len(base_val)), random_state=42)\n",
    "\n",
    "    # Helper: one merge function respecting keys if present\n",
    "    def _merge_all(base_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Tag each row with its original position to guard against one‐to‐many blowup\n",
    "        df = base_df.copy().reset_index(drop=False).rename(columns={'index': '_orig_index'})\n",
    "\n",
    "        # results (most tasks for F1 are grounded there; join if not already)\n",
    "        results = tables[\"results\"]\n",
    "        join_keys = [k for k in [\"raceId\",\"driverId\",\"constructorId\"] if k in df.columns and k in results.columns]\n",
    "        if join_keys:\n",
    "            df = df.merge(results, how=\"left\", on=join_keys, suffixes=(\"\",\"_res\"))\n",
    "\n",
    "        # races\n",
    "        if \"raceId\" in df.columns:\n",
    "            races = tables[\"races\"][[\"raceId\",\"year\",\"round\",\"circuitId\",\"name\",\"date\",\"time\"]]\n",
    "            df = df.merge(races, how=\"left\", on=\"raceId\", suffixes=(\"\",\"_race\"))\n",
    "\n",
    "        # circuits\n",
    "        if \"circuitId\" in df.columns:\n",
    "            circuits = tables[\"circuits\"][[\"circuitId\",\"name\",\"location\",\"country\",\"lat\",\"lng\",\"alt\"]]\n",
    "            df = df.merge(circuits, how=\"left\", on=\"circuitId\", suffixes=(\"\",\"_circuit\"))\n",
    "\n",
    "        # drivers\n",
    "        if \"driverId\" in df.columns:\n",
    "            drivers = tables[\"drivers\"][[\"driverId\",\"driverRef\",\"code\",\"forename\",\"surname\",\"dob\",\"nationality\"]]\n",
    "            df = df.merge(drivers, how=\"left\", on=\"driverId\", suffixes=(\"\",\"_drv\"))\n",
    "\n",
    "        # constructors\n",
    "        if \"constructorId\" in df.columns:\n",
    "            constructors = tables[\"constructors\"][[\"constructorId\",\"constructorRef\",\"name\",\"nationality\"]]\n",
    "            df = df.merge(constructors, how=\"left\", on=\"constructorId\", suffixes=(\"\",\"_con\"))\n",
    "\n",
    "        # standings (driver-level)\n",
    "        if \"raceId\" in df.columns and \"driverId\" in df.columns and \"standings\" in tables:\n",
    "            drv_st = tables[\"standings\"][[\"raceId\",\"driverId\",\"points\",\"position\",\"wins\",\"date\"]].rename(\n",
    "                columns={\"points\":\"drv_points_to_date\",\"position\":\"drv_pos_to_date\",\"wins\":\"drv_wins_to_date\",\"date\":\"drv_standings_date\"}\n",
    "            )\n",
    "            df = df.merge(drv_st, how=\"left\", on=[\"raceId\",\"driverId\"])\n",
    "\n",
    "        # constructor_results\n",
    "        if \"raceId\" in df.columns and \"constructorId\" in df.columns and \"constructor_results\" in tables:\n",
    "            cr = tables[\"constructor_results\"][[\"raceId\",\"constructorId\",\"points\",\"date\"]].rename(\n",
    "                columns={\"points\":\"con_points_at_race\",\"date\":\"con_results_date\"}\n",
    "            )\n",
    "            df = df.merge(cr, how=\"left\", on=[\"raceId\",\"constructorId\"])\n",
    "\n",
    "        # constructor_standings\n",
    "        if \"raceId\" in df.columns and \"constructorId\" in df.columns and \"constructor_standings\" in tables:\n",
    "            cs = tables[\"constructor_standings\"][[\"raceId\",\"constructorId\",\"points\",\"position\",\"wins\",\"date\"]].rename(\n",
    "                columns={\"points\":\"con_points_to_date\",\"position\":\"con_pos_to_date\",\"wins\":\"con_wins_to_date\",\"date\":\"con_standings_date\"}\n",
    "            )\n",
    "            df = df.merge(cs, how=\"left\", on=[\"raceId\",\"constructorId\"])\n",
    "\n",
    "        # qualifying\n",
    "        if \"raceId\" in df.columns and \"driverId\" in df.columns and \"constructorId\" in df.columns and \"qualifying\" in tables:\n",
    "            q = tables[\"qualifying\"][[\"raceId\",\"driverId\",\"constructorId\",\"number\",\"position\"]].rename(\n",
    "                columns={\"number\":\"quali_number\",\"position\":\"quali_position\"}\n",
    "            )\n",
    "            df = df.merge(q, how=\"left\", on=[\"raceId\",\"driverId\",\"constructorId\"])\n",
    "\n",
    "        # --- Light feature engineering (schema-aware) ---\n",
    "        # Driver age on race date\n",
    "        if \"dob\" in df.columns:\n",
    "            # race date can be from results or races; use the first date-like col available\n",
    "            date_cols = [c for c in df.columns if \"date\" in c.lower()]\n",
    "            race_date = None\n",
    "            for c in [\"date\", \"date_race\", \"date_y\", \"date_res\"] + date_cols:\n",
    "                if c in df.columns:\n",
    "                    race_date = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "                    break\n",
    "            dob = pd.to_datetime(df[\"dob\"], errors=\"coerce\")\n",
    "            if race_date is not None:\n",
    "                df[\"driver_age_years\"] = (race_date - dob).dt.days / 365.25\n",
    "\n",
    "        # Calendar features from main date if present\n",
    "        if \"date\" in df.columns:\n",
    "            dt = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "            df[\"race_year\"]  = dt.dt.year\n",
    "            df[\"race_month\"] = dt.dt.month\n",
    "            df[\"race_day\"]   = dt.dt.day\n",
    "            df[\"race_dow\"]   = dt.dt.dayofweek\n",
    "\n",
    "        # Grid-based derived feature if available\n",
    "        if \"grid\" in df.columns and \"position\" in df.columns:\n",
    "            df[\"grid_advancement\"] = df[\"grid\"] - df[\"position\"]\n",
    "\n",
    "        # Tie qualifying to grid if both present\n",
    "        if \"quali_position\" in df.columns and \"grid\" in df.columns:\n",
    "            df[\"quali_to_grid_delta\"] = df[\"quali_position\"] - df[\"grid\"]\n",
    "\n",
    "        # --- NEW: merge engineered driver-features as of race date ---\n",
    "        if \"driverId\" in df.columns:\n",
    "            # find the appropriate race-date column\n",
    "            date_cols = [c for c in df.columns if \"date\" in c.lower()]\n",
    "            for c in [\"date\", \"date_race\", \"date_y\", \"date_res\"] + date_cols:\n",
    "                if c in df.columns:\n",
    "                    df[\"_race_date\"] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "                    break\n",
    "            # prepare driver_feats for asof-join\n",
    "            feats = driver_feats.rename(columns={\"date\": \"feat_date\"})\n",
    "            feats = feats.sort_values([\"driverId\", \"feat_date\"])\n",
    "            df = df.sort_values([\"driverId\", \"_race_date\"])\n",
    "            # only bring in stats from before each race\n",
    "            df = pd.merge_asof(\n",
    "                df,\n",
    "                feats,\n",
    "                left_on=\"_race_date\",\n",
    "                right_on=\"feat_date\",\n",
    "                by=\"driverId\",\n",
    "                direction=\"backward\",\n",
    "            )\n",
    "            df.drop(columns=[\"feat_date\"], inplace=True)\n",
    "\n",
    "        # Drop any duplicates and restore original row count\n",
    "        df = df.sort_values('_orig_index').drop_duplicates(subset=['_orig_index'])\n",
    "        df = df.drop(columns=['_orig_index', '_race_date'])\n",
    "        return df\n",
    "\n",
    "    train_merged = _merge_all(base_train)\n",
    "    val_merged   = _merge_all(base_val)\n",
    "    test_merged  = _merge_all(base_test)\n",
    "\n",
    "    target_col = task.target_col\n",
    "    # Safety: drop target if it appears in merged views (RelBench warns about leakage)\n",
    "    for df in (train_merged, val_merged, test_merged):\n",
    "        if target_col in df.columns:\n",
    "            df.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "    # X/y\n",
    "    X_train_df, y_train = train_merged, base_train[target_col]\n",
    "    X_val_df,   y_val   = val_merged,   base_val[target_col]\n",
    "    X_test_df,  y_test  = test_merged,  base_test[target_col]\n",
    "\n",
    "    # skrub vectorization\n",
    "    tv = build_tv()\n",
    "    Xt_train, Xt_val, Xt_test, tv = fit_transform_splits(tv, X_train_df, X_val_df, X_test_df)\n",
    "\n",
    "    # Decide model family (keep same rule as single-table)\n",
    "    is_regression = pd.api.types.is_float_dtype(y_train) and y_train.nunique() > 10\n",
    "\n",
    "    if is_regression:\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    # Fit + time\n",
    "    with elapsed_timer() as t_fit:\n",
    "        model.fit(Xt_train, y_train)\n",
    "    fit_time = t_fit()\n",
    "\n",
    "    # Predict + time\n",
    "    with elapsed_timer() as t_pred_val:\n",
    "        y_val_pred = model.predict(Xt_val)\n",
    "        prob_val = None\n",
    "        if not is_regression and hasattr(model, \"predict_proba\"):\n",
    "            prob_val = model.predict_proba(Xt_val)\n",
    "    pred_time_val = t_pred_val()\n",
    "\n",
    "    with elapsed_timer() as t_pred_test:\n",
    "        y_test_pred = model.predict(Xt_test)\n",
    "        prob_test = None\n",
    "        if not is_regression and hasattr(model, \"predict_proba\"):\n",
    "            prob_test = model.predict_proba(Xt_test)\n",
    "    pred_time_test = t_pred_test()\n",
    "\n",
    "    # Primary metric (simple, tutorial-friendly)\n",
    "    if is_regression:\n",
    "        primary_metric_val  = mean_absolute_error(y_val,  y_val_pred)\n",
    "        primary_metric_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    else:\n",
    "        primary_metric_val  = accuracy_score(y_val,  y_val_pred)\n",
    "        primary_metric_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "2213d3092cc43fd0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:23:03.182192Z",
     "start_time": "2025-08-14T20:19:37.431397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TASKS = [\"driver-dnf\", \"driver-top3\", \"driver-position\"]\n",
    "TASKS = [\"driver-dnf\"]\n",
    "\n",
    "all_results_long = []\n",
    "\n",
    "def results_to_long(task, setting, split, metrics):\n",
    "    rows = []\n",
    "    for metric_name, value in metrics.items():\n",
    "        # Only add row if value is not None and not NaN\n",
    "        if value is not None and not (isinstance(value, float) and np.isnan(value)):\n",
    "            rows.append({\n",
    "                \"dataset\": DATASET,  # Fill with DATASET variable\n",
    "                \"task\": task,\n",
    "                \"split\": split,\n",
    "                \"setting\": setting,\n",
    "                \"method\": \"TabPFN_experiment_v1.0\",\n",
    "                \"metric\": metric_name,\n",
    "                \"score\": value\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "# Use tqdm to show progress bar for tasks and settings\n",
    "for task in tqdm(TASKS, desc=\"Tasks\"):\n",
    "    task_setting_pairs = list(product(TASKS, [(\"single\", run_single_table_experiment), (\"merged\", run_merged_table_experiment)]))\n",
    "\n",
    "    for (task, (setting, run_fn)) in tqdm(task_setting_pairs, desc=\"Task/Setting pairs\"):\n",
    "        res = run_fn(task)\n",
    "        for split, metrics in res.items():\n",
    "            all_results_long.extend(results_to_long(task, setting, split, metrics))\n",
    "\n",
    "results_long_df = pd.DataFrame(all_results_long)\n",
    "# Ensure 'dataset' is the first column\n",
    "cols = [\"dataset\"] + [col for col in results_long_df.columns if col != \"dataset\"]\n",
    "results_long_df = results_long_df[cols]\n",
    "# Round all numerical values in 'score' to 4 decimal places\n",
    "results_long_df[\"score\"] = results_long_df[\"score\"].apply(lambda x: round(x, 4) if isinstance(x, (float, int, np.floating, np.integer)) else x)\n",
    "\n",
    "results_long_df.to_csv(\"results_summary_long.csv\", index=False)\n",
    "results_long_df"
   ],
   "id": "4ebb21a39e26d553",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tasks:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Task/Setting pairs:   0%|          | 0/2 [03:25<?, ?it/s]\u001B[A\n",
      "Tasks:   0%|          | 0/1 [03:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m task_setting_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(product(TASKS, [(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle\u001B[39m\u001B[38;5;124m\"\u001B[39m, run_single_table_experiment), (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmerged\u001B[39m\u001B[38;5;124m\"\u001B[39m, run_merged_table_experiment)]))\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (task, (setting, run_fn)) \u001B[38;5;129;01min\u001B[39;00m tqdm(task_setting_pairs, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTask/Setting pairs\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 27\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mrun_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m split, metrics \u001B[38;5;129;01min\u001B[39;00m res\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     29\u001B[0m         all_results_long\u001B[38;5;241m.\u001B[39mextend(results_to_long(task, setting, split, metrics))\n",
      "Cell \u001B[0;32mIn[5], line 69\u001B[0m, in \u001B[0;36mrun_single_table_experiment\u001B[0;34m(task_name)\u001B[0m\n\u001B[1;32m     67\u001B[0m     prob_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_regression \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict_proba\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 69\u001B[0m         prob_test \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m pred_time_test \u001B[38;5;241m=\u001B[39m t_pred_test()\n\u001B[1;32m     72\u001B[0m \u001B[38;5;66;03m# Primary metric to mirror RelBench style: accuracy for clf, MAE for reg\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/classifier.py:724\u001B[0m, in \u001B[0;36mTabPFNClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;129m@config_context\u001B[39m(transform_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpredict_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: XType) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m    715\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Predict the probabilities of the classes for the provided input samples.\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \n\u001B[1;32m    717\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;124;03m        Shape (n_samples, n_classes).\u001B[39;00m\n\u001B[1;32m    723\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 724\u001B[0m     proba_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    725\u001B[0m     output \u001B[38;5;241m=\u001B[39m proba_tensor\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m    727\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterface_config_\u001B[38;5;241m.\u001B[39mUSE_SKLEARN_16_DECIMAL_PRECISION:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/classifier.py:679\u001B[0m, in \u001B[0;36mTabPFNClassifier._raw_predict\u001B[0;34m(self, X, return_logits)\u001B[0m\n\u001B[1;32m    676\u001B[0m     X \u001B[38;5;241m=\u001B[39m _fix_dtypes(X, cat_indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minferred_categorical_indices_)\n\u001B[1;32m    677\u001B[0m     X \u001B[38;5;241m=\u001B[39m _process_text_na_dataframe(X, ord_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessor_)\n\u001B[0;32m--> 679\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inference_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_logits\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/classifier.py:818\u001B[0m, in \u001B[0;36mTabPFNClassifier.forward\u001B[0;34m(self, X, use_inference_mode, return_logits)\u001B[0m\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecutor_\u001B[38;5;241m.\u001B[39muse_torch_inference_mode(use_inference\u001B[38;5;241m=\u001B[39muse_inference_mode)\n\u001B[1;32m    817\u001B[0m outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 818\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output, config \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecutor_\u001B[38;5;241m.\u001B[39miter_outputs(\n\u001B[1;32m    819\u001B[0m     X,\n\u001B[1;32m    820\u001B[0m     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_,\n\u001B[1;32m    821\u001B[0m     autocast\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_autocast_,\n\u001B[1;32m    822\u001B[0m ):\n\u001B[1;32m    823\u001B[0m     original_ndim \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mndim\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;66;03m# This block correctly handles both single configs and lists of configs\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/inference.py:503\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001B[0;34m(self, X, device, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[1;32m    500\u001B[0m     get_autocast_context(device, enabled\u001B[38;5;241m=\u001B[39mautocast),\n\u001B[1;32m    501\u001B[0m     torch\u001B[38;5;241m.\u001B[39minference_mode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode),\n\u001B[1;32m    502\u001B[0m ):\n\u001B[0;32m--> 503\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_return_standard_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_return_standard_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategorical_inds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched_cat_ix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    510\u001B[0m output \u001B[38;5;241m=\u001B[39m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m output, config\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/transformer.py:549\u001B[0m, in \u001B[0;36mPerFeatureTransformer.forward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    542\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour embedded x and y returned the following:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_x)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_y)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    546\u001B[0m     )\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[0;32m--> 549\u001B[0m encoder_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedded_input\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43membedded_input\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/transformer.py:94\u001B[0m, in \u001B[0;36mLayerStack.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(partial(layer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, use_reentrant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/layer.py:421\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward\u001B[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    412\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be layer normed here.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    415\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    416\u001B[0m         state,\n\u001B[1;32m    417\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    418\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    419\u001B[0m     )\n\u001B[0;32m--> 421\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43msublayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_norm:\n\u001B[1;32m    423\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    424\u001B[0m         state,\n\u001B[1;32m    425\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    426\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    427\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/layer.py:319\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiquery_item_attention_for_test_set:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m single_eval_pos \u001B[38;5;241m<\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m--> 319\u001B[0m         new_x_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn_between_items\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m            \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m            \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_cached_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreuse_first_head_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    331\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m         new_x_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/attention/full_attention.py:333\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[0;34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv)\u001B[0m\n\u001B[1;32m    316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_k_cache \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\n\u001B[1;32m    317\u001B[0m             batch_size,\n\u001B[1;32m    318\u001B[0m             seqlen_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    322\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    323\u001B[0m         )\n\u001B[1;32m    324\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_v_cache \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\n\u001B[1;32m    325\u001B[0m             batch_size,\n\u001B[1;32m    326\u001B[0m             seqlen_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    330\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    331\u001B[0m         )\n\u001B[0;32m--> 333\u001B[0m output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_k_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_v_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_kv_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cached_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cached_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_inplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreuse_first_head_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreuse_first_head_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\u001B[38;5;241m.\u001B[39mreshape(x_shape_after_transpose[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m output\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:])\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/memory.py:101\u001B[0m, in \u001B[0;36msupport_save_peak_mem_factor.<locals>.method_\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[0;32m--> 101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m+\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m method(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/attention/full_attention.py:472\u001B[0m, in \u001B[0;36mMultiHeadAttention._compute\u001B[0;34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Attention computation.\u001B[39;00m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;124;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    462\u001B[0m q, k, v, kv, qkv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_qkv(\n\u001B[1;32m    463\u001B[0m     x,\n\u001B[1;32m    464\u001B[0m     x_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    470\u001B[0m     reuse_first_head_kv\u001B[38;5;241m=\u001B[39mreuse_first_head_kv,\n\u001B[1;32m    471\u001B[0m )\n\u001B[0;32m--> 472\u001B[0m attention_head_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_attention_heads\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m    \u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m    \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m    \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqkv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39meinsum(\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m... h d, h d s -> ... s\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    483\u001B[0m     attention_head_outputs,\n\u001B[1;32m    484\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_w_out,\n\u001B[1;32m    485\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/tabpfn/architectures/base/attention/full_attention.py:691\u001B[0m, in \u001B[0;36mMultiHeadAttention.compute_attention_heads\u001B[0;34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001B[0m\n\u001B[1;32m    688\u001B[0m v \u001B[38;5;241m=\u001B[39m MultiHeadAttention\u001B[38;5;241m.\u001B[39mbroadcast_kv_across_heads(v, share_kv_across_n_heads)\n\u001B[1;32m    689\u001B[0m logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39meinsum(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb q h d, b k h d -> b q k h\u001B[39m\u001B[38;5;124m\"\u001B[39m, q, k)\n\u001B[1;32m    690\u001B[0m logits \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 691\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43md_k\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m softmax_scale \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m softmax_scale\n\u001B[1;32m    694\u001B[0m )\n\u001B[1;32m    695\u001B[0m ps \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    696\u001B[0m ps \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdropout(ps, dropout_p, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_metric(metric, split=None, setting=None):\n",
    "    \"\"\"\n",
    "    Plot the given metric from results_long_df.\n",
    "    Optionally filter by split and/or setting.\n",
    "    \"\"\"\n",
    "    df = results_long_df[results_long_df[\"metric\"] == metric]\n",
    "    if split is not None:\n",
    "        df = df[df[\"split\"] == split]\n",
    "    if setting is not None:\n",
    "        df = df[df[\"setting\"] == setting]\n",
    "    if df.empty:\n",
    "        print(f\"No data for metric: {metric}, split: {split}, setting: {setting}\")\n",
    "        return\n",
    "    ax = df.pivot(index=\"task\", columns=\"setting\", values=\"score\").plot(kind=\"bar\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f\"{metric} by task and setting\")\n",
    "    ax.legend(title=\"setting\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_metric(\"accuracy\", split=\"test\")\n",
    "plot_metric(\"f1_macro\", split=\"val\")\n",
    "plot_metric(\"primary_metric_relbench\", split=\"test\")\n"
   ],
   "id": "6508b14c79bf4677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aa929637db7d0d54",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
