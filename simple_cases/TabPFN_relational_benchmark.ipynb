{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TabPFN Relational Benchmark**\n",
    "This notebook benchmarks the performance of TabPFN models on datasets from RelBench in two scenarios:\n",
    "1. **Single Table** – Using only the target entity table.\n",
    "2. **Merged Table** – Using a naively denormalized table obtained by joining related tables.\n",
    "\n",
    "It automates dataset loading, preprocessing (including date feature engineering), vectorization, model training, prediction, and evaluation for all compatible tasks within a chosen RelBench dataset. The results allow comparing model performance between single-table and merged-table configurations.\n"
   ],
   "id": "7ab5a9bf5466de0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "ac93e97c56d4b905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.233948Z",
     "start_time": "2025-08-21T15:18:40.231455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, Any, List, Tuple\n",
    "\n",
    "# --- Skrub / Sentence Transformers ---\n",
    "from skrub import TableVectorizer\n",
    "\n",
    "# --- RelBench ---\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task, get_task_names\n",
    "from relbench.base import TaskType\n",
    "import relbench.metrics\n",
    "\n",
    "# --- TabPFN ---\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# --- Featuretools ---\n",
    "import featuretools as ft"
   ],
   "id": "57624fe02c838842",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.245055Z",
     "start_time": "2025-08-21T15:18:40.243532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ],
   "id": "ebce2e3934db1e43",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set Global Configuration",
   "id": "7154198e21fe2a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.257669Z",
     "start_time": "2025-08-21T15:18:40.255220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device selection (CPU, CUDA, or MPS if available)\n",
    "def get_device():\n",
    "    # Uncomment for auto-detection\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    # elif torch.cuda.is_available():\n",
    "    #     return \"cuda\"\n",
    "    # else:\n",
    "    #     return \"cpu\"\n",
    "    return \"cpu\"  # Default: CPU\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Dataset and experiment settings\n",
    "DATASET        = globals().get(\"DATASET\", \"rel-f1\")           # Default dataset\n",
    "MAIN_TABLE     = globals().get(\"MAIN_TABLE\", \"qualifying\")    # Main table for single-table mode\n",
    "SEED           = globals().get(\"SEED\", 42)                    # Random seed\n",
    "N_ESTIMATORS   = globals().get(\"N_ESTIMATORS\", 16)            # TabPFN estimators\n",
    "TABPFN_MAX     = globals().get(\"TABPFN_MAX\", 10000)            # Max TabPFN samples\n",
    "\n",
    "# getML engine state\n",
    "_ENGINE_STARTED = False\n",
    "\n",
    "# Optional: quiet Featuretools logs\n",
    "ft.config.log_print_threshold = 1000000"
   ],
   "id": "c5959e09ecd4c20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Featuretools knobs (safe defaults)",
   "id": "4c5b68b64b21e661"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.271681Z",
     "start_time": "2025-08-21T15:18:40.269530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Featuretools knobs (stable across datasets) ----\n",
    "FT_MAX_DEPTH = globals().get(\"FT_MAX_DEPTH\", 2)\n",
    "\n",
    "# Desired primitives (resolved at runtime to what your FT version supports)\n",
    "FT_AGG_PRIMITIVES_WISHLIST = [\"mean\", \"sum\", \"count\", \"n_unique\", \"max\", \"min\", \"std\", \"mode\"]\n",
    "FT_TRANS_PRIMITIVES_WISHLIST = [\"day\", \"month\", \"year\", \"weekday\", \"hour\"]\n",
    "\n",
    "# Drop raw join keys from model inputs (to avoid trivial leakage)\n",
    "DROP_JOIN_KEYS_FROM_X = globals().get(\"DROP_JOIN_KEYS_FROM_X\", True)\n",
    "\n",
    "# ---- Generic PK/FK inference thresholds ----\n",
    "PK_MIN_UNIQUE_RATIO = globals().get(\"PK_MIN_UNIQUE_RATIO\", 0.98)        # exclude constant-ish columns in PK\n",
    "PK_MAX_NULL_RATIO   = globals().get(\"PK_MAX_NULL_RATIO\", 0.02)          # exclude columns with too many nulls\n",
    "FK_COVERAGE_THRESHOLD = globals().get(\"FK_COVERAGE_THRESHOLD\", 0.90)    # minimum referential coverage for FKs\n",
    "FK_MIN_UNIQUE_RATIO = globals().get(\"FK_MIN_UNIQUE_RATIO\", 0.01)        # exclude constant-ish columns in FK\n",
    "FK_MAX_UNIQUE_RATIO = globals().get(\"FK_MAX_UNIQUE_RATIO\", 0.95)        # exclude near-unique -> likely not an FK\n",
    "KEY_NAME_BONUS = globals().get(\"KEY_NAME_BONUS\", 0.05)\n",
    "\n",
    "# Name hint boost: helps columns that *look* like keys to win ties\n",
    "KEY_NAME_BONUS = globals().get(\"KEY_NAME_BONUS\", 0.05)\n"
   ],
   "id": "701d9b49628bf0e9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook Configuration and Dataset Selection\n",
    "\n",
    "\n",
    "Sets the dataset name (`DATASET`) and download flag (`DOWNLOAD`), then discovers all available tasks for the selected dataset using RelBench’s APIs. Filters tasks to only those compatible with TabPFN (classification and regression).\n"
   ],
   "id": "a86eaa89573fdf63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.282728Z",
     "start_time": "2025-08-21T15:18:40.280182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reuse existing config if present, otherwise set defaults\n",
    "DATASET = globals().get(\"DATASET\", \"rel-f1\")\n",
    "DOWNLOAD = globals().get(\"DOWNLOAD\", True)\n",
    "\n",
    "# Discover tasks and keep only entity-level cls/reg tasks TabPFN can handle\n",
    "def _is_tabpfn_friendly(task):\n",
    "    \"\"\"\n",
    "    Check if a task is compatible with TabPFN.\n",
    "    \"\"\"\n",
    "    return task.task_type in (\n",
    "        TaskType.BINARY_CLASSIFICATION,\n",
    "        TaskType.MULTICLASS_CLASSIFICATION,\n",
    "        TaskType.MULTILABEL_CLASSIFICATION,\n",
    "        TaskType.REGRESSION,\n",
    "    )\n",
    "\n",
    "_all = get_task_names(DATASET)  # shown in tutorials\n",
    "TASKS = []\n",
    "for tname in _all:\n",
    "    try:\n",
    "        t = get_task(DATASET, tname, download=DOWNLOAD)\n",
    "        if _is_tabpfn_friendly(t):\n",
    "            TASKS.append(tname)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {tname}: {e!s}\")\n",
    "\n",
    "print(f\"{DATASET}: {len(TASKS)} TabPFN-friendly tasks -> {TASKS}\")\n"
   ],
   "id": "d94075cf88bf6806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel-f1: 3 TabPFN-friendly tasks -> ['driver-position', 'driver-dnf', 'driver-top3']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Patch RelBench Metrics (Optional)",
   "id": "affc15acb6a0f8aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.294059Z",
     "start_time": "2025-08-21T15:18:40.292308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    \"\"\"\n",
    "    Compute RMSE using sklearn's mean_squared_error.\n",
    "    \"\"\"\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fetch Dataset Splits\n",
    "\n",
    "Utility functions to load a task’s splits (`train`, `val`, `test`), convert them to pandas DataFrames, and extract features (`X`) and targets (`y`). Includes functions to:\n",
    "* Load train/val/test splits for a task.\n",
    "* Extract features/targets.\n",
    "* Infer primary keys.\n",
    "* Denormalize tables (one-hop join).\n",
    "* Build data frames for both single-table and merged-table scenarios.\n"
   ],
   "id": "1a35d633effdd263"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset loaders / frame builders",
   "id": "4887e13ee3e11db1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.305842Z",
     "start_time": "2025-08-21T15:18:40.303389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_splits(dataset_name: str, task_name: str, download: bool = True):\n",
    "    \"\"\"\n",
    "    Fetch train/val/test splits for a given dataset and task.\n",
    "    \"\"\"\n",
    "    task = get_task(dataset_name, task_name, download=download)\n",
    "    # keep original columns (mask_input_cols=False so we see raw fields)\n",
    "    splits = {\n",
    "        split: task.get_table(split, mask_input_cols=False)\n",
    "        for split in (\"train\", \"val\", \"test\")\n",
    "    }\n",
    "    return task, splits\n",
    "\n",
    "def to_Xy(df: pd.DataFrame, target_col: str):\n",
    "    y = df[target_col].to_numpy()\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y\n",
    "\n",
    "def build_single_table_frames(task, splits):\n",
    "    \"\"\"\n",
    "    Single-table mode: do NOT engineer features here.\n",
    "    Just return raw base table X, y per split (target dropped from X).\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "\n",
    "    for split, table in splits.items():\n",
    "        df = table.df.copy()\n",
    "\n",
    "        if task.target_col not in df.columns:\n",
    "            raise ValueError(f\"Target column '{task.target_col}' not found in table '{df.name}'\")\n",
    "\n",
    "        X, y = to_Xy(df, task.target_col)\n",
    "        frames[split] = (X, y, df)\n",
    "    return frames\n"
   ],
   "id": "ac5f4a739cba0093",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Featuretools helpers: dtype cleanup, PK/FK inference, ES builders",
   "id": "27fbf5f3011bd7f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.318944Z",
     "start_time": "2025-08-21T15:18:40.316678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _normalize_name(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a string to a lowercase alphanumeric representation.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-z0-9]', '', str(s).lower())\n",
    "\n",
    "def _name_matches_pk(child_col: str, parent_pk: str) -> bool:\n",
    "    \"\"\"\n",
    "    Require that child column name matches parent PK name (normalized).\n",
    "    \"\"\"\n",
    "    return _normalize_name(child_col) == _normalize_name(parent_pk)\n",
    "\n",
    "def _dtype_category(dt) -> str:\n",
    "    \"\"\"\n",
    "    Determine the category of a pandas dtype.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pandas.api.types as pat\n",
    "        if pat.is_datetime64_any_dtype(dt): return \"dt\"\n",
    "        if pat.is_integer_dtype(dt) or pat.is_bool_dtype(dt): return \"int\"\n",
    "        if pat.is_float_dtype(dt): return \"float\"\n",
    "        if pat.is_string_dtype(dt) or dt == object: return \"str\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"other\"\n",
    "\n",
    "def _dtype_compatible(dt_parent, dt_child) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if two dtypes are compatible for PK/FK relationships.\n",
    "    \"\"\"\n",
    "    a, b = _dtype_category(dt_parent), _dtype_category(dt_child)\n",
    "    # keys should be int↔int or str↔str; allow bool as int\n",
    "    if a == \"int\" and b == \"int\": return True\n",
    "    if a == \"str\" and b == \"str\": return True\n",
    "    return False"
   ],
   "id": "aa39b143967388db",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Featuretools helpers: robust, dataset-agnostic",
   "id": "d2a611da17e857b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.341209Z",
     "start_time": "2025-08-21T15:18:40.326190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _clean_for_ft(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dtype cleanup for Featuretools:\n",
    "      - convert object/string columns to categorical,\n",
    "      - parse datetime-like columns,\n",
    "      - ensure no mixed dtypes in columns.\n",
    "    \"\"\"\n",
    "    x = df.copy()\n",
    "    # parse only strong time-like names\n",
    "    for c in x.columns:\n",
    "        if _looks_like_time_name(c) and not pd.api.types.is_datetime64_any_dtype(x[c]):\n",
    "            try:\n",
    "                parsed = pd.to_datetime(x[c], errors=\"coerce\")\n",
    "                if parsed.notna().sum() > 0 and parsed.nunique(dropna=True) > 1:\n",
    "                    x[c] = parsed\n",
    "            except Exception:\n",
    "                pass\n",
    "    return x\n",
    "\n",
    "def _is_key_like(colname: str) -> bool:\n",
    "    \"\"\"\n",
    "    key-like name detection:\n",
    "      - ends with _id, id, _key, key (case-insensitive),\n",
    "      - ends with ID or Id (case-sensitive).\n",
    "    \"\"\"\n",
    "    s = str(colname)\n",
    "    sl = s.lower()\n",
    "    return (\n",
    "        sl.endswith(\"_id\") or sl.endswith(\"id\") or\n",
    "        sl.endswith(\"_key\") or sl.endswith(\"key\") or\n",
    "        s.endswith(\"ID\") or s.endswith(\"Id\")\n",
    "    )\n",
    "\n",
    "def _score_pk(series: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    PK score based on uniqueness and null ratio\n",
    "    \"\"\"\n",
    "    n = len(series)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    nunq = series.nunique(dropna=True)\n",
    "    null_ratio = 1.0 - series.notna().mean()\n",
    "    unique_ratio = nunq / max(1, n)\n",
    "    score = unique_ratio - null_ratio  # prefer unique, penalize nulls\n",
    "    if _is_key_like(series.name):\n",
    "        score += KEY_NAME_BONUS\n",
    "    return float(score)\n",
    "\n",
    "def _candidate_pk(df: pd.DataFrame) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Candidate primary key detection\n",
    "    \"\"\"\n",
    "    best_col, best_score = None, -1.0\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        # quick skip for obvious non-keys\n",
    "        if pd.api.types.is_float_dtype(s) and not pd.api.types.is_integer_dtype(s):\n",
    "            # allow floats only if they look like ints after dropna\n",
    "            if not np.allclose(s.dropna() % 1, 0):\n",
    "                continue\n",
    "        sc = _score_pk(s)\n",
    "        if sc > best_score:\n",
    "            best_col, best_score = c, sc\n",
    "    # require thresholds\n",
    "    if best_col is None:\n",
    "        return None\n",
    "    s = df[best_col]\n",
    "    nunq = s.nunique(dropna=True)\n",
    "    n = len(s)\n",
    "    null_ratio = 1.0 - s.notna().mean()\n",
    "    if (nunq / max(1, n) >= PK_MIN_UNIQUE_RATIO) and (null_ratio <= PK_MAX_NULL_RATIO):\n",
    "        return best_col\n",
    "    return None\n",
    "\n",
    "# ---------- Time detection (strict; never equals PK) ----------\n",
    "_TIME_NAME_PATTERN = re.compile(\n",
    "    r\"(^|[_])(\"\n",
    "    r\"timestamp|datetime|event_time|eventtime|time|date|dt|\"\n",
    "    r\"created_at|updated_at|inserted_at|occurred_at|recorded_at\"\n",
    "    r\")([_]|$)\", re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def _looks_like_time_name(colname: str) -> bool:\n",
    "    \"\"\"\n",
    "    Time-like name detection\n",
    "    \"\"\"\n",
    "    name = str(colname)\n",
    "    if name.lower() == \"ts\" or name.lower().startswith(\"ts_\") or name.lower().endswith(\"_ts\"):\n",
    "        return True\n",
    "    return _TIME_NAME_PATTERN.search(name) is not None\n",
    "\n",
    "def _detect_time_col(df: pd.DataFrame, pk: Optional[str] = None) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to detect a time-like column in the DataFrame.\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        if c == pk:\n",
    "            continue\n",
    "        if not _looks_like_time_name(c):\n",
    "            continue\n",
    "        s = df[c]\n",
    "        if not pd.api.types.is_datetime64_any_dtype(s):\n",
    "            try:\n",
    "                s = pd.to_datetime(s, errors=\"coerce\")\n",
    "            except Exception:\n",
    "                continue\n",
    "        if s.notna().sum() > 0 and s.nunique(dropna=True) > 1:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# ---------- PK/FK inference across all tables (incl. MAIN_TABLE) ----------\n",
    "def _infer_pk_fk_graph_auto(all_tables: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Schema-agnostic PK/FK inference with strict name+dtype gating:\n",
    "      - pick single-column PK by uniqueness/nulls (+name hint),\n",
    "      - propose FKs only when child column NAME == parent PK NAME (normalized),\n",
    "      - require dtype compatibility, not-near-unique child, and high referential coverage,\n",
    "      - forbid child's own PK as FK; forbid self-relationships.\n",
    "    \"\"\"\n",
    "    # 1) PKs\n",
    "    pkeys: Dict[str, Optional[str]] = {}\n",
    "    for tname, df in all_tables.items():\n",
    "        pkeys[tname] = _candidate_pk(df)\n",
    "\n",
    "    # 2) parent PK value sets + dtypes\n",
    "    parent_values: Dict[str, set] = {}\n",
    "    parent_pk_dtype: Dict[str, Any] = {}\n",
    "    for parent, pk in pkeys.items():\n",
    "        if pk and pk in all_tables[parent].columns:\n",
    "            parent_pk_dtype[parent] = all_tables[parent][pk].dtype\n",
    "            vals = pd.Series(all_tables[parent][pk]).dropna().astype(str).unique()\n",
    "            if len(vals) > 0:\n",
    "                parent_values[parent] = set(vals.tolist())\n",
    "\n",
    "    # 3) scan child tables for key-like columns that *name-match* a parent PK\n",
    "    fkeys: Dict[str, List[Dict[str, Any]]] = {parent: [] for parent in all_tables.keys()}\n",
    "    reasons: List[str] = []\n",
    "\n",
    "    for child, cdf in all_tables.items():\n",
    "        child_pk = pkeys.get(child)\n",
    "        for parent, pk in pkeys.items():\n",
    "            if not pk:\n",
    "                continue\n",
    "            if parent == child:\n",
    "                continue\n",
    "            if parent not in parent_values:\n",
    "                continue\n",
    "\n",
    "            # candidate child columns whose NAME matches the parent's PK\n",
    "            for col in cdf.columns:\n",
    "                if col == child_pk:\n",
    "                    continue\n",
    "                if not _name_matches_pk(col, pk):\n",
    "                    continue\n",
    "                # dtype compatibility\n",
    "                if not _dtype_compatible(parent_pk_dtype.get(parent, None), cdf[col].dtype):\n",
    "                    continue\n",
    "                # child column cardinality constraints (many-to-one)\n",
    "                s = cdf[col].dropna()\n",
    "                if s.empty:\n",
    "                    continue\n",
    "                nunq = s.nunique(dropna=True)\n",
    "                uniq_ratio = nunq / max(1, len(s))\n",
    "                if uniq_ratio < FK_MIN_UNIQUE_RATIO or uniq_ratio > FK_MAX_UNIQUE_RATIO:\n",
    "                    continue\n",
    "                # referential coverage check\n",
    "                coverage = (s.astype(str).isin(pd.Series(list(parent_values[parent])))).mean()\n",
    "                if coverage >= FK_COVERAGE_THRESHOLD:\n",
    "                    lst = fkeys.setdefault(parent, [])\n",
    "                    if not any(r[\"child\"] == child and r[\"fk\"] == col for r in lst):\n",
    "                        lst.append({\"child\": child, \"fk\": col, \"coverage\": float(coverage)})\n",
    "                        reasons.append(f\"{parent}.{pk} <- {child}.{col} (coverage={coverage:.3f})\")\n",
    "\n",
    "    return {\"pkeys\": pkeys, \"fkeys\": fkeys, \"debug\": {\"reasons\": reasons}}\n",
    "\n",
    "\n",
    "def _prune_fk_cycles(schema: Dict[str, Dict[str, Any]], base_name: str) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Remove edges that introduce cycles. Preference:\n",
    "      - keep edges incident to the MAIN_TABLE (base_name),\n",
    "      - keep edges with higher coverage,\n",
    "      - drop the weakest edge per detected cycle.\n",
    "    \"\"\"\n",
    "    pkeys = schema[\"pkeys\"]\n",
    "    fkeys = {k: list(v) for k, v in schema[\"fkeys\"].items()}\n",
    "\n",
    "    def edges():\n",
    "        for parent, rels in fkeys.items():\n",
    "            for r in rels:\n",
    "                yield (parent, r[\"child\"], r)\n",
    "\n",
    "    # build adjacency\n",
    "    def build_adj():\n",
    "        adj = {}\n",
    "        for u, v, r in edges():\n",
    "            adj.setdefault(u, []).append((v, r))\n",
    "        return adj\n",
    "\n",
    "    # cycle detection via DFS\n",
    "    def find_cycle():\n",
    "        adj = build_adj()\n",
    "        visited, stack = {}, []\n",
    "        def dfs(u):\n",
    "            visited[u] = 1\n",
    "            stack.append(u)\n",
    "            for v, r in adj.get(u, []):\n",
    "                if visited.get(v, 0) == 0:\n",
    "                    cyc = dfs(v)\n",
    "                    if cyc: return cyc\n",
    "                elif visited.get(v, 0) == 1:\n",
    "                    # cycle found: collect path u->...->v\n",
    "                    if v in stack:\n",
    "                        i = stack.index(v)\n",
    "                        cyc_nodes = stack[i:] + [v]\n",
    "                        cyc_edges = []\n",
    "                        # collect edges on this cycle\n",
    "                        for a, b in zip(cyc_nodes, cyc_nodes[1:]):\n",
    "                            # find the relationship object\n",
    "                            rel = None\n",
    "                            for nb, r2 in adj.get(a, []):\n",
    "                                if nb == b:\n",
    "                                    rel = r2; break\n",
    "                            if rel: cyc_edges.append((a, b, rel))\n",
    "                        return cyc_edges\n",
    "            stack.pop()\n",
    "            visited[u] = 2\n",
    "            return None\n",
    "\n",
    "        for u in set(list(pkeys.keys()) + [base_name]):\n",
    "            if visited.get(u, 0) == 0:\n",
    "                cyc = dfs(u)\n",
    "                if cyc: return cyc\n",
    "        return None\n",
    "\n",
    "    # iteratively prune one weakest edge per cycle\n",
    "    removed = 0\n",
    "    while True:\n",
    "        cyc = find_cycle()\n",
    "        if not cyc:\n",
    "            break\n",
    "        # pick edge to drop: avoid dropping edges touching base_name if possible; lowest coverage wins\n",
    "        cand = []\n",
    "        for a, b, r in cyc:\n",
    "            score = r.get(\"coverage\", 0.0)\n",
    "            touches_base = int(a == base_name or b == base_name)\n",
    "            cand.append((touches_base, score, a, b, r))\n",
    "        # sort: prefer removing edges NOT touching base_name, and with lowest coverage\n",
    "        cand.sort(key=lambda x: (x[0], x[1]))\n",
    "        _, _, a, b, r = cand[0]\n",
    "        # remove\n",
    "        fkeys[a] = [x for x in fkeys.get(a, []) if not (x[\"child\"] == b and x[\"fk\"] == r[\"fk\"])]\n",
    "        removed += 1\n",
    "    if removed:\n",
    "        print(f\"[Schema] Pruned {removed} cyclic relationship(s)\")\n",
    "    return {\"pkeys\": pkeys, \"fkeys\": fkeys, \"debug\": schema.get(\"debug\", {})}\n",
    "\n",
    "\n",
    "\n",
    "# ---------- EntitySet builder (safe: never pk==time_index) ----------\n",
    "def _make_es_for_split(base_name: str,\n",
    "                       pop_df: pd.DataFrame,\n",
    "                       all_tables: Dict[str, pd.DataFrame],\n",
    "                       schema: Dict[str, Dict[str, Any]]) -> ft.EntitySet:\n",
    "    \"\"\"\n",
    "    Extract a Featuretools EntitySet from the given base table and all related tables.\n",
    "    \"\"\"\n",
    "    es = ft.EntitySet(id=f\"rb_es_{base_name}\")\n",
    "\n",
    "    def _add_df_safe(es_obj, name, df, pk_candidate):\n",
    "        df = _clean_for_ft(df)\n",
    "        # index\n",
    "        if pk_candidate is None or pk_candidate not in df.columns:\n",
    "            idx = f\"{name}__ft_index\"; make_idx = True\n",
    "        else:\n",
    "            idx = pk_candidate; make_idx = False\n",
    "        # time index\n",
    "        tcol = _detect_time_col(df, pk=idx)\n",
    "        if tcol is not None and tcol == idx:\n",
    "            tcol = None\n",
    "        if tcol is not None and not pd.api.types.is_datetime64_any_dtype(df[tcol]):\n",
    "            tcol = None\n",
    "\n",
    "        if make_idx:\n",
    "            return es_obj.add_dataframe(dataframe_name=name, dataframe=df, index=idx, make_index=True, time_index=tcol), idx\n",
    "        else:\n",
    "            return es_obj.add_dataframe(dataframe_name=name, dataframe=df, index=idx, time_index=tcol), idx\n",
    "\n",
    "    # add MAIN_TABLE\n",
    "    pop_pk = schema[\"pkeys\"].get(base_name)\n",
    "    es, pop_idx = _add_df_safe(es, base_name, pop_df, pop_pk)\n",
    "\n",
    "    # add other tables\n",
    "    for tname, df in all_tables.items():\n",
    "        if tname == base_name:\n",
    "            continue\n",
    "        pk = schema[\"pkeys\"].get(tname)\n",
    "        es, _ = _add_df_safe(es, tname, df, pk)\n",
    "\n",
    "    # relationships (parent: one, child: many; FK lives on child)\n",
    "    rel_added, rel_skipped = 0, 0\n",
    "    for parent, rels in schema[\"fkeys\"].items():\n",
    "        if parent not in es.dataframe_dict:\n",
    "            continue\n",
    "        parent_pk = schema[\"pkeys\"].get(parent) or f\"{parent}__ft_index\"\n",
    "        for r in rels:\n",
    "            child = r[\"child\"]; fk = r[\"fk\"]\n",
    "            if child not in es.dataframe_dict:\n",
    "                rel_skipped += 1; continue\n",
    "            child_idx = es[child].ww.index\n",
    "            # Skip if FK column is the child's index (illegal in FT) or missing\n",
    "            if fk == child_idx or fk not in es[child].ww.columns:\n",
    "                rel_skipped += 1; continue\n",
    "            es = es.add_relationship(parent_dataframe_name=parent,\n",
    "                                     parent_column_name=parent_pk,\n",
    "                                     child_dataframe_name=child,\n",
    "                                     child_column_name=fk)\n",
    "            rel_added += 1\n",
    "\n",
    "    return es\n",
    "\n",
    "# ---------- Primitive resolver (version-agnostic) ----------\n",
    "def _resolve_ft_primitives(agg_wishlist: list, trans_wishlist: list) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Resolve Featuretools primitives based on wishlist and available primitives.\n",
    "    \"\"\"\n",
    "    prim_df = ft.primitives.list_primitives()\n",
    "    have_agg = set(prim_df[prim_df.type == \"aggregation\"].name.str.lower())\n",
    "    have_trans = set(prim_df[prim_df.type == \"transform\"].name.str.lower())\n",
    "\n",
    "    alias_groups_agg = [\n",
    "        {\"n_unique\", \"nunique\", \"num_unique\", \"count_unique\"},\n",
    "        {\"mode\", \"mode_agg\"},\n",
    "        {\"std\", \"standard_deviation\"},\n",
    "        {\"count\"}\n",
    "    ]\n",
    "    alias_groups_trans = [\n",
    "        {\"weekday\", \"week_day\"},\n",
    "        {\"year\"}, {\"month\"}, {\"day\"}, {\"hour\"}\n",
    "    ]\n",
    "    def pick(wish, have, groups):\n",
    "        out = []\n",
    "        for w in [w.lower() for w in wish]:\n",
    "            if w in have:\n",
    "                out.append(w); continue\n",
    "            matched = False\n",
    "            for g in groups:\n",
    "                if w in g:\n",
    "                    for cand in g:\n",
    "                        if cand in have:\n",
    "                            out.append(cand); matched = True; break\n",
    "                if matched: break\n",
    "        # ensure some basics\n",
    "        if not out and have:\n",
    "            for fb in [\"mean\", \"sum\", \"count\", \"max\", \"min\"]:\n",
    "                if fb in have: out.append(fb)\n",
    "        # dedupe\n",
    "        seen, uniq = set(), []\n",
    "        for p in out:\n",
    "            if p not in seen: seen.add(p); uniq.append(p)\n",
    "        return uniq\n",
    "    return pick(agg_wishlist, have_agg, alias_groups_agg), pick(trans_wishlist, have_trans, alias_groups_trans)\n",
    "\n",
    "# ---------- DFS (train -> reuse on val/test) ----------\n",
    "def _dfs_feature_matrices(es_train: ft.EntitySet,\n",
    "                          es_val: ft.EntitySet,\n",
    "                          es_test: ft.EntitySet,\n",
    "                          target_df: str):\n",
    "    \"\"\"\n",
    "    Run Featuretools DFS on the training EntitySet and reuse the feature definitions on validation and test sets.\n",
    "    \"\"\"\n",
    "    agg_prims, trans_prims = _resolve_ft_primitives(FT_AGG_PRIMITIVES_WISHLIST, FT_TRANS_PRIMITIVES_WISHLIST)\n",
    "\n",
    "    fm_train, fdefs = ft.dfs(\n",
    "        entityset=es_train,\n",
    "        target_dataframe_name=target_df,\n",
    "        agg_primitives=agg_prims,\n",
    "        trans_primitives=trans_prims,\n",
    "        max_depth=FT_MAX_DEPTH,\n",
    "        features_only=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    fm_val = ft.calculate_feature_matrix(features=fdefs, entityset=es_val, verbose=False)\n",
    "    fm_test = ft.calculate_feature_matrix(features=fdefs, entityset=es_test, verbose=False)\n",
    "\n",
    "    # align columns\n",
    "    fm_val = fm_val.reindex(columns=fm_train.columns, fill_value=np.nan)\n",
    "    fm_test = fm_test.reindex(columns=fm_train.columns, fill_value=np.nan)\n",
    "\n",
    "    return fm_train, fm_val, fm_test, fdefs\n"
   ],
   "id": "32f1a606727db779",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Merged-Table Frames",
   "id": "48d1dac2d154369a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.351689Z",
     "start_time": "2025-08-21T15:18:40.347567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_merged_table_frames(dataset, task, splits):\n",
    "    \"\"\"\n",
    "    Generic merged features with Featuretools:\n",
    "    - load ALL tables as pandas,\n",
    "    - include TRAIN MAIN_TABLE table in PK/FK inference,\n",
    "    - infer PK/FK graph automatically (unique ratio + coverage),\n",
    "    - build EntitySet per split,\n",
    "    - DFS on train, reuse features on val/test,\n",
    "    - drop join keys from X and never include target in X,\n",
    "    - return dict with (X, y, engineered_df) per split.\n",
    "    \"\"\"\n",
    "    # --- Load DB tables (pandas) ---\n",
    "    db = dataset.get_db()\n",
    "    all_tables: Dict[str, pd.DataFrame] = {\n",
    "        name: (tbl.df.copy() if hasattr(tbl, \"df\") else tbl.to_pandas())\n",
    "        for name, tbl in db.table_dict.items()\n",
    "    }\n",
    "    all_tables = {k: _clean_for_ft(v) for k, v in all_tables.items()}\n",
    "\n",
    "    base_name = getattr(splits[\"train\"], \"name\", MAIN_TABLE)\n",
    "    # include MAIN_TABLE (TRAIN) into inference so relations can touch the target df\n",
    "    pop = {split: tbl.df.copy() for split, tbl in splits.items()}\n",
    "    combined_for_schema = dict(all_tables)\n",
    "    combined_for_schema[base_name] = _clean_for_ft(pop[\"train\"].copy())\n",
    "\n",
    "    # --- Automatic PK/FK inference (no manual schema) ---\n",
    "    schema = _infer_pk_fk_graph_auto(combined_for_schema)\n",
    "    reasons = schema.get(\"debug\", {}).get(\"reasons\", [])\n",
    "    print(f\"[Schema] inferred={len(reasons)} examples:\", reasons[:8])\n",
    "\n",
    "    # --- Prune cycles to prevent DFS recursion ---\n",
    "    schema = _prune_fk_cycles(schema, base_name=base_name)\n",
    "\n",
    "    if schema.get(\"debug\", {}).get(\"reasons\"):\n",
    "        print(\"[Schema] inferred relationships (sample):\", schema[\"debug\"][\"reasons\"][:10])\n",
    "    else:\n",
    "        print(\"[Schema] WARNING: no relationships inferred. Consider lowering FK_COVERAGE_THRESHOLD.\")\n",
    "\n",
    "    # --- Build ES per split with the same schema ---\n",
    "    es_train = _make_es_for_split(base_name, pop[\"train\"], all_tables, schema)\n",
    "    es_val   = _make_es_for_split(base_name, pop[\"val\"],   all_tables, schema)\n",
    "    es_test  = _make_es_for_split(base_name, pop[\"test\"],  all_tables, schema)\n",
    "\n",
    "    # --- DFS and aligned feature matrices ---\n",
    "    fe_train, fe_val, fe_test, feature_defs = _dfs_feature_matrices(es_train, es_val, es_test, target_df=base_name)\n",
    "\n",
    "    # --- Prepare (X, y) and drop keys/target from X ---\n",
    "    def _drop_keys(dfX: pd.DataFrame) -> pd.DataFrame:\n",
    "        if not DROP_JOIN_KEYS_FROM_X:\n",
    "            return dfX\n",
    "        drop_cols = set()\n",
    "        pop_pk = schema[\"pkeys\"].get(base_name)\n",
    "        if pop_pk and pop_pk in dfX.columns:\n",
    "            drop_cols.add(pop_pk)\n",
    "        for parent, rels in schema[\"fkeys\"].items():\n",
    "            for r in rels:\n",
    "                fk = r[\"fk\"]\n",
    "                if fk in dfX.columns:\n",
    "                    drop_cols.add(fk)\n",
    "        return dfX.drop(columns=list(drop_cols), errors=\"ignore\")\n",
    "\n",
    "    def _to_Xy(fe_df: pd.DataFrame, raw_df: pd.DataFrame):\n",
    "        X = fe_df.copy()\n",
    "        if task.target_col in X.columns:\n",
    "            X = X.drop(columns=[task.target_col], errors=\"ignore\")\n",
    "        X = _drop_keys(X)\n",
    "        y = raw_df[task.target_col].to_numpy()\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = _to_Xy(fe_train, pop[\"train\"])\n",
    "    Xva, yva = _to_Xy(fe_val,   pop[\"val\"])\n",
    "    Xte, yte = _to_Xy(fe_test,  pop[\"test\"])\n",
    "\n",
    "    return {\n",
    "        \"train\": (Xtr, ytr, fe_train),\n",
    "        \"val\":   (Xva, yva, fe_val),\n",
    "        \"test\":  (Xte, yte, fe_test),\n",
    "    }\n"
   ],
   "id": "1e53fa004c6c4217",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merged-mode diagnostics",
   "id": "83f90a0a78a37210"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.361491Z",
     "start_time": "2025-08-21T15:18:40.358714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Diagnostics: single vs merged feature spaces --------\n",
    "def compare_single_vs_merged(di_single, di_merged, target_name: str, label=\"train\"):\n",
    "    Xs, ys, df_s = di_single[label]\n",
    "    Xm, ym, df_m = di_merged[label]\n",
    "\n",
    "    print(f\"[Diag:{label}] X_single: {Xs.shape}, X_merged: {Xm.shape}\")\n",
    "    print(f\"[Diag:{label}] y match: {np.allclose(ys, ym)}\")\n",
    "\n",
    "    # columns present only in merged\n",
    "    only_m = [c for c in Xm.columns if c not in Xs.columns]\n",
    "    only_s = [c for c in Xs.columns if c not in Xm.columns]\n",
    "    print(f\"[Diag:{label}] new cols in merged: {len(only_m)} ; dropped vs merged: {len(only_s)}\")\n",
    "\n",
    "    # low-variance check on merged-only columns\n",
    "    if only_m:\n",
    "        lv = Xm[only_m].nunique(dropna=True)\n",
    "        print(f\"[Diag:{label}] merged-only columns nunique (head):\")\n",
    "        print(lv.sort_values().head(10))\n",
    "\n",
    "    try:\n",
    "        from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "        y = ys\n",
    "        # pick MI type by y dtype\n",
    "        if pd.api.types.is_integer_dtype(y) or pd.api.types.is_bool_dtype(y):\n",
    "            mi_fun = mutual_info_classif\n",
    "        else:\n",
    "            mi_fun = mutual_info_regression\n",
    "\n",
    "        # compute MI for up to 200 merged-only cols to keep it fast\n",
    "        subset = only_m[:200]\n",
    "        if subset:\n",
    "            mi = mi_fun(pd.DataFrame(Xm[subset]).fillna(0), y, discrete_features='auto', random_state=0)\n",
    "            mi_s = pd.Series(mi, index=subset).sort_values(ascending=False)\n",
    "            print(f\"[Diag:{label}] top merged-only MI features:\")\n",
    "            print(mi_s.head(10))\n",
    "        else:\n",
    "            print(f\"[Diag:{label}] no merged-only columns to test MI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Diag:{label}] MI calc skipped: {e}\")\n"
   ],
   "id": "99a94738a0272101",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorization Wrapper (Version-Safe)\n",
    "\n",
    "Initializes a `TableVectorizer` with only supported arguments for the installed `skrub` or `dirty_cat` version, ensuring compatibility. Transforms `train`, `val`, and `test` splits into numerical feature matrices, converting them to dense format if necessary.\n"
   ],
   "id": "f7cf59b1861625f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper Functions for Vectorization",
   "id": "ff99875cd0db904d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.370992Z",
     "start_time": "2025-08-21T15:18:40.368344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _make_table_vectorizer():\n",
    "    \"\"\"\n",
    "    Create a TableVectorizer with version-safe arguments.\n",
    "    \"\"\"\n",
    "    sig = inspect.signature(TableVectorizer.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    tv_kwargs = {}\n",
    "\n",
    "    # Only set kwargs that actually exist in the installed version\n",
    "    if \"cardinality_threshold\" in allowed:\n",
    "        tv_kwargs[\"cardinality_threshold\"] = globals().get(\"CARDINALITY_THRESHOLD\", 1000)\n",
    "\n",
    "    # Some versions expose this; others don't, guard it\n",
    "    if \"high_cardinality_transformer\" in allowed:\n",
    "        tv_kwargs[\"high_cardinality_transformer\"] = globals().get(\"HIGH_CARD_TRANSFORMER\", \"hashing\")\n",
    "\n",
    "    # Optional knobs if you define them globally and the version supports them\n",
    "    if \"text_separator\" in allowed and \"TEXT_SEPARATOR\" in globals():\n",
    "        tv_kwargs[\"text_separator\"] = globals()[\"TEXT_SEPARATOR\"]\n",
    "    if \"numerical_transformer\" in allowed and \"NUMERICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"numerical_transformer\"] = globals()[\"NUMERICAL_TRANSFORMER\"]\n",
    "    if \"categorical_transformer\" in allowed and \"CATEGORICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"categorical_transformer\"] = globals()[\"CATEGORICAL_TRANSFORMER\"]\n",
    "\n",
    "    return TableVectorizer(**tv_kwargs)\n",
    "\n",
    "def _to_dense(X):\n",
    "    \"\"\"\n",
    "    Convert a sparse matrix to a dense NumPy array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # scipy sparse matrices have .toarray()\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "    except Exception:\n",
    "        return X\n",
    "\n",
    "def vectorize_splits(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Vectorize train, val, and test splits using a TableVectorizer.\n",
    "    \"\"\"\n",
    "    # Fit only on training data to prevent data leakage\n",
    "    tv = _make_table_vectorizer()\n",
    "    Xt = _to_dense(tv.fit_transform(X_train))\n",
    "    Xv = _to_dense(tv.transform(X_val))\n",
    "    Xs = _to_dense(tv.transform(X_test))\n",
    "    return tv, Xt, Xv, Xs\n"
   ],
   "id": "ffb43a27c3ac51cb",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and Prediction Helpers",
   "id": "e135f05177e4b188"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:40.380197Z",
     "start_time": "2025-08-21T15:18:40.377658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _subsample(X, y, cap=TABPFN_MAX, seed=SEED):\n",
    "    \"\"\"\n",
    "    Subsample the dataset to a maximum size defined by `cap`.\n",
    "    \"\"\"\n",
    "    if len(X) <= cap:\n",
    "        return X, y, np.arange(len(X))\n",
    "    idx = np.random.RandomState(seed).choice(len(X), size=cap, replace=False)\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        Xs = X.iloc[idx]\n",
    "    else:\n",
    "        Xs = X[idx]\n",
    "    ys = y[idx]\n",
    "    return Xs, ys, idx\n",
    "\n",
    "def _fit_tabpfn(task, Xt, yt):\n",
    "    \"\"\"\n",
    "    Fit a TabPFN model for the given task type.\n",
    "    \"\"\"\n",
    "    if task.task_type == TaskType.REGRESSION and TabPFNRegressor is not None:\n",
    "        model = TabPFNRegressor(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    else:\n",
    "        model = TabPFNClassifier(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    model.fit(Xt, yt)\n",
    "    return model\n",
    "\n",
    "def _predict_for_task(task, model, X):\n",
    "    \"\"\"\n",
    "    Make predictions using the fitted model for the given task type.\n",
    "    \"\"\"\n",
    "    # align with RelBench evaluators: AUROC expects probabilities for the positive class\n",
    "    if task.task_type == TaskType.REGRESSION:\n",
    "        return model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    if task.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "        return proba[:, 1]\n",
    "    else:\n",
    "        # multiclass/multilabel: pass full probability matrix\n",
    "        return proba"
   ],
   "id": "5c53f649ce01b948",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run TabPFN on Selected Tasks\n",
    "\n",
    "Runs TabPFN on a specified dataset and task, handling both single-table and merged-table modes. It vectorizes the data, fits the model, makes predictions, and evaluates performance using RelBench’s evaluators. Returns a dictionary with results."
   ],
   "id": "21448305df117a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:42.260710Z",
     "start_time": "2025-08-21T15:18:40.387283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = get_dataset(DATASET, download=DOWNLOAD)\n",
    "\n",
    "for task_name in TASKS:\n",
    "    task, splits = fetch_splits(DATASET, task_name, download=DOWNLOAD)\n",
    "\n",
    "    frames_single = build_single_table_frames(task, splits)\n",
    "    frames_merged = build_merged_table_frames(dataset, task, splits)\n",
    "\n",
    "    # Display head of train, val and test of frames_merged\n",
    "    # Show all column names and count for merged train split\n",
    "    merged_train_df = frames_merged[\"train\"][2]\n",
    "    print(\"Single-table (train) head:\")\n",
    "    print(frames_single[\"train\"][2].head(5))\n",
    "\n",
    "    print(\"\\nMerged-table (train) head:\")\n",
    "    print(frames_merged[\"train\"][2].head(5))\n",
    "\n",
    "\n",
    "    #compare_single_vs_merged(frames_single, frames_merged, target_name=task.target_col, label=\"train\")\n",
    "\n",
    "    # ---- Diagnostics: which columns are dropped vs kept? ----\n",
    "\n",
    "    def _cols_dropped_between(engineered_df: pd.DataFrame, X_after_drop: pd.DataFrame):\n",
    "        eng_cols = list(engineered_df.columns)\n",
    "        X_cols = list(X_after_drop.columns)\n",
    "        dropped = [c for c in eng_cols if c not in X_cols]\n",
    "        return dropped\n",
    "\n",
    "    def show_drop_report(frames_single, frames_merged):\n",
    "        print(\"=== SINGLE (train) ===\")\n",
    "        Xs, ys, df_s = frames_single[\"train\"]\n",
    "        dropped_s = _cols_dropped_between(df_s, Xs)\n",
    "        print(f\"Kept: {Xs.shape[1]} | Dropped: {len(dropped_s)}\")\n",
    "        if dropped_s:\n",
    "            print(\"Dropped columns (single):\", dropped_s[:50])  # cap for readability\n",
    "        else:\n",
    "            print(\"Dropped columns (single): []\")\n",
    "\n",
    "        print(\"\\n=== MERGED (train) ===\")\n",
    "        Xm, ym, df_m = frames_merged[\"train\"]\n",
    "        dropped_m = _cols_dropped_between(df_m, Xm)\n",
    "        print(f\"Kept: {Xm.shape[1]} | Dropped: {len(dropped_m)}\")\n",
    "        if dropped_m:\n",
    "            print(\"Dropped columns (merged):\", dropped_m[:50])\n",
    "        else:\n",
    "            print(\"Dropped columns (merged): []\")\n",
    "\n",
    "    # Call it once after both frames are built:\n",
    "    show_drop_report(frames_single, frames_merged)\n",
    "\n"
   ],
   "id": "1a124faf7a2ca60d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /Users/michaelflppv/Library/Caches/relbench/rel-f1/db...\n",
      "Done in 0.01 seconds.\n",
      "[Schema] inferred=10 examples: ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)']\n",
      "[Schema] inferred relationships (sample): ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)', 'races.raceId <- constructor_standings.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_standings.constructorId (coverage=1.000)']\n",
      "Single-table (train) head:\n",
      "        date  driverId  position\n",
      "0 2004-07-05        10     10.75\n",
      "1 2004-07-05        47     12.00\n",
      "2 2004-03-07         7     15.00\n",
      "3 2004-01-07        10      9.00\n",
      "4 2003-09-09        52     13.00\n",
      "\n",
      "Merged-table (train) head:\n",
      "                      driverId  position DAY(date) HOUR(date) MONTH(date)  \\\n",
      "qualifying__ft_index                                                        \n",
      "470                        579       1.0        19          0           6   \n",
      "1858                       589      15.0        19          0           6   \n",
      "1859                       704       8.0        19          0           6   \n",
      "2302                       786       2.0        19          0           6   \n",
      "2303                       687       3.0        19          0           6   \n",
      "\n",
      "                     WEEKDAY(date) YEAR(date) drivers.code  \\\n",
      "qualifying__ft_index                                         \n",
      "470                              0       1950           \\N   \n",
      "1858                             0       1950           \\N   \n",
      "1859                             0       1950           \\N   \n",
      "2302                             0       1950           \\N   \n",
      "2303                             0       1950           \\N   \n",
      "\n",
      "                     drivers.nationality  drivers.COUNT(qualifying)  ...  \\\n",
      "qualifying__ft_index                                                 ...   \n",
      "470                            Argentine                         26  ...   \n",
      "1858                          Monegasque                         11  ...   \n",
      "1859                              French                          8  ...   \n",
      "2302                             Italian                          3  ...   \n",
      "2303                             British                          9  ...   \n",
      "\n",
      "                      drivers.STD(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "470                                          9.274960   \n",
      "1858                                        23.898896   \n",
      "1859                                        17.332532   \n",
      "2302                                         3.938928   \n",
      "2303                                        22.738216   \n",
      "\n",
      "                      drivers.STD(standings.wins)  \\\n",
      "qualifying__ft_index                                \n",
      "470                                      1.556562   \n",
      "1858                                     0.000000   \n",
      "1859                                     0.000000   \n",
      "2302                                     0.514929   \n",
      "2303                                     0.000000   \n",
      "\n",
      "                      drivers.SUM(standings.points)  \\\n",
      "qualifying__ft_index                                  \n",
      "470                                         1131.28   \n",
      "1858                                          24.00   \n",
      "1859                                          33.00   \n",
      "2302                                         116.00   \n",
      "2303                                           8.00   \n",
      "\n",
      "                      drivers.SUM(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "470                                             350.0   \n",
      "1858                                           1610.0   \n",
      "1859                                            680.0   \n",
      "2302                                             68.0   \n",
      "2303                                           1296.0   \n",
      "\n",
      "                      drivers.SUM(standings.wins)  drivers.DAY(dob)  \\\n",
      "qualifying__ft_index                                                  \n",
      "470                                         108.0                24   \n",
      "1858                                          0.0                 3   \n",
      "1859                                          0.0                 8   \n",
      "2302                                          5.0                 9   \n",
      "2303                                          0.0                12   \n",
      "\n",
      "                      drivers.HOUR(dob)  drivers.MONTH(dob)  \\\n",
      "qualifying__ft_index                                          \n",
      "470                                   0                   6   \n",
      "1858                                  0                   8   \n",
      "1859                                  0                  10   \n",
      "2302                                  0                   6   \n",
      "2303                                  0                  11   \n",
      "\n",
      "                      drivers.WEEKDAY(dob)  drivers.YEAR(dob)  \n",
      "qualifying__ft_index                                           \n",
      "470                                      5               1911  \n",
      "1858                                     3               1899  \n",
      "1859                                     5               1904  \n",
      "2302                                     3               1898  \n",
      "2303                                     3               1914  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "=== SINGLE (train) ===\n",
      "Kept: 2 | Dropped: 1\n",
      "Dropped columns (single): ['position']\n",
      "\n",
      "=== MERGED (train) ===\n",
      "Kept: 90 | Dropped: 2\n",
      "Dropped columns (merged): ['driverId', 'position']\n",
      "[Schema] inferred=10 examples: ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)']\n",
      "[Schema] inferred relationships (sample): ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)', 'races.raceId <- constructor_standings.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_standings.constructorId (coverage=1.000)']\n",
      "Single-table (train) head:\n",
      "        date  driverId  did_not_finish\n",
      "0 2004-08-04        20               1\n",
      "1 2004-08-04        12               1\n",
      "2 2004-07-05        10               0\n",
      "3 2004-07-05        47               0\n",
      "4 2004-06-05        31               1\n",
      "\n",
      "Merged-table (train) head:\n",
      "                      driverId  did_not_finish DAY(date) HOUR(date)  \\\n",
      "qualifying__ft_index                                                  \n",
      "673                        642               1        20          0   \n",
      "674                        633               1        20          0   \n",
      "675                        529               1        20          0   \n",
      "676                        559               1        20          0   \n",
      "693                        792               1        20          0   \n",
      "\n",
      "                     MONTH(date) WEEKDAY(date) YEAR(date) drivers.code  \\\n",
      "qualifying__ft_index                                                     \n",
      "673                            5             5       1950           \\N   \n",
      "674                            5             5       1950           \\N   \n",
      "675                            5             5       1950           \\N   \n",
      "676                            5             5       1950           \\N   \n",
      "693                            5             5       1950           \\N   \n",
      "\n",
      "                     drivers.nationality  drivers.COUNT(qualifying)  ...  \\\n",
      "qualifying__ft_index                                                 ...   \n",
      "673                              Italian                         24  ...   \n",
      "674                              Italian                         24  ...   \n",
      "675                             American                         11  ...   \n",
      "676                             American                          6  ...   \n",
      "693                            Argentine                          1  ...   \n",
      "\n",
      "                      drivers.STD(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "673                                          6.927403   \n",
      "674                                         10.522770   \n",
      "675                                         20.423241   \n",
      "676                                         26.670340   \n",
      "693                                         12.952477   \n",
      "\n",
      "                      drivers.STD(standings.wins)  \\\n",
      "qualifying__ft_index                                \n",
      "673                                      0.711793   \n",
      "674                                      0.000000   \n",
      "675                                      0.000000   \n",
      "676                                      0.361620   \n",
      "693                                      0.000000   \n",
      "\n",
      "                      drivers.SUM(standings.points)  \\\n",
      "qualifying__ft_index                                  \n",
      "673                                          528.31   \n",
      "674                                          216.00   \n",
      "675                                           76.00   \n",
      "676                                           48.00   \n",
      "693                                            0.00   \n",
      "\n",
      "                      drivers.SUM(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "673                                             253.0   \n",
      "674                                             621.0   \n",
      "675                                            2744.0   \n",
      "676                                            1969.0   \n",
      "693                                             349.0   \n",
      "\n",
      "                      drivers.SUM(standings.wins)  drivers.DAY(dob)  \\\n",
      "qualifying__ft_index                                                  \n",
      "673                                          21.0                30   \n",
      "674                                           0.0                16   \n",
      "675                                           0.0                12   \n",
      "676                                           6.0                 6   \n",
      "693                                           0.0                21   \n",
      "\n",
      "                      drivers.HOUR(dob)  drivers.MONTH(dob)  \\\n",
      "qualifying__ft_index                                          \n",
      "673                                   0                  10   \n",
      "674                                   0                   5   \n",
      "675                                   0                   9   \n",
      "676                                   0                   1   \n",
      "693                                   0                  10   \n",
      "\n",
      "                      drivers.WEEKDAY(dob)  drivers.YEAR(dob)  \n",
      "qualifying__ft_index                                           \n",
      "673                                      1               1906  \n",
      "674                                      6               1909  \n",
      "675                                      1               1916  \n",
      "676                                      2               1926  \n",
      "693                                      0               1912  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "=== SINGLE (train) ===\n",
      "Kept: 2 | Dropped: 1\n",
      "Dropped columns (single): ['did_not_finish']\n",
      "\n",
      "=== MERGED (train) ===\n",
      "Kept: 90 | Dropped: 2\n",
      "Dropped columns (merged): ['driverId', 'did_not_finish']\n",
      "[Schema] inferred=10 examples: ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)']\n",
      "[Schema] inferred relationships (sample): ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)', 'races.raceId <- constructor_standings.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_standings.constructorId (coverage=1.000)']\n",
      "Single-table (train) head:\n",
      "        date  driverId  qualifying\n",
      "0 2004-08-04        12           0\n",
      "1 2004-08-04        20           0\n",
      "2 2004-07-05        10           0\n",
      "3 2004-07-05        47           0\n",
      "4 2004-06-05        31           0\n",
      "\n",
      "Merged-table (train) head:\n",
      "                      driverId  qualifying DAY(date) HOUR(date) MONTH(date)  \\\n",
      "qualifying__ft_index                                                          \n",
      "90                         104           0        28          0           2   \n",
      "171                         64           0        28          0           2   \n",
      "172                         54           1        28          0           2   \n",
      "335                         91           0        28          0           2   \n",
      "336                         83           0        28          0           2   \n",
      "\n",
      "                     WEEKDAY(date) YEAR(date) drivers.code  \\\n",
      "qualifying__ft_index                                         \n",
      "90                               0       1994           \\N   \n",
      "171                              0       1994           \\N   \n",
      "172                              0       1994           \\N   \n",
      "335                              0       1994           \\N   \n",
      "336                              0       1994           \\N   \n",
      "\n",
      "                     drivers.nationality  drivers.COUNT(qualifying)  ...  \\\n",
      "qualifying__ft_index                                                 ...   \n",
      "90                               Italian                          9  ...   \n",
      "171                              British                         38  ...   \n",
      "172                               French                         38  ...   \n",
      "335                              Belgian                         10  ...   \n",
      "336                              British                         20  ...   \n",
      "\n",
      "                      drivers.STD(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "90                                           8.992987   \n",
      "171                                          6.912618   \n",
      "172                                          5.530336   \n",
      "335                                          9.123150   \n",
      "336                                          7.211489   \n",
      "\n",
      "                      drivers.STD(standings.wins)  \\\n",
      "qualifying__ft_index                                \n",
      "90                                       0.485358   \n",
      "171                                      0.415646   \n",
      "172                                      0.240934   \n",
      "335                                      0.000000   \n",
      "336                                      0.000000   \n",
      "\n",
      "                      drivers.SUM(standings.points)  \\\n",
      "qualifying__ft_index                                  \n",
      "90                                           1659.5   \n",
      "171                                           876.0   \n",
      "172                                          2124.0   \n",
      "335                                            52.0   \n",
      "336                                           668.0   \n",
      "\n",
      "                      drivers.SUM(standings.position)  \\\n",
      "qualifying__ft_index                                    \n",
      "90                                             2987.0   \n",
      "171                                            2294.0   \n",
      "172                                            1827.0   \n",
      "335                                            2377.0   \n",
      "336                                            2619.0   \n",
      "\n",
      "                      drivers.SUM(standings.wins)  drivers.DAY(dob)  \\\n",
      "qualifying__ft_index                                                  \n",
      "90                                           44.0                23   \n",
      "171                                          19.0                25   \n",
      "172                                          12.0                11   \n",
      "335                                           0.0                23   \n",
      "336                                           0.0                 1   \n",
      "\n",
      "                      drivers.HOUR(dob)  drivers.MONTH(dob)  \\\n",
      "qualifying__ft_index                                          \n",
      "90                                    0                  12   \n",
      "171                                   0                   6   \n",
      "172                                   0                   6   \n",
      "335                                   0                  12   \n",
      "336                                   0                   6   \n",
      "\n",
      "                      drivers.WEEKDAY(dob)  drivers.YEAR(dob)  \n",
      "qualifying__ft_index                                           \n",
      "90                                       6               1956  \n",
      "171                                      3               1964  \n",
      "172                                      3               1964  \n",
      "335                                      6               1962  \n",
      "336                                      0               1959  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "=== SINGLE (train) ===\n",
      "Kept: 2 | Dropped: 1\n",
      "Dropped columns (single): ['qualifying']\n",
      "\n",
      "=== MERGED (train) ===\n",
      "Kept: 90 | Dropped: 2\n",
      "Dropped columns (merged): ['driverId', 'qualifying']\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:18:42.276091Z",
     "start_time": "2025-08-21T15:18:42.273127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tabpfn_on_task(dataset_name: str, task_name: str, mode: str = \"single\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run TabPFN on a specified dataset and task, handling both single-table and merged-table modes.\n",
    "    \"\"\"\n",
    "    # Load dataset and task splits\n",
    "    dataset = get_dataset(dataset_name, download=DOWNLOAD)\n",
    "    task, splits = fetch_splits(dataset_name, task_name, download=DOWNLOAD)\n",
    "\n",
    "    # Ensure the task is compatible with TabPFN\n",
    "    if mode == \"single\":\n",
    "        frames = build_single_table_frames(task, splits)\n",
    "    elif mode == \"merged\":\n",
    "        try:\n",
    "            frames = build_merged_table_frames(dataset, task, splits)\n",
    "        except Exception as e:\n",
    "            print(f\"merged mode failed: {e}, falling back to single-table mode.\")\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'single' or 'merged'\")\n",
    "\n",
    "    # Extract features and targets for each split\n",
    "    (Xtr, ytr, _dftr) = frames[\"train\"]\n",
    "    (Xva, yva, dfva)  = frames[\"val\"]\n",
    "    (Xte, yte, dfte)  = frames[\"test\"]\n",
    "\n",
    "    # Vectorize\n",
    "    tv, Xt, Xv, Xs = vectorize_splits(Xtr, Xva, Xte)\n",
    "\n",
    "    # Respect TabPFN's sample cap\n",
    "    Xt_cap, yt_cap, _ = _subsample(Xt, ytr, cap=TABPFN_MAX, seed=SEED)\n",
    "\n",
    "    # Fit\n",
    "    model = _fit_tabpfn(task, Xt_cap, yt_cap)\n",
    "\n",
    "    # Predict & Evaluate with RelBench evaluators\n",
    "    val_pred  = _predict_for_task(task, model, Xv)\n",
    "    test_pred = _predict_for_task(task, model, Xs)\n",
    "\n",
    "    # Align predictions with original DataFrame indices for evaluation\n",
    "    val_metrics  = task.evaluate(val_pred,  splits[\"val\"])\n",
    "    test_metrics = task.evaluate(test_pred, splits[\"test\"])\n",
    "\n",
    "    # Convert metrics to a dictionary, ensuring all values are floats\n",
    "    out = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"task\": task_name,\n",
    "        \"mode\": mode,\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"n_train_used\": len(Xt_cap),\n",
    "        \"n_train_total\": len(Xt),\n",
    "        \"n_val\": len(Xv),\n",
    "        \"n_test\": len(Xs),\n",
    "    }\n",
    "    return out"
   ],
   "id": "52860c3ba39daf4c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Orchestrator for Benchmark Runs\n",
    "\n",
    "Iterates over all discovered tasks and runs TabPFN in both **single** and **merged** modes. Collects performance metrics for validation and test splits into a results table, handling failures gracefully. Sorts results for easier comparison.\n"
   ],
   "id": "67ce1925dce06a6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-08-21T15:18:42.291089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODES = globals().get(\"MODES\", [\"single\", \"merged\"])\n",
    "\n",
    "records = []\n",
    "failures = []\n",
    "\n",
    "# Run TabPFN on all tasks in both modes and collect results\n",
    "for task_name in TASKS:\n",
    "    for mode in MODES:\n",
    "        try:\n",
    "            res = run_tabpfn_on_task(DATASET, task_name, mode=mode)\n",
    "            # Flatten metrics for val and test, one metric per row\n",
    "            for split in [\"val\", \"test\"]:\n",
    "                metrics = res.get(f\"{split}_metrics\") or {}\n",
    "                for metric_name, metric_value in metrics.items():\n",
    "                    # Only add rows with non-empty metric_value\n",
    "                    if metric_value is not None and not (isinstance(metric_value, float) and np.isnan(metric_value)):\n",
    "                        records.append({\n",
    "                            \"dataset\": res.get(\"dataset\", DATASET),\n",
    "                            \"task\": res.get(\"task\", task_name),\n",
    "                            \"split\": split,\n",
    "                            \"mode\": res.get(\"mode\", mode),\n",
    "                            \"method\": \"TabPFN_experimental_v1.0\",\n",
    "                            \"metric\": metric_name,\n",
    "                            \"score\": metric_value,\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            msg = f\"[{DATASET} | {task_name} | {mode}] failed: {e!s}\"\n",
    "            print(msg)\n",
    "            failures.append(msg)\n",
    "\n",
    "# Convert collected records into a DataFrame\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# If no successful runs were recorded, display a message and create an empty DataFrame\n",
    "if results_df.empty:\n",
    "    print(\"No successful runs were recorded. Check the failure messages above.\")\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"dataset\", \"task\", \"split\", \"mode\", \"method\", \"metric\", \"score\"]\n",
    "    )\n",
    "else:\n",
    "    # Ensure required sort keys exist even if some rows missed them\n",
    "    for col in [\"task\", \"mode\"]:\n",
    "        if col not in results_df.columns:\n",
    "            results_df[col] = pd.NA\n",
    "    # Sort only by the columns that exist to avoid KeyError\n",
    "    sort_keys = [c for c in [\"task\", \"mode\", \"metric\"] if c in results_df.columns]\n",
    "    if sort_keys:\n",
    "        results_df = results_df.sort_values(sort_keys)\n",
    "\n",
    "results_df"
   ],
   "id": "8119d8844ebded86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Schema] inferred=10 examples: ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)']\n",
      "[Schema] inferred relationships (sample): ['drivers.driverId <- qualifying.driverId (coverage=1.000)', 'drivers.driverId <- results.driverId (coverage=1.000)', 'races.raceId <- results.raceId (coverage=1.000)', 'drivers.driverId <- standings.driverId (coverage=1.000)', 'races.raceId <- standings.raceId (coverage=1.000)', 'circuits.circuitId <- races.circuitId (coverage=1.000)', 'races.raceId <- constructor_results.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_results.constructorId (coverage=1.000)', 'races.raceId <- constructor_standings.raceId (coverage=1.000)', 'constructors.constructorId <- constructor_standings.constructorId (coverage=1.000)']\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Results to CSV",
   "id": "77a4dc93cb1858d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify output directory\n",
    "out_dir = globals().get(\"OUT_DIR\", \"outputs\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Change timestamp format to \"dd.mm.yyyy-hh:mm\"\n",
    "timestamp = time.strftime(\"%d.%m.%Y-%H:%M\")\n",
    "csv_name = f\"tabpfn_{DATASET}_{timestamp}.csv\"\n",
    "csv_path = os.path.join(out_dir, csv_name)\n",
    "\n",
    "# Round all numerical results to 4 decimal places before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(results_df[\"score\"]):\n",
    "        results_df[\"score\"] = results_df[\"score\"].round(4)\n",
    "    else:\n",
    "        # Optionally, try to convert to numeric first\n",
    "        results_df[\"score\"] = pd.to_numeric(results_df[\"score\"], errors=\"coerce\").round(4)\n",
    "\n",
    "# Filter out rows with empty score values before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    results_df = results_df[results_df[\"score\"].notnull()]\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved results to: {csv_path}\")\n"
   ],
   "id": "c13a29742326995c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
