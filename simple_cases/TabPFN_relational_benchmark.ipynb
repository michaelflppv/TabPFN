{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.406273Z",
     "start_time": "2025-08-14T11:59:49.641249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "# RelBench\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "import relbench.metrics\n",
    "import inspect\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# Device preference\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define global dataset variable\n",
    "DATASET = \"rel-f1\"\n"
   ],
   "id": "57624fe02c838842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.414720Z",
     "start_time": "2025-08-14T11:59:51.412808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.486853Z",
     "start_time": "2025-08-14T11:59:51.420314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = time.perf_counter()\n",
    "    yield lambda: time.perf_counter() - start\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        out[\"roc_auc\"] = np.nan\n",
    "    return out\n",
    "\n",
    "def regression_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    # Accepts y_prob for compatibility, but ignores it\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "dataset = get_dataset(DATASET)\n",
    "db = dataset.get_db()\n",
    "\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Convert all tables to pandas DataFrames\n",
    "tables = {}\n",
    "for name in db.table_dict:\n",
    "    tables[name] = to_pandas(db.table_dict[name])\n",
    "\n",
    "for t in tables.values():\n",
    "    for col in t.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            t[col] = pd.to_datetime(t[col], errors=\"coerce\")"
   ],
   "id": "4da5c0d65181834d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /Users/michaelflppv/Library/Caches/relbench/rel-f1/db...\n",
      "Done in 0.04 seconds.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.552671Z",
     "start_time": "2025-08-14T11:59:51.548519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_single_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(DATASET, task_name)\n",
    "\n",
    "    # Create a training, validation, and test splits\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    # Input features need to be numeric, otherwise encoded\n",
    "    df = train_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_train = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df[task.target_col]\n",
    "\n",
    "    df = val_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_val = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df[task.target_col]\n",
    "\n",
    "    # For the test set, we do not sample to keep the full dataset\n",
    "    df = test_table.df\n",
    "    X_test = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df[task.target_col]\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        # Depending on the task, TabPFNClassifier or TabPFNRegressor is used\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE, ignore_pretraining_limits=True)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    # Get only the primary metric value (not dict)\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res"
   ],
   "id": "f430cf6e11811564",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.636467Z",
     "start_time": "2025-08-14T11:59:51.604154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create features for drivers based on their past performance\n",
    "# This function creates features like average position, points, DNF rate, and average laps\n",
    "def engineer_driver_features():\n",
    "    # Extract the race dates and results\n",
    "    results = tables[\"results\"].merge(\n",
    "        tables[\"races\"][[\"raceId\", \"date\"]],\n",
    "        on=\"raceId\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"results columns after merge:\", results.columns.tolist())\n",
    "    print(\"Number of rows after merge:\", results.shape[0])\n",
    "    results = results.dropna(subset=[\"driverId\", \"date_y\"])\n",
    "    print(\"Number of rows after dropna:\", results.shape[0])\n",
    "\n",
    "    # Create a did not finish (DNF) flag as indicator for future race outcomes\n",
    "    results[\"dnf_flag\"] = (~results[\"positionOrder\"].isna()).astype(int)\n",
    "    # For each driver, calculate the average position, points, DNF rate, and average laps\n",
    "    # Only the information before the current race is used\n",
    "    feats = results.groupby(\"driverId\").expanding().agg({\n",
    "        \"positionOrder\": \"mean\",\n",
    "        \"points\": \"mean\",\n",
    "        \"dnf_flag\": \"mean\",\n",
    "        \"laps\": \"mean\"\n",
    "    }).reset_index()\n",
    "    feats = feats.rename(columns={\n",
    "        \"positionOrder\": \"avg_position\",\n",
    "        \"points\": \"avg_points\",\n",
    "        \"dnf_flag\": \"dnf_rate\",\n",
    "        \"laps\": \"avg_laps\"\n",
    "    })\n",
    "    feats[\"date\"] = results[\"date_y\"].values\n",
    "    return feats\n",
    "\n",
    "driver_feats = engineer_driver_features()"
   ],
   "id": "de1f9fe2a4bd02ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results columns after merge: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionOrder', 'points', 'laps', 'milliseconds', 'fastestLap', 'rank', 'statusId', 'date_x', 'date_y']\n",
      "Number of rows after merge: 20323\n",
      "Number of rows after dropna: 20323\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:51.651256Z",
     "start_time": "2025-08-14T11:59:51.645447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_merged_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(DATASET, task_name)\n",
    "\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    df_train = train_table.df\n",
    "    df_train = df_train.sample(n=min(1000, len(df_train)), random_state=42)\n",
    "    idx_train = list(zip(df_train[\"driverId\"], df_train[\"date\"]))\n",
    "    X_train = df_train.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df_train[task.target_col]\n",
    "\n",
    "    df_val = val_table.df\n",
    "    df_val = df_val.sample(n=min(1000, len(df_val)), random_state=42)\n",
    "    idx_val   = list(zip(df_val[\"driverId\"], df_val[\"date\"]))\n",
    "    X_val = df_val.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df_val[task.target_col]\n",
    "\n",
    "    # For the test set, we do not sample to keep the full dataset\n",
    "    df_test = test_table.df\n",
    "    idx_test  = list(zip(df_test[\"driverId\"], df_test[\"date\"]))\n",
    "    X_test = df_test.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df_test[task.target_col]\n",
    "\n",
    "    # Merge features by driverId and date (backward asof join)\n",
    "    # backward asof join finds the last row in the other table where\n",
    "    # the time is less than or equal to the time in the current row of the self table\n",
    "    def enrich(X, idx):\n",
    "        df = X.copy()\n",
    "        # Create a DataFrame with driverId and date for each row\n",
    "        idx_df = pd.DataFrame(idx, columns=[\"driverId\", \"date\"]) # create DataFrame from tuples\n",
    "        idx_df[\"driverId\"] = idx_df[\"driverId\"].astype(\"int64\")\n",
    "        idx_df[\"date\"] = pd.to_datetime(idx_df[\"date\"]) # ensure date is in datetime format\n",
    "        driver_feats_fixed = driver_feats.copy()\n",
    "        driver_feats_fixed[\"driverId\"] = driver_feats_fixed[\"driverId\"].astype(\"int64\")\n",
    "        # Use backward asof merge to align features with the closest previous date\n",
    "        merged = pd.merge_asof(\n",
    "            idx_df.sort_values(\"date\"),\n",
    "            driver_feats_fixed.sort_values(\"date\"),\n",
    "            on=\"date\", by=\"driverId\",\n",
    "            direction=\"backward\", tolerance=pd.Timedelta(\"3650D\") # 10 years tolerance\n",
    "        )\n",
    "        merged = merged.drop(columns=[\"driverId\", \"date\"]) # already present in df\n",
    "        df = pd.concat([df.reset_index(drop=True), merged.reset_index(drop=True)], axis=1)\n",
    "        return df\n",
    "\n",
    "    X_train_en = enrich(X_train, idx_train)\n",
    "    X_val_en   = enrich(X_val, idx_val)\n",
    "    X_test_en  = enrich(X_test, idx_test)\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train_en, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val_en)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test_en)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val_en)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test_en)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "2213d3092cc43fd0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:08:35.109720Z",
     "start_time": "2025-08-14T11:59:51.660220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TASKS = [\"driver-dnf\", \"driver-top3\", \"driver-position\"]\n",
    "TASKS = [\"driver-dnf\"]\n",
    "\n",
    "all_results_long = []\n",
    "\n",
    "def results_to_long(task, setting, split, metrics):\n",
    "    rows = []\n",
    "    for metric_name, value in metrics.items():\n",
    "        # Only add row if value is not None and not NaN\n",
    "        if value is not None and not (isinstance(value, float) and np.isnan(value)):\n",
    "            rows.append({\n",
    "                \"dataset\": DATASET,  # Fill with DATASET variable\n",
    "                \"task\": task,\n",
    "                \"split\": split,\n",
    "                \"setting\": setting,\n",
    "                \"method\": \"TabPFN_experiment_v1.0\",\n",
    "                \"metric\": metric_name,\n",
    "                \"score\": value\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"=== {task} | Single Table ===\")\n",
    "    res_single = run_single_table_experiment(task)\n",
    "    for split, metrics in res_single.items():\n",
    "        all_results_long.extend(results_to_long(task, \"single\", split, metrics))\n",
    "\n",
    "    print(f\"=== {task} | Merged Table ===\")\n",
    "    res_merged = run_merged_table_experiment(task)\n",
    "    for split, metrics in res_merged.items():\n",
    "        all_results_long.extend(results_to_long(task, \"merged\", split, metrics))\n",
    "\n",
    "results_long_df = pd.DataFrame(all_results_long)\n",
    "# Ensure 'dataset' is the first column\n",
    "cols = [\"dataset\"] + [col for col in results_long_df.columns if col != \"dataset\"]\n",
    "results_long_df = results_long_df[cols]\n",
    "# Round all numerical values in 'score' to 4 decimal places\n",
    "results_long_df[\"score\"] = results_long_df[\"score\"].apply(lambda x: round(x, 4) if isinstance(x, (float, int, np.floating, np.integer)) else x)\n",
    "\n",
    "results_long_df.to_csv(\"results_summary_long.csv\", index=False)\n",
    "results_long_df"
   ],
   "id": "4ebb21a39e26d553",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== driver-dnf | Single Table ===\n",
      "=== driver-dnf | Merged Table ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   dataset        task split setting                  method  \\\n",
       "0   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "1   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "2   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "3   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "4   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "5   rel-f1  driver-dnf   val  single  TabPFN_experiment_v1.0   \n",
       "6   rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "7   rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "8   rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "9   rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "10  rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "11  rel-f1  driver-dnf  test  single  TabPFN_experiment_v1.0   \n",
       "12  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "13  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "14  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "15  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "16  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "17  rel-f1  driver-dnf   val  merged  TabPFN_experiment_v1.0   \n",
       "18  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "19  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "20  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "21  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "22  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "23  rel-f1  driver-dnf  test  merged  TabPFN_experiment_v1.0   \n",
       "\n",
       "                     metric    score  \n",
       "0                  accuracy   0.7792  \n",
       "1                  f1_macro   0.4379  \n",
       "2                   roc_auc   0.6393  \n",
       "3                  fit_time   1.5767  \n",
       "4              predict_time  60.4653  \n",
       "5   primary_metric_relbench   0.8072  \n",
       "6                  accuracy   0.7051  \n",
       "7                  f1_macro   0.4135  \n",
       "8                   roc_auc   0.6432  \n",
       "9                  fit_time   1.5767  \n",
       "10             predict_time  62.2831  \n",
       "11  primary_metric_relbench   0.7991  \n",
       "12                 accuracy   0.7792  \n",
       "13                 f1_macro   0.4379  \n",
       "14                  roc_auc   0.6498  \n",
       "15                 fit_time   1.1091  \n",
       "16             predict_time  68.0796  \n",
       "17  primary_metric_relbench   0.8027  \n",
       "18                 accuracy   0.7051  \n",
       "19                 f1_macro   0.4135  \n",
       "20                  roc_auc   0.6621  \n",
       "21                 fit_time   1.1091  \n",
       "22             predict_time  68.9140  \n",
       "23  primary_metric_relbench   0.7918  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>split</th>\n",
       "      <th>setting</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.5767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>predict_time</td>\n",
       "      <td>60.4653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>primary_metric_relbench</td>\n",
       "      <td>0.8072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.4135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.6432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.5767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>predict_time</td>\n",
       "      <td>62.2831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>single</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>primary_metric_relbench</td>\n",
       "      <td>0.7991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.6498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>predict_time</td>\n",
       "      <td>68.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>val</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>primary_metric_relbench</td>\n",
       "      <td>0.8027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.4135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.6621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>predict_time</td>\n",
       "      <td>68.9140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rel-f1</td>\n",
       "      <td>driver-dnf</td>\n",
       "      <td>test</td>\n",
       "      <td>merged</td>\n",
       "      <td>TabPFN_experiment_v1.0</td>\n",
       "      <td>primary_metric_relbench</td>\n",
       "      <td>0.7918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:08:35.145060Z",
     "start_time": "2025-08-14T12:08:35.142606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_metric(metric):\n",
    "    if metric not in results_long_df.columns:\n",
    "        print(f\"Metric '{metric}' not found in results. Skipping.\")\n",
    "        return\n",
    "    sub = results_long_df[(results_long_df[\"split\"] == \"test\") & results_long_df[metric].notna()]\n",
    "    if sub.empty:\n",
    "        return\n",
    "    pivot = sub.pivot(index=\"task\", columns=\"setting\", values=metric)\n",
    "    pivot.plot(kind=\"bar\", figsize=(8, 4), title=metric)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"roc_auc\", \"f1_macro\", \"mae\", \"fit_time\", \"predict_time\"]:\n",
    "    plot_metric(m)"
   ],
   "id": "8e2bb976df5d5820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric 'roc_auc' not found in results. Skipping.\n",
      "Metric 'f1_macro' not found in results. Skipping.\n",
      "Metric 'mae' not found in results. Skipping.\n",
      "Metric 'fit_time' not found in results. Skipping.\n",
      "Metric 'predict_time' not found in results. Skipping.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:08:35.230250Z",
     "start_time": "2025-08-14T12:08:35.228874Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "77cc75bf3cdeb172",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
