{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TabPFN Relational Benchmark**\n",
    "This notebook benchmarks the performance of TabPFN models on datasets from RelBench in two scenarios:\n",
    "1. **Single Table** – Using only the target entity table.\n",
    "2. **Merged Table** – Using a naively denormalized table obtained by joining related tables.\n",
    "\n",
    "It automates dataset loading, preprocessing (including date feature engineering), vectorization, model training, prediction, and evaluation for all compatible tasks within a chosen RelBench dataset. The results allow comparing model performance between single-table and merged-table configurations.\n"
   ],
   "id": "7ab5a9bf5466de0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "ac93e97c56d4b905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- PyTorch and PyTorch Geometric ---\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "# --- Skrub and Sentence Transformers ---\n",
    "from skrub import TableVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- RelBench ---\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task, get_task_names\n",
    "from relbench.base import TaskType\n",
    "import relbench.metrics\n",
    "from relbench.modeling.utils import get_stype_proposal, to_unix_time\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "\n",
    "# --- TabPFN ---\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n"
   ],
   "id": "57624fe02c838842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set Global Configuration",
   "id": "7154198e21fe2a01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Device preference\n",
    "#if torch.backends.mps.is_available():\n",
    "#    DEVICE = \"mps\"\n",
    "#elif torch.cuda.is_available():\n",
    "#    DEVICE = \"cuda\"\n",
    "#else:\n",
    "#    DEVICE = \"cpu\"\n",
    "\n",
    "DEVICE = \"cpu\" # Force CPU for compatibility with all environments\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define global dataset variable (any available dataset from relbench.datasets)\n",
    "# \"rel-f1\" is the default, but can be overridden by setting DATASET variable\n",
    "DATASET = \"rel-stack\"\n",
    "\n",
    "# Global configuration variables with defaults\n",
    "SEED   = globals().get(\"SEED\", 42)\n",
    "N_ESTIMATORS = globals().get(\"N_ESTIMATORS\", 16) # number of TabPFN estimators\n",
    "TABPFN_MAX = globals().get(\"TABPFN_MAX\", 2000)  # hard ceiling for TabPFN"
   ],
   "id": "c5959e09ecd4c20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook Configuration and Dataset Selection\n",
    "\n",
    "\n",
    "Sets the dataset name (`DATASET`) and download flag (`DOWNLOAD`), then discovers all available tasks for the selected dataset using RelBench’s APIs. Filters tasks to only those compatible with TabPFN (classification and regression).\n"
   ],
   "id": "a86eaa89573fdf63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reuse existing config if present, otherwise set defaults\n",
    "DATASET = globals().get(\"DATASET\", \"rel-f1\")\n",
    "DOWNLOAD = globals().get(\"DOWNLOAD\", True)\n",
    "\n",
    "# Discover tasks and keep only entity-level cls/reg tasks TabPFN can handle\n",
    "def _is_tabpfn_friendly(task):\n",
    "    return task.task_type in (\n",
    "        TaskType.BINARY_CLASSIFICATION,\n",
    "        TaskType.MULTICLASS_CLASSIFICATION,\n",
    "        TaskType.MULTILABEL_CLASSIFICATION,\n",
    "        TaskType.REGRESSION,\n",
    "    )\n",
    "\n",
    "_all = get_task_names(DATASET)  # shown in tutorials\n",
    "TASKS = []\n",
    "for tname in _all:\n",
    "    try:\n",
    "        t = get_task(DATASET, tname, download=DOWNLOAD)\n",
    "        if _is_tabpfn_friendly(t):\n",
    "            TASKS.append(tname)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {tname}: {e!s}\")\n",
    "\n",
    "print(f\"{DATASET}: {len(TASKS)} TabPFN-friendly tasks -> {TASKS}\")\n"
   ],
   "id": "d94075cf88bf6806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Patch RelBench Metrics (Optional)",
   "id": "affc15acb6a0f8aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text Embedding Configuration",
   "id": "5629815fd3214b7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a text embedding class using GloVe embeddings from Sentence Transformers.\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))"
   ],
   "id": "78e9b5ef45024fb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions for Dataset Loading and Table Processing\n",
   "id": "2d748a1a5dea1d28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Date Feature Engineering\n",
    "\n",
    "Processes all tables in the dataset to detect and parse date columns, replacing missing values and generating engineered date-related features (e.g., year, month, weekday, cyclical encodings).\n"
   ],
   "id": "76f494f170e324f0"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset and its database\n",
    "dataset = get_dataset(DATASET)\n",
    "db = dataset.get_db()\n",
    "\n",
    "# Helper function to convert any table-like object to a pandas DataFrame\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Convert all tables to pandas DataFrames\n",
    "tables = {name: to_pandas(tbl) for name, tbl in db.table_dict.items()}\n",
    "\n",
    "# Date feature engineering\n",
    "# This will modify the tables in-place, adding new date-related features.\n",
    "for name, df in tables.items():\n",
    "    # Drop duplicate columns and force a copy\n",
    "    df = df.loc[:, ~df.columns.duplicated()].copy()\n",
    "    date_cols = [col for col in df.columns if \"date\" in col.lower()]\n",
    "    if not date_cols:\n",
    "        tables[name] = df\n",
    "        continue\n",
    "\n",
    "    # Compute cleaned dates and all features in memory\n",
    "    dt_clean = {}\n",
    "    feats = {}\n",
    "    for col in date_cols:\n",
    "        dt = pd.to_datetime(df[col], errors=\"coerce\", utc=True)\n",
    "        dt_filled = dt.fillna(dt.min())\n",
    "        dt_clean[col] = dt_filled.dt.tz_localize(None)\n",
    "        feats.update({\n",
    "            f\"{col}_year\":            dt_filled.dt.year,\n",
    "            f\"{col}_month\":           dt_filled.dt.month,\n",
    "            f\"{col}_day\":             dt_filled.dt.day,\n",
    "            f\"{col}_weekday\":         dt_filled.dt.weekday,\n",
    "            f\"{col}_quarter\":         dt_filled.dt.quarter,\n",
    "            f\"{col}_is_month_start\":  dt_filled.dt.is_month_start.astype(int),\n",
    "            f\"{col}_is_month_end\":    dt_filled.dt.is_month_end.astype(int),\n",
    "            f\"{col}_is_weekend\":      (dt_filled.dt.weekday >= 5).astype(int),\n",
    "            f\"{col}_month_sin\":       np.sin(2 * np.pi * dt_filled.dt.month / 12),\n",
    "            f\"{col}_month_cos\":       np.cos(2 * np.pi * dt_filled.dt.month / 12),\n",
    "            f\"{col}_weekday_sin\":     np.sin(2 * np.pi * dt_filled.dt.weekday / 7),\n",
    "            f\"{col}_weekday_cos\":     np.cos(2 * np.pi * dt_filled.dt.weekday / 7),\n",
    "            f\"{col}_elapsed_days\":    (dt_filled - dt_filled.min()).dt.days,\n",
    "        })\n",
    "\n",
    "    # Drop original date columns and concatenate new ones in a single op\n",
    "    df = df.drop(columns=date_cols)\n",
    "    new_cols_df = pd.DataFrame({**dt_clean, **feats}, index=df.index)\n",
    "    df = pd.concat([df, new_cols_df], axis=1)\n",
    "\n",
    "    tables[name] = df\n",
    "\n",
    "# Update the database with modified DataFrames\n",
    "for name, df in tables.items():\n",
    "    db.table_dict[name].df = df\n",
    "\n",
    "# Patch infer_series_stype to handle \"truth value of a Series\" errors without recursion\n",
    "import torch_frame.utils.infer_stype as ts\n",
    "\n",
    "# Wrap only once by marking the safe wrapper\n",
    "if not getattr(ts.infer_series_stype, \"__safe_wrapped__\", False):\n",
    "    original_infer = ts.infer_series_stype\n",
    "\n",
    "    def safe_infer_series_stype(ser):\n",
    "        try:\n",
    "            return original_infer(ser)\n",
    "        except ValueError as e:\n",
    "            if \"truth value of a Series\" in str(e):\n",
    "                return original_infer(ser.dropna())\n",
    "            raise\n",
    "\n",
    "    safe_infer_series_stype.__safe_wrapped__ = True\n",
    "    ts.infer_series_stype = safe_infer_series_stype"
   ],
   "id": "d37c8ff4b032ae52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Flatten One-Hop Foreign Key Relationships\n",
    "\n",
    "This function takes a heterogeneous data structure (tensor frames) and a database object, then flattens the one-hop foreign key relationships starting from a specified target table. It performs left joins to denormalize the data into a single pandas DataFrame."
   ],
   "id": "8a3ef84da239d251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def flatten_one_hop(hetero_data, db, target_table, cutoff_times):\n",
    "    # base table as pandas\n",
    "    base = to_pandas(db.table_dict[target_table])\n",
    "    dfs = []\n",
    "    # for each row, join only past neighbors\n",
    "    for idx, cutoff in enumerate(cutoff_times):\n",
    "        row = base.iloc[[idx]]\n",
    "        # For each foreign key in the target table, find the corresponding primary key table and join\n",
    "        for fkey, pkey_table in db.table_dict[target_table].fkey_col_to_pkey_table.items():\n",
    "            nbr = to_pandas(db.table_dict[pkey_table])\n",
    "            time_col = db.table_dict[pkey_table].time_col\n",
    "            # If the neighbor table has a time column, filter by cutoff\n",
    "            if time_col is not None:\n",
    "                nbr = nbr[to_unix_time(nbr[time_col]) <= cutoff]\n",
    "            # Perform left join on the foreign key to primary key relationship\n",
    "            # We drop the primary key column from the neighbor table to avoid duplication\n",
    "            row = row.merge(\n",
    "                nbr.drop(columns=[db.table_dict[pkey_table].pkey_col]),\n",
    "                left_on=fkey, right_on=db.table_dict[pkey_table].pkey_col,\n",
    "                how=\"left\", suffixes=(\"\", f\"_{pkey_table}\")\n",
    "            )\n",
    "        dfs.append(row)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ],
   "id": "de77c03733f542aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fetch Dataset Splits\n",
    "\n",
    "Utility functions to load a task’s splits (`train`, `val`, `test`), convert them to pandas DataFrames, and extract features (`X`) and targets (`y`). Includes functions to build:\n",
    "- **Single-table frames** directly from the target entity table.\n",
    "- **Merged-table frames** by performing a one-hop foreign key → primary key join to denormalize data.\n"
   ],
   "id": "1a35d633effdd263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fetches the task and its splits from the dataset, returning a task object and a dictionary of DataFrames for each split.\n",
    "def fetch_splits(dataset_name: str, task_name: str, download: bool = True):\n",
    "    task = get_task(dataset_name, task_name, download=download)\n",
    "    # keep original columns (tutorial shows mask_input_cols flag)\n",
    "    splits = {\n",
    "        split: task.get_table(split, mask_input_cols=False)\n",
    "        for split in (\"train\", \"val\", \"test\")\n",
    "    }\n",
    "    return task, splits\n",
    "\n",
    "# Converts a DataFrame to feature matrix (X) and target vector (y) based on the specified target column.\n",
    "def to_Xy(df: pd.DataFrame, target_col: str):\n",
    "    y = df[target_col].to_numpy()\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y\n",
    "\n",
    "# Infers the primary key column from a table object and its DataFrame. It checks for common attribute names first, then falls back to finding the first unique column.\n",
    "def _infer_pk(table_obj, df: pd.DataFrame):\n",
    "    # best-effort: check common attribute names first, then infer by uniqueness\n",
    "    for attr in (\"primary_key_col\", \"pkey\", \"pk\", \"primary_key\", \"id_col\"):\n",
    "        if hasattr(table_obj, attr):\n",
    "            cand = getattr(table_obj, attr)\n",
    "            if isinstance(cand, str) and cand in df.columns:\n",
    "                return cand\n",
    "    # fallback: take the first unique column if exists\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            if df[c].is_unique:\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# Builds frames for each split of a task, either using the original target table (single-table mode) or by denormalizing the data (merged-table mode). Returns a dictionary with split names as keys and tuples of (X, y, original_df) as values.\n",
    "def build_single_table_frames(task, splits):\n",
    "    frames = {}\n",
    "    for split, table in splits.items():\n",
    "        df = table.df.copy()\n",
    "        # IMPORTANT: do not touch column masking/order; just drop the target to form X\n",
    "        X, y = to_Xy(df, task.target_col)\n",
    "        frames[split] = (X, y, df)  # keep original df for evaluation alignment\n",
    "    return frames\n",
    "\n",
    "# Builds frames for each split of a dataset in merged-table mode by performing a one-hop foreign key → primary key join. It flattens the data structure, extracts features and targets, and returns a dictionary with split names as keys and tuples of (X, y, merged_df) as values.\n",
    "def build_merged_table_frames(hetero_data, db, task, splits):\n",
    "    out = {}\n",
    "    tbl = task.entity_table\n",
    "    tcol = db.table_dict[tbl].time_col\n",
    "\n",
    "    for name, table in splits.items():\n",
    "        # get pandas DataFrame from Table object\n",
    "        df = table.df if hasattr(table, \"df\") else to_pandas(table)\n",
    "        # compute cutoff timestamps\n",
    "        cutoff = to_unix_time(df[tcol]) if tcol else [None] * len(df)\n",
    "        # flatten via one-hop join\n",
    "        merged = flatten_one_hop(hetero_data, db, tbl, cutoff)\n",
    "        # split into features/target\n",
    "        X, y = to_Xy(merged, task.target_col)\n",
    "        out[name] = (X, y, merged)\n",
    "    return out\n"
   ],
   "id": "1cfbaca7c6d3b12c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorization Wrapper (Version-Safe)\n",
    "\n",
    "Initializes a `TableVectorizer` with only supported arguments for the installed `skrub` or `dirty_cat` version, ensuring compatibility. Transforms `train`, `val`, and `test` splits into numerical feature matrices, converting them to dense format if necessary.\n"
   ],
   "id": "f7cf59b1861625f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper Functions for Vectorization",
   "id": "ff99875cd0db904d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This function creates a `TableVectorizer` instance with version-specific arguments.\n",
    "def _make_table_vectorizer():\n",
    "    sig = inspect.signature(TableVectorizer.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    tv_kwargs = {}\n",
    "\n",
    "    # Only set kwargs that actually exist in the installed version\n",
    "    if \"cardinality_threshold\" in allowed:\n",
    "        tv_kwargs[\"cardinality_threshold\"] = globals().get(\"CARDINALITY_THRESHOLD\", 1000)\n",
    "\n",
    "    # Some versions expose this; others don't, guard it\n",
    "    if \"high_cardinality_transformer\" in allowed:\n",
    "        tv_kwargs[\"high_cardinality_transformer\"] = globals().get(\"HIGH_CARD_TRANSFORMER\", \"hashing\")\n",
    "\n",
    "    # Optional knobs if you define them globally and the version supports them\n",
    "    if \"text_separator\" in allowed and \"TEXT_SEPARATOR\" in globals():\n",
    "        tv_kwargs[\"text_separator\"] = globals()[\"TEXT_SEPARATOR\"]\n",
    "    if \"numerical_transformer\" in allowed and \"NUMERICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"numerical_transformer\"] = globals()[\"NUMERICAL_TRANSFORMER\"]\n",
    "    if \"categorical_transformer\" in allowed and \"CATEGORICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"categorical_transformer\"] = globals()[\"CATEGORICAL_TRANSFORMER\"]\n",
    "\n",
    "    return TableVectorizer(**tv_kwargs)\n",
    "\n",
    "# Converts a sparse matrix to a dense NumPy array, handling cases where the input is already dense or does not support `.toarray()`.\n",
    "def _to_dense(X):\n",
    "    try:\n",
    "        # scipy sparse matrices have .toarray()\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "    except Exception:\n",
    "        return X\n",
    "\n",
    "# Vectorizes the training, validation, and test splits using a `TableVectorizer`. It initializes the vectorizer, fits it on the training data, and transforms all splits into dense NumPy arrays. Returns the vectorizer and the transformed matrices.\n",
    "def vectorize_splits(X_train, X_val, X_test):\n",
    "    # Fit only on training data to prevent data leakage\n",
    "    tv = _make_table_vectorizer()\n",
    "    Xt = _to_dense(tv.fit_transform(X_train))\n",
    "    Xv = _to_dense(tv.transform(X_val))\n",
    "    Xs = _to_dense(tv.transform(X_test))\n",
    "    return tv, Xt, Xv, Xs\n"
   ],
   "id": "ffb43a27c3ac51cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This function subsamples the training data to a maximum size defined by `TABPFN_MAX`. If the dataset is smaller than this cap, it returns the full dataset; otherwise, it randomly samples without replacement.\n",
    "def _subsample(X, y, cap=TABPFN_MAX, seed=SEED):\n",
    "    if len(X) <= cap:\n",
    "        return X, y, np.arange(len(X))\n",
    "    idx = np.random.RandomState(seed).choice(len(X), size=cap, replace=False)\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        Xs = X.iloc[idx]\n",
    "    else:\n",
    "        Xs = X[idx]\n",
    "    ys = y[idx]\n",
    "    return Xs, ys, idx\n",
    "\n",
    "# Fits a TabPFN model (either classifier or regressor) based on the task type. It initializes the model with the specified device and number of estimators, then fits it to the provided training data.\n",
    "def _fit_tabpfn(task, Xt, yt):\n",
    "    if task.task_type == TaskType.REGRESSION and TabPFNRegressor is not None:\n",
    "        model = TabPFNRegressor(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    else:\n",
    "        model = TabPFNClassifier(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    model.fit(Xt, yt)\n",
    "    return model\n",
    "\n",
    "# Helper function to make predictions for a given task using the fitted model. It handles different task types (regression, binary classification, multiclass/multilabel) and returns the appropriate prediction format.\n",
    "def _predict_for_task(task, model, X):\n",
    "    # align with RelBench evaluators: AUROC expects probabilities for the positive class\n",
    "    if task.task_type == TaskType.REGRESSION:\n",
    "        return model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    if task.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "        return proba[:, 1]\n",
    "    else:\n",
    "        # multiclass/multilabel: pass full probability matrix\n",
    "        return proba"
   ],
   "id": "5c53f649ce01b948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build a hetero-temporal graph for experiments\n",
   "id": "b93e756ef255ccaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=torch.device(DEVICE)), batch_size=256\n",
    ")\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=text_embedder_cfg,\n",
    "    cache_dir=None,\n",
    ")"
   ],
   "id": "748b9595f3f8950a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run TabPFN on Selected Tasks\n",
    "\n",
    "Runs TabPFN on a specified dataset and task, handling both single-table and merged-table modes. It vectorizes the data, fits the model, makes predictions, and evaluates performance using RelBench’s evaluators. Returns a dictionary with results."
   ],
   "id": "21448305df117a22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_tabpfn_on_task(dataset_name: str, task_name: str, mode: str = \"single\") -> Dict[str, Any]:\n",
    "    # Load dataset and task splits\n",
    "    input_db = get_dataset(dataset_name, download=DOWNLOAD).get_db()\n",
    "    task, splits = fetch_splits(dataset_name, task_name, download=DOWNLOAD)\n",
    "\n",
    "    # Ensure the task is compatible with TabPFN\n",
    "    if mode == \"single\":\n",
    "        frames = build_single_table_frames(task, splits)\n",
    "    elif mode == \"merged\":\n",
    "        frames = build_merged_table_frames(data, input_db, task, splits)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'single' or 'merged'\")\n",
    "\n",
    "    # Extract features and targets for each split\n",
    "    (Xtr, ytr, _dftr) = frames[\"train\"]\n",
    "    (Xva, yva, dfva)  = frames[\"val\"]\n",
    "    (Xte, yte, dfte)  = frames[\"test\"]\n",
    "\n",
    "    # Vectorize\n",
    "    tv, Xt, Xv, Xs = vectorize_splits(Xtr, Xva, Xte)\n",
    "\n",
    "    # Respect TabPFN's sample cap\n",
    "    Xt_cap, yt_cap, _ = _subsample(Xt, ytr, cap=TABPFN_MAX, seed=SEED)\n",
    "\n",
    "    # Fit\n",
    "    model = _fit_tabpfn(task, Xt_cap, yt_cap)\n",
    "\n",
    "    # Predict & Evaluate with RelBench evaluators\n",
    "    val_pred  = _predict_for_task(task, model, Xv)\n",
    "    test_pred = _predict_for_task(task, model, Xs)\n",
    "\n",
    "    # Align predictions with original DataFrame indices for evaluation\n",
    "    val_metrics  = task.evaluate(val_pred,  splits[\"val\"])\n",
    "    test_metrics = task.evaluate(test_pred, splits[\"test\"])\n",
    "\n",
    "    # Convert metrics to a dictionary, ensuring all values are floats\n",
    "    out = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"task\": task_name,\n",
    "        \"mode\": mode,\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"n_train_used\": len(Xt_cap),\n",
    "        \"n_train_total\": len(Xt),\n",
    "        \"n_val\": len(Xv),\n",
    "        \"n_test\": len(Xs),\n",
    "    }\n",
    "    return out"
   ],
   "id": "52860c3ba39daf4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Orchestrator for Benchmark Runs\n",
    "\n",
    "Iterates over all discovered tasks and runs TabPFN in both **single** and **merged** modes. Collects performance metrics for validation and test splits into a results table, handling failures gracefully. Sorts results for easier comparison.\n"
   ],
   "id": "1390db1f75d264ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODES = globals().get(\"MODES\", [\"single\", \"merged\"])\n",
    "\n",
    "records = []\n",
    "failures = []\n",
    "\n",
    "# Run TabPFN on all tasks in both modes and collect results\n",
    "for task_name in TASKS:\n",
    "    for mode in MODES:\n",
    "        try:\n",
    "            res = run_tabpfn_on_task(DATASET, task_name, mode=mode)\n",
    "            # Flatten metrics for val and test, one metric per row\n",
    "            for split in [\"val\", \"test\"]:\n",
    "                metrics = res.get(f\"{split}_metrics\") or {}\n",
    "                for metric_name, metric_value in metrics.items():\n",
    "                    # Only add rows with non-empty metric_value\n",
    "                    if metric_value is not None and not (isinstance(metric_value, float) and np.isnan(metric_value)):\n",
    "                        records.append({\n",
    "                            \"dataset\": res.get(\"dataset\", DATASET),\n",
    "                            \"task\": res.get(\"task\", task_name),\n",
    "                            \"split\": split,\n",
    "                            \"mode\": res.get(\"mode\", mode),\n",
    "                            \"method\": \"TabPFN_experimental_v1.0\",\n",
    "                            \"metric\": metric_name,\n",
    "                            \"score\": metric_value,\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            msg = f\"[{DATASET} | {task_name} | {mode}] failed: {e!s}\"\n",
    "            print(msg)\n",
    "            failures.append(msg)\n",
    "\n",
    "# Convert collected records into a DataFrame\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# If no successful runs were recorded, display a message and create an empty DataFrame\n",
    "if results_df.empty:\n",
    "    print(\"No successful runs were recorded. Check the failure messages above.\")\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"dataset\", \"task\", \"split\", \"mode\", \"method\", \"metric\", \"score\"]\n",
    "    )\n",
    "else:\n",
    "    # Ensure required sort keys exist even if some rows missed them\n",
    "    for col in [\"task\", \"mode\"]:\n",
    "        if col not in results_df.columns:\n",
    "            results_df[col] = pd.NA\n",
    "    # Sort only by the columns that exist to avoid KeyError\n",
    "    sort_keys = [c for c in [\"task\", \"mode\", \"metric\"] if c in results_df.columns]\n",
    "    if sort_keys:\n",
    "        results_df = results_df.sort_values(sort_keys)\n",
    "\n",
    "display(results_df)\n"
   ],
   "id": "be6242da806a8050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Results to CSV",
   "id": "63c64e43fa5f49a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify output directory\n",
    "out_dir = globals().get(\"OUT_DIR\", \"outputs\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Change timestamp format to \"dd.mm.yyyy-hh:mm\"\n",
    "timestamp = time.strftime(\"%d.%m.%Y-%H:%M\")\n",
    "csv_name = f\"tabpfn_{DATASET}_{timestamp}.csv\"\n",
    "csv_path = os.path.join(out_dir, csv_name)\n",
    "\n",
    "# Round all numerical results to 4 decimal places before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(results_df[\"score\"]):\n",
    "        results_df[\"score\"] = results_df[\"score\"].round(4)\n",
    "    else:\n",
    "        # Optionally, try to convert to numeric first\n",
    "        results_df[\"score\"] = pd.to_numeric(results_df[\"score\"], errors=\"coerce\").round(4)\n",
    "\n",
    "# Filter out rows with empty score values before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    results_df = results_df[results_df[\"score\"].notnull()]\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved results to: {csv_path}\")\n"
   ],
   "id": "aa929637db7d0d54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "51d929bb0341da09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
