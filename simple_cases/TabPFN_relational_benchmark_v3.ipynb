{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TabPFN Relational Benchmark**\n",
    "This notebook benchmarks the performance of TabPFN models on datasets from RelBench in two scenarios:\n",
    "1. **Single Table** – Using only the target entity table.\n",
    "2. **Merged Table** – Using a naively denormalized table obtained by joining related tables.\n",
    "\n",
    "It automates dataset loading, preprocessing (including date feature engineering), vectorization, model training, prediction, and evaluation for all compatible tasks within a chosen RelBench dataset. The results allow comparing model performance between single-table and merged-table configurations.\n"
   ],
   "id": "7ab5a9bf5466de0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "ac93e97c56d4b905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, Any, List, Tuple\n",
    "\n",
    "# --- Skrub / Sentence Transformers ---\n",
    "from skrub import TableVectorizer\n",
    "\n",
    "# --- RelBench ---\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task, get_task_names\n",
    "from relbench.base import TaskType\n",
    "import relbench.metrics\n",
    "\n",
    "# --- TabPFN ---\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# --- Featuretools ---\n",
    "import featuretools as ft"
   ],
   "id": "57624fe02c838842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ],
   "id": "ebce2e3934db1e43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set Global Configuration",
   "id": "7154198e21fe2a01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Device selection (CPU, CUDA, or MPS if available)\n",
    "def get_device():\n",
    "    # Uncomment for auto-detection\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    # elif torch.cuda.is_available():\n",
    "    #     return \"cuda\"\n",
    "    # else:\n",
    "    #     return \"cpu\"\n",
    "    return \"cpu\"  # Default: CPU\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Dataset and experiment settings\n",
    "DATASET        = globals().get(\"DATASET\", \"rel-f1\")           # Default dataset\n",
    "MAIN_TABLE     = globals().get(\"MAIN_TABLE\", \"qualifying\")    # Main table for single-table mode\n",
    "SEED           = globals().get(\"SEED\", 42)                    # Random seed\n",
    "N_ESTIMATORS   = globals().get(\"N_ESTIMATORS\", 16)            # TabPFN estimators\n",
    "TABPFN_MAX     = globals().get(\"TABPFN_MAX\", 10000)            # Max TabPFN samples\n",
    "\n",
    "# getML engine state\n",
    "_ENGINE_STARTED = False\n",
    "\n",
    "# Optional: quiet Featuretools logs\n",
    "ft.config.log_print_threshold = 1000000"
   ],
   "id": "c5959e09ecd4c20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Featuretools knobs (safe defaults)",
   "id": "4c5b68b64b21e661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---- Featuretools knobs (stable across datasets) ----\n",
    "FT_MAX_DEPTH = globals().get(\"FT_MAX_DEPTH\", 2)\n",
    "\n",
    "# Desired primitives (resolved at runtime to what your FT version supports)\n",
    "FT_AGG_PRIMITIVES_WISHLIST = [\"mean\", \"sum\", \"count\", \"n_unique\", \"max\", \"min\", \"std\", \"mode\"]\n",
    "FT_TRANS_PRIMITIVES_WISHLIST = [\"day\", \"month\", \"year\", \"weekday\", \"hour\"]\n",
    "\n",
    "# Drop raw join keys from model inputs (to avoid trivial leakage)\n",
    "DROP_JOIN_KEYS_FROM_X = globals().get(\"DROP_JOIN_KEYS_FROM_X\", True)\n",
    "\n",
    "# ---- Generic PK/FK inference thresholds ----\n",
    "PK_MIN_UNIQUE_RATIO = globals().get(\"PK_MIN_UNIQUE_RATIO\", 0.98)        # exclude constant-ish columns in PK\n",
    "PK_MAX_NULL_RATIO   = globals().get(\"PK_MAX_NULL_RATIO\", 0.02)          # exclude columns with too many nulls\n",
    "FK_COVERAGE_THRESHOLD = globals().get(\"FK_COVERAGE_THRESHOLD\", 0.90)    # minimum referential coverage for FKs\n",
    "FK_MIN_UNIQUE_RATIO = globals().get(\"FK_MIN_UNIQUE_RATIO\", 0.01)        # exclude constant-ish columns in FK\n",
    "FK_MAX_UNIQUE_RATIO = globals().get(\"FK_MAX_UNIQUE_RATIO\", 0.95)        # exclude near-unique -> likely not an FK\n",
    "KEY_NAME_BONUS = globals().get(\"KEY_NAME_BONUS\", 0.05)\n",
    "\n",
    "# Name hint boost: helps columns that *look* like keys to win ties\n",
    "KEY_NAME_BONUS = globals().get(\"KEY_NAME_BONUS\", 0.05)\n"
   ],
   "id": "701d9b49628bf0e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook Configuration and Dataset Selection\n",
    "\n",
    "\n",
    "Sets the dataset name (`DATASET`) and download flag (`DOWNLOAD`), then discovers all available tasks for the selected dataset using RelBench’s APIs. Filters tasks to only those compatible with TabPFN (classification and regression).\n"
   ],
   "id": "a86eaa89573fdf63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reuse existing config if present, otherwise set defaults\n",
    "DATASET = globals().get(\"DATASET\", \"rel-f1\")\n",
    "DOWNLOAD = globals().get(\"DOWNLOAD\", True)\n",
    "\n",
    "# Discover tasks and keep only entity-level cls/reg tasks TabPFN can handle\n",
    "def _is_tabpfn_friendly(task):\n",
    "    \"\"\"\n",
    "    Check if a task is compatible with TabPFN.\n",
    "    \"\"\"\n",
    "    return task.task_type in (\n",
    "        TaskType.BINARY_CLASSIFICATION,\n",
    "        TaskType.MULTICLASS_CLASSIFICATION,\n",
    "        TaskType.MULTILABEL_CLASSIFICATION,\n",
    "        TaskType.REGRESSION,\n",
    "    )\n",
    "\n",
    "_all = get_task_names(DATASET)  # shown in tutorials\n",
    "TASKS = []\n",
    "for tname in _all:\n",
    "    try:\n",
    "        t = get_task(DATASET, tname, download=DOWNLOAD)\n",
    "        if _is_tabpfn_friendly(t):\n",
    "            TASKS.append(tname)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {tname}: {e!s}\")\n",
    "\n",
    "print(f\"{DATASET}: {len(TASKS)} TabPFN-friendly tasks -> {TASKS}\")\n"
   ],
   "id": "d94075cf88bf6806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fetch Dataset Splits\n",
    "\n",
    "Utility functions to load a task’s splits (`train`, `val`, `test`), convert them to pandas DataFrames, and extract features (`X`) and targets (`y`). Includes functions to:\n",
    "* Load train/val/test splits for a task.\n",
    "* Extract features/targets.\n",
    "* Infer primary keys.\n",
    "* Denormalize tables (one-hop join).\n",
    "* Build data frames for both single-table and merged-table scenarios.\n"
   ],
   "id": "1a35d633effdd263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_splits(dataset_name: str, task_name: str, download: bool = True):\n",
    "    \"\"\"\n",
    "    Fetch train/val/test splits for a given dataset and task.\n",
    "    \"\"\"\n",
    "    task = get_task(dataset_name, task_name, download=download)\n",
    "    # keep original columns (mask_input_cols=False so we see raw fields)\n",
    "    splits = {\n",
    "        split: task.get_table(split, mask_input_cols=False)\n",
    "        for split in (\"train\", \"val\", \"test\")\n",
    "    }\n",
    "    return task, splits\n",
    "\n",
    "def to_Xy(df: pd.DataFrame, target_col: str):\n",
    "    y = df[target_col].to_numpy()\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y\n",
    "\n",
    "def build_single_table_frames(task, splits):\n",
    "    \"\"\"\n",
    "    Single-table mode: do NOT engineer features here.\n",
    "    Just return raw base table X, y per split (target dropped from X).\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "\n",
    "    for split, table in splits.items():\n",
    "        df = table.df.copy()\n",
    "\n",
    "        if task.target_col not in df.columns:\n",
    "            raise ValueError(f\"Target column '{task.target_col}' not found in table '{df.name}'\")\n",
    "\n",
    "        X, y = to_Xy(df, task.target_col)\n",
    "        frames[split] = (X, y, df)\n",
    "    return frames\n"
   ],
   "id": "ac5f4a739cba0093",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Featuretools helpers\n",
    "This section contains utility functions for Featuretools integration. It includes PK/FK inference, time detection, and EntitySet building. The PK/FK inference is done with strict name+dtype gating to ensure robustness. "
   ],
   "id": "facab72f26914001"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PK/FK inference (strict name+dtype gating)",
   "id": "27fbf5f3011bd7f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _normalize_name(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a string to a lowercase alphanumeric representation.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-z0-9]', '', str(s).lower())\n",
    "\n",
    "def _name_matches_pk(child_col: str, parent_pk: str) -> bool:\n",
    "    \"\"\"\n",
    "    Require that child column name matches parent PK name (normalized).\n",
    "    \"\"\"\n",
    "    return _normalize_name(child_col) == _normalize_name(parent_pk)\n",
    "\n",
    "def _dtype_category(dt) -> str:\n",
    "    \"\"\"\n",
    "    Determine the category of a pandas dtype.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pandas.api.types as pat\n",
    "        if pat.is_datetime64_any_dtype(dt): return \"dt\"\n",
    "        if pat.is_integer_dtype(dt) or pat.is_bool_dtype(dt): return \"int\"\n",
    "        if pat.is_float_dtype(dt): return \"float\"\n",
    "        if pat.is_string_dtype(dt) or dt == object: return \"str\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"other\"\n",
    "\n",
    "def _dtype_compatible(dt_parent, dt_child) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if two dtypes are compatible for PK/FK relationships.\n",
    "    \"\"\"\n",
    "    a, b = _dtype_category(dt_parent), _dtype_category(dt_child)\n",
    "    if a == \"int\" and b == \"int\": return True\n",
    "    if a == \"str\" and b == \"str\": return True\n",
    "    return False"
   ],
   "id": "aa39b143967388db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PK/FK inference helpers (PK candidate)",
   "id": "d2a611da17e857b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _clean_for_ft(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dtype cleanup for Featuretools:\n",
    "      - convert object/string columns to categorical,\n",
    "      - parse datetime-like columns,\n",
    "      - ensure no mixed dtypes in columns.\n",
    "    \"\"\"\n",
    "    x = df.copy()\n",
    "    # parse only strong time-like names\n",
    "    for c in x.columns:\n",
    "        if _looks_like_time_name(c) and not pd.api.types.is_datetime64_any_dtype(x[c]):\n",
    "            try:\n",
    "                parsed = pd.to_datetime(x[c], errors=\"coerce\")\n",
    "                if parsed.notna().sum() > 0 and parsed.nunique(dropna=True) > 1:\n",
    "                    x[c] = parsed\n",
    "            except Exception:\n",
    "                pass\n",
    "    return x\n",
    "\n",
    "def _is_key_like(colname: str) -> bool:\n",
    "    \"\"\"\n",
    "    key-like name detection:\n",
    "      - ends with _id, id, _key, key (case-insensitive),\n",
    "      - ends with ID or Id (case-sensitive).\n",
    "    \"\"\"\n",
    "    s = str(colname)\n",
    "    sl = s.lower()\n",
    "    return (\n",
    "        sl.endswith(\"_id\") or sl.endswith(\"id\") or\n",
    "        sl.endswith(\"_key\") or sl.endswith(\"key\") or\n",
    "        s.endswith(\"ID\") or s.endswith(\"Id\")\n",
    "    )\n",
    "\n",
    "def _score_pk(series: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    PK score based on uniqueness and null ratio\n",
    "    \"\"\"\n",
    "    n = len(series)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    nunq = series.nunique(dropna=True)\n",
    "    null_ratio = 1.0 - series.notna().mean()\n",
    "    unique_ratio = nunq / max(1, n)\n",
    "    score = unique_ratio - null_ratio  # prefer unique, penalize nulls\n",
    "    if _is_key_like(series.name):\n",
    "        score += KEY_NAME_BONUS\n",
    "    return float(score)\n",
    "\n",
    "def _candidate_pk(df: pd.DataFrame) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Candidate primary key detection\n",
    "    \"\"\"\n",
    "    best_col, best_score = None, -1.0\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        # quick skip for obvious non-keys\n",
    "        if pd.api.types.is_float_dtype(s) and not pd.api.types.is_integer_dtype(s):\n",
    "            # allow floats only if they look like ints after dropna\n",
    "            if not np.allclose(s.dropna() % 1, 0):\n",
    "                continue\n",
    "        sc = _score_pk(s)\n",
    "        if sc > best_score:\n",
    "            best_col, best_score = c, sc\n",
    "    # require thresholds\n",
    "    if best_col is None:\n",
    "        return None\n",
    "    s = df[best_col]\n",
    "    nunq = s.nunique(dropna=True)\n",
    "    n = len(s)\n",
    "    null_ratio = 1.0 - s.notna().mean()\n",
    "    if (nunq / max(1, n) >= PK_MIN_UNIQUE_RATIO) and (null_ratio <= PK_MAX_NULL_RATIO):\n",
    "        return best_col\n",
    "    return None"
   ],
   "id": "32f1a606727db779",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time detection (strict; never equals PK)\n",
   "id": "9edc8df5c89dccdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_TIME_NAME_PATTERN = re.compile(\n",
    "    r\"(^|[_])(\"\n",
    "    r\"timestamp|datetime|event_time|eventtime|time|date|dt|\"\n",
    "    r\"created_at|updated_at|inserted_at|occurred_at|recorded_at\"\n",
    "    r\")([_]|$)\", re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def _looks_like_time_name(colname: str) -> bool:\n",
    "    \"\"\"\n",
    "    Time-like name detection\n",
    "    \"\"\"\n",
    "    name = str(colname)\n",
    "    if name.lower() == \"ts\" or name.lower().startswith(\"ts_\") or name.lower().endswith(\"_ts\"):\n",
    "        return True\n",
    "    return _TIME_NAME_PATTERN.search(name) is not None\n",
    "\n",
    "def _detect_time_col(df: pd.DataFrame, pk: Optional[str] = None) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to detect a time-like column in the DataFrame.\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        if c == pk:\n",
    "            continue\n",
    "        if not _looks_like_time_name(c):\n",
    "            continue\n",
    "        s = df[c]\n",
    "        if not pd.api.types.is_datetime64_any_dtype(s):\n",
    "            try:\n",
    "                s = pd.to_datetime(s, errors=\"coerce\")\n",
    "            except Exception:\n",
    "                continue\n",
    "        if s.notna().sum() > 0 and s.nunique(dropna=True) > 1:\n",
    "            return c\n",
    "    return None"
   ],
   "id": "508ed4a66468fa28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PK/FK inference across all tables (incl. MAIN_TABLE)",
   "id": "d1d5ee815a18d66b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _infer_pk_fk_graph(all_tables: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Schema-agnostic PK/FK inference with strict name+dtype gating:\n",
    "      - pick single-column PK by uniqueness/nulls (+name hint),\n",
    "      - propose FKs only when child column NAME == parent PK NAME (normalized),\n",
    "      - require dtype compatibility, not-near-unique child, and high referential coverage,\n",
    "      - forbid child's own PK as FK; forbid self-relationships.\n",
    "    \"\"\"\n",
    "    # 1) PKs\n",
    "    pkeys: Dict[str, Optional[str]] = {}\n",
    "    for tname, df in all_tables.items():\n",
    "        pkeys[tname] = _candidate_pk(df)\n",
    "\n",
    "    # 2) parent PK value sets + dtypes\n",
    "    parent_values: Dict[str, set] = {}\n",
    "    parent_pk_dtype: Dict[str, Any] = {}\n",
    "    for parent, pk in pkeys.items():\n",
    "        if pk and pk in all_tables[parent].columns:\n",
    "            parent_pk_dtype[parent] = all_tables[parent][pk].dtype\n",
    "            vals = pd.Series(all_tables[parent][pk]).dropna().astype(str).unique()\n",
    "            if len(vals) > 0:\n",
    "                parent_values[parent] = set(vals.tolist())\n",
    "\n",
    "    # 3) scan child tables for key-like columns that *name-match* a parent PK\n",
    "    fkeys: Dict[str, List[Dict[str, Any]]] = {parent: [] for parent in all_tables.keys()}\n",
    "    reasons: List[str] = []\n",
    "\n",
    "    for child, cdf in all_tables.items():\n",
    "        child_pk = pkeys.get(child)\n",
    "        for parent, pk in pkeys.items():\n",
    "            if not pk:\n",
    "                continue\n",
    "            if parent == child:\n",
    "                continue\n",
    "            if parent not in parent_values:\n",
    "                continue\n",
    "\n",
    "            # candidate child columns whose NAME matches the parent's PK\n",
    "            for col in cdf.columns:\n",
    "                if col == child_pk:\n",
    "                    continue\n",
    "                if not _name_matches_pk(col, pk):\n",
    "                    continue\n",
    "                # dtype compatibility\n",
    "                if not _dtype_compatible(parent_pk_dtype.get(parent, None), cdf[col].dtype):\n",
    "                    continue\n",
    "                # child column cardinality constraints (many-to-one)\n",
    "                s = cdf[col].dropna()\n",
    "                if s.empty:\n",
    "                    continue\n",
    "                nunq = s.nunique(dropna=True)\n",
    "                uniq_ratio = nunq / max(1, len(s))\n",
    "                if uniq_ratio < FK_MIN_UNIQUE_RATIO or uniq_ratio > FK_MAX_UNIQUE_RATIO:\n",
    "                    continue\n",
    "                # referential coverage check\n",
    "                coverage = (s.astype(str).isin(pd.Series(list(parent_values[parent])))).mean()\n",
    "                if coverage >= FK_COVERAGE_THRESHOLD:\n",
    "                    lst = fkeys.setdefault(parent, [])\n",
    "                    if not any(r[\"child\"] == child and r[\"fk\"] == col for r in lst):\n",
    "                        lst.append({\"child\": child, \"fk\": col, \"coverage\": float(coverage)})\n",
    "                        reasons.append(f\"{parent}.{pk} <- {child}.{col} (coverage={coverage:.3f})\")\n",
    "\n",
    "    return {\"pkeys\": pkeys, \"fkeys\": fkeys, \"debug\": {\"reasons\": reasons}}\n",
    "\n",
    "\n",
    "def _prune_fk_cycles(schema: Dict[str, Dict[str, Any]], base_name: str) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Remove edges that introduce cycles. Preference:\n",
    "      - keep edges incident to the MAIN_TABLE (base_name),\n",
    "      - keep edges with higher coverage,\n",
    "      - drop the weakest edge per detected cycle.\n",
    "    \"\"\"\n",
    "    pkeys = schema[\"pkeys\"]\n",
    "    fkeys = {k: list(v) for k, v in schema[\"fkeys\"].items()}\n",
    "\n",
    "    def edges():\n",
    "        for parent, rels in fkeys.items():\n",
    "            for r in rels:\n",
    "                yield (parent, r[\"child\"], r)\n",
    "\n",
    "    # build adjacency\n",
    "    def build_adj():\n",
    "        adj = {}\n",
    "        for u, v, r in edges():\n",
    "            adj.setdefault(u, []).append((v, r))\n",
    "        return adj\n",
    "\n",
    "    # cycle detection via DFS\n",
    "    def find_cycle():\n",
    "        adj = build_adj()\n",
    "        visited, stack = {}, []\n",
    "        def dfs(u):\n",
    "            visited[u] = 1\n",
    "            stack.append(u)\n",
    "            for v, r in adj.get(u, []):\n",
    "                if visited.get(v, 0) == 0:\n",
    "                    cyc = dfs(v)\n",
    "                    if cyc: return cyc\n",
    "                elif visited.get(v, 0) == 1:\n",
    "                    # cycle found: collect path u->...->v\n",
    "                    if v in stack:\n",
    "                        i = stack.index(v)\n",
    "                        cyc_nodes = stack[i:] + [v]\n",
    "                        cyc_edges = []\n",
    "                        # collect edges on this cycle\n",
    "                        for a, b in zip(cyc_nodes, cyc_nodes[1:]):\n",
    "                            # find the relationship object\n",
    "                            rel = None\n",
    "                            for nb, r2 in adj.get(a, []):\n",
    "                                if nb == b:\n",
    "                                    rel = r2; break\n",
    "                            if rel: cyc_edges.append((a, b, rel))\n",
    "                        return cyc_edges\n",
    "            stack.pop()\n",
    "            visited[u] = 2\n",
    "            return None\n",
    "\n",
    "        for u in set(list(pkeys.keys()) + [base_name]):\n",
    "            if visited.get(u, 0) == 0:\n",
    "                cyc = dfs(u)\n",
    "                if cyc: return cyc\n",
    "        return None\n",
    "\n",
    "    # iteratively prune one weakest edge per cycle\n",
    "    removed = 0\n",
    "    while True:\n",
    "        cyc = find_cycle()\n",
    "        if not cyc:\n",
    "            break\n",
    "        # pick edge to drop: avoid dropping edges touching base_name if possible; lowest coverage wins\n",
    "        cand = []\n",
    "        for a, b, r in cyc:\n",
    "            score = r.get(\"coverage\", 0.0)\n",
    "            touches_base = int(a == base_name or b == base_name)\n",
    "            cand.append((touches_base, score, a, b, r))\n",
    "        # sort: prefer removing edges NOT touching base_name, and with lowest coverage\n",
    "        cand.sort(key=lambda x: (x[0], x[1]))\n",
    "        _, _, a, b, r = cand[0]\n",
    "        # remove\n",
    "        fkeys[a] = [x for x in fkeys.get(a, []) if not (x[\"child\"] == b and x[\"fk\"] == r[\"fk\"])]\n",
    "        removed += 1\n",
    "    if removed:\n",
    "        print(f\"[Schema] Pruned {removed} cyclic relationship(s)\")\n",
    "    return {\"pkeys\": pkeys, \"fkeys\": fkeys, \"debug\": schema.get(\"debug\", {})}"
   ],
   "id": "9fd3745d11bf4a0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### EntitySet builder (safe: never PK equals time_index)",
   "id": "ec69833bb9c3cfcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _make_es_for_split(base_name: str,\n",
    "                       pop_df: pd.DataFrame,\n",
    "                       all_tables: Dict[str, pd.DataFrame],\n",
    "                       schema: Dict[str, Dict[str, Any]]) -> ft.EntitySet:\n",
    "    \"\"\"\n",
    "    Extract a Featuretools EntitySet from the given base table and all related tables.\n",
    "    \"\"\"\n",
    "    es = ft.EntitySet(id=f\"rb_es_{base_name}\")\n",
    "\n",
    "    def _add_df_safe(es_obj, name, df, pk_candidate):\n",
    "        df = _clean_for_ft(df)\n",
    "        # index\n",
    "        if pk_candidate is None or pk_candidate not in df.columns:\n",
    "            idx = f\"{name}__ft_index\"; make_idx = True\n",
    "        else:\n",
    "            idx = pk_candidate; make_idx = False\n",
    "        # time index\n",
    "        tcol = _detect_time_col(df, pk=idx)\n",
    "        if tcol is not None and tcol == idx:\n",
    "            tcol = None\n",
    "        if tcol is not None and not pd.api.types.is_datetime64_any_dtype(df[tcol]):\n",
    "            tcol = None\n",
    "\n",
    "        if make_idx:\n",
    "            return es_obj.add_dataframe(dataframe_name=name, dataframe=df, index=idx, make_index=True, time_index=tcol), idx\n",
    "        else:\n",
    "            return es_obj.add_dataframe(dataframe_name=name, dataframe=df, index=idx, time_index=tcol), idx\n",
    "\n",
    "    # add MAIN_TABLE\n",
    "    pop_pk = schema[\"pkeys\"].get(base_name)\n",
    "    es, pop_idx = _add_df_safe(es, base_name, pop_df, pop_pk)\n",
    "\n",
    "    # add other tables\n",
    "    for tname, df in all_tables.items():\n",
    "        if tname == base_name:\n",
    "            continue\n",
    "        pk = schema[\"pkeys\"].get(tname)\n",
    "        es, _ = _add_df_safe(es, tname, df, pk)\n",
    "\n",
    "    # relationships (parent: one, child: many; FK lives on child)\n",
    "    rel_added, rel_skipped = 0, 0\n",
    "    for parent, rels in schema[\"fkeys\"].items():\n",
    "        if parent not in es.dataframe_dict:\n",
    "            continue\n",
    "        parent_pk = schema[\"pkeys\"].get(parent) or f\"{parent}__ft_index\"\n",
    "        for r in rels:\n",
    "            child = r[\"child\"]; fk = r[\"fk\"]\n",
    "            if child not in es.dataframe_dict:\n",
    "                rel_skipped += 1; continue\n",
    "            child_idx = es[child].ww.index\n",
    "            # Skip if FK column is the child's index (illegal in FT) or missing\n",
    "            if fk == child_idx or fk not in es[child].ww.columns:\n",
    "                rel_skipped += 1; continue\n",
    "            es = es.add_relationship(parent_dataframe_name=parent,\n",
    "                                     parent_column_name=parent_pk,\n",
    "                                     child_dataframe_name=child,\n",
    "                                     child_column_name=fk)\n",
    "            rel_added += 1\n",
    "\n",
    "    return es"
   ],
   "id": "b0227d63477a2d2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Primitive resolver",
   "id": "4427b65cfdb9e1d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _resolve_ft_primitives(agg_wishlist: list, trans_wishlist: list) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Resolve Featuretools primitives based on wishlist and available primitives.\n",
    "    \"\"\"\n",
    "    prim_df = ft.primitives.list_primitives()\n",
    "    have_agg = set(prim_df[prim_df.type == \"aggregation\"].name.str.lower())\n",
    "    have_trans = set(prim_df[prim_df.type == \"transform\"].name.str.lower())\n",
    "\n",
    "    alias_groups_agg = [\n",
    "        {\"n_unique\", \"nunique\", \"num_unique\", \"count_unique\"},\n",
    "        {\"mode\", \"mode_agg\"},\n",
    "        {\"std\", \"standard_deviation\"},\n",
    "        {\"count\"}\n",
    "    ]\n",
    "    alias_groups_trans = [\n",
    "        {\"weekday\", \"week_day\"},\n",
    "        {\"year\"}, {\"month\"}, {\"day\"}, {\"hour\"}\n",
    "    ]\n",
    "    def pick(wish, have, groups):\n",
    "        out = []\n",
    "        for w in [w.lower() for w in wish]:\n",
    "            if w in have:\n",
    "                out.append(w); continue\n",
    "            matched = False\n",
    "            for g in groups:\n",
    "                if w in g:\n",
    "                    for cand in g:\n",
    "                        if cand in have:\n",
    "                            out.append(cand); matched = True; break\n",
    "                if matched: break\n",
    "        # ensure some basics\n",
    "        if not out and have:\n",
    "            for fb in [\"mean\", \"sum\", \"count\", \"max\", \"min\"]:\n",
    "                if fb in have: out.append(fb)\n",
    "        # dedupe\n",
    "        seen, uniq = set(), []\n",
    "        for p in out:\n",
    "            if p not in seen: seen.add(p); uniq.append(p)\n",
    "        return uniq\n",
    "    return pick(agg_wishlist, have_agg, alias_groups_agg), pick(trans_wishlist, have_trans, alias_groups_trans)"
   ],
   "id": "135b0bc9ce648d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DFS (train -> reuse on val/test)",
   "id": "ee4011449c6bffb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _dfs_feature_matrices(es_train: ft.EntitySet,\n",
    "                          es_val: ft.EntitySet,\n",
    "                          es_test: ft.EntitySet,\n",
    "                          target_df: str):\n",
    "    \"\"\"\n",
    "    Run Featuretools DFS on the training EntitySet and reuse the feature definitions on validation and test sets.\n",
    "    \"\"\"\n",
    "    agg_prims, trans_prims = _resolve_ft_primitives(FT_AGG_PRIMITIVES_WISHLIST, FT_TRANS_PRIMITIVES_WISHLIST)\n",
    "\n",
    "    fm_train, fdefs = ft.dfs(\n",
    "        entityset=es_train,\n",
    "        target_dataframe_name=target_df,\n",
    "        agg_primitives=agg_prims,\n",
    "        trans_primitives=trans_prims,\n",
    "        max_depth=FT_MAX_DEPTH,\n",
    "        features_only=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    fm_val = ft.calculate_feature_matrix(features=fdefs, entityset=es_val, verbose=False)\n",
    "    fm_test = ft.calculate_feature_matrix(features=fdefs, entityset=es_test, verbose=False)\n",
    "\n",
    "    # align columns\n",
    "    fm_val = fm_val.reindex(columns=fm_train.columns, fill_value=np.nan)\n",
    "    fm_test = fm_test.reindex(columns=fm_train.columns, fill_value=np.nan)\n",
    "\n",
    "    return fm_train, fm_val, fm_test, fdefs\n"
   ],
   "id": "6505961cff9554c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Merged-Table Frames",
   "id": "48d1dac2d154369a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_merged_table_frames(dataset, task, splits):\n",
    "    \"\"\"\n",
    "    Generic merged features with Featuretools:\n",
    "    - load ALL tables as pandas,\n",
    "    - include TRAIN MAIN_TABLE table in PK/FK inference,\n",
    "    - infer PK/FK graph automatically (unique ratio + coverage),\n",
    "    - build EntitySet per split,\n",
    "    - DFS on train, reuse features on val/test,\n",
    "    - drop join keys from X and never include target in X,\n",
    "    - return dict with (X, y, engineered_df) per split.\n",
    "    \"\"\"\n",
    "    # --- Load DB tables (pandas) ---\n",
    "    db = dataset.get_db()\n",
    "    all_tables: Dict[str, pd.DataFrame] = {\n",
    "        name: (tbl.df.copy() if hasattr(tbl, \"df\") else tbl.to_pandas())\n",
    "        for name, tbl in db.table_dict.items()\n",
    "    }\n",
    "    all_tables = {k: _clean_for_ft(v) for k, v in all_tables.items()}\n",
    "\n",
    "    base_name = getattr(splits[\"train\"], \"name\", MAIN_TABLE)\n",
    "    # include MAIN_TABLE (TRAIN) into inference so relations can touch the target df\n",
    "    pop = {split: tbl.df.copy() for split, tbl in splits.items()}\n",
    "    combined_for_schema = dict(all_tables)\n",
    "    combined_for_schema[base_name] = _clean_for_ft(pop[\"train\"].copy())\n",
    "\n",
    "    # --- Automatic PK/FK inference (no manual schema) ---\n",
    "    schema = _infer_pk_fk_graph(combined_for_schema)\n",
    "\n",
    "    # --- Prune cycles to prevent DFS recursion ---\n",
    "    schema = _prune_fk_cycles(schema, base_name=base_name)\n",
    "\n",
    "    if not schema.get(\"debug\", {}).get(\"reasons\"):\n",
    "        print(\"[Schema] WARNING: no relationships inferred. Consider lowering FK_COVERAGE_THRESHOLD.\")\n",
    "\n",
    "    # --- Build ES per split with the same schema ---\n",
    "    es_train = _make_es_for_split(base_name, pop[\"train\"], all_tables, schema)\n",
    "    es_val   = _make_es_for_split(base_name, pop[\"val\"],   all_tables, schema)\n",
    "    es_test  = _make_es_for_split(base_name, pop[\"test\"],  all_tables, schema)\n",
    "\n",
    "    # --- DFS and aligned feature matrices ---\n",
    "    fe_train, fe_val, fe_test, feature_defs = _dfs_feature_matrices(es_train, es_val, es_test, target_df=base_name)\n",
    "\n",
    "    # --- Prepare (X, y) and drop keys/target from X ---\n",
    "    def _drop_keys(dfX: pd.DataFrame) -> pd.DataFrame:\n",
    "        if not DROP_JOIN_KEYS_FROM_X:\n",
    "            return dfX\n",
    "        drop_cols = set()\n",
    "        pop_pk = schema[\"pkeys\"].get(base_name)\n",
    "        if pop_pk and pop_pk in dfX.columns:\n",
    "            drop_cols.add(pop_pk)\n",
    "        for parent, rels in schema[\"fkeys\"].items():\n",
    "            for r in rels:\n",
    "                fk = r[\"fk\"]\n",
    "                if fk in dfX.columns:\n",
    "                    drop_cols.add(fk)\n",
    "        return dfX.drop(columns=list(drop_cols), errors=\"ignore\")\n",
    "\n",
    "    def _to_Xy(fe_df: pd.DataFrame, raw_df: pd.DataFrame):\n",
    "        X = fe_df.copy()\n",
    "        if task.target_col in X.columns:\n",
    "            X = X.drop(columns=[task.target_col], errors=\"ignore\")\n",
    "        X = _drop_keys(X)\n",
    "        y = raw_df[task.target_col].to_numpy()\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = _to_Xy(fe_train, pop[\"train\"])\n",
    "    Xva, yva = _to_Xy(fe_val,   pop[\"val\"])\n",
    "    Xte, yte = _to_Xy(fe_test,  pop[\"test\"])\n",
    "\n",
    "    return {\n",
    "        \"train\": (Xtr, ytr, fe_train),\n",
    "        \"val\":   (Xva, yva, fe_val),\n",
    "        \"test\":  (Xte, yte, fe_test),\n",
    "    }\n"
   ],
   "id": "1e53fa004c6c4217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorization Wrapper (Version-Safe)\n",
    "\n",
    "Initializes a `TableVectorizer` with only supported arguments for the installed `skrub` or `dirty_cat` version, ensuring compatibility. Transforms `train`, `val`, and `test` splits into numerical feature matrices, converting them to dense format if necessary.\n"
   ],
   "id": "f7cf59b1861625f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper Functions for Vectorization",
   "id": "ff99875cd0db904d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _make_table_vectorizer():\n",
    "    \"\"\"\n",
    "    Create a TableVectorizer with version-safe arguments.\n",
    "    \"\"\"\n",
    "    sig = inspect.signature(TableVectorizer.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    tv_kwargs = {}\n",
    "\n",
    "    # Only set kwargs that actually exist in the installed version\n",
    "    if \"cardinality_threshold\" in allowed:\n",
    "        tv_kwargs[\"cardinality_threshold\"] = globals().get(\"CARDINALITY_THRESHOLD\", 1000)\n",
    "\n",
    "    # Some versions expose this; others don't, guard it\n",
    "    if \"high_cardinality_transformer\" in allowed:\n",
    "        tv_kwargs[\"high_cardinality_transformer\"] = globals().get(\"HIGH_CARD_TRANSFORMER\", \"hashing\")\n",
    "\n",
    "    # Optional knobs if you define them globally and the version supports them\n",
    "    if \"text_separator\" in allowed and \"TEXT_SEPARATOR\" in globals():\n",
    "        tv_kwargs[\"text_separator\"] = globals()[\"TEXT_SEPARATOR\"]\n",
    "    if \"numerical_transformer\" in allowed and \"NUMERICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"numerical_transformer\"] = globals()[\"NUMERICAL_TRANSFORMER\"]\n",
    "    if \"categorical_transformer\" in allowed and \"CATEGORICAL_TRANSFORMER\" in globals():\n",
    "        tv_kwargs[\"categorical_transformer\"] = globals()[\"CATEGORICAL_TRANSFORMER\"]\n",
    "\n",
    "    return TableVectorizer(**tv_kwargs)\n",
    "\n",
    "def _to_dense(X):\n",
    "    \"\"\"\n",
    "    Convert a sparse matrix to a dense NumPy array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # scipy sparse matrices have .toarray()\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "    except Exception:\n",
    "        return X\n",
    "\n",
    "def vectorize_splits(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Vectorize train, val, and test splits using a TableVectorizer.\n",
    "    \"\"\"\n",
    "    # Fit only on training data to prevent data leakage\n",
    "    tv = _make_table_vectorizer()\n",
    "    Xt = _to_dense(tv.fit_transform(X_train))\n",
    "    Xv = _to_dense(tv.transform(X_val))\n",
    "    Xs = _to_dense(tv.transform(X_test))\n",
    "    return tv, Xt, Xv, Xs\n"
   ],
   "id": "ffb43a27c3ac51cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and Prediction Helpers",
   "id": "e135f05177e4b188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _subsample(X, y, cap=TABPFN_MAX, seed=SEED):\n",
    "    \"\"\"\n",
    "    Subsample the dataset to a maximum size defined by `cap`.\n",
    "    \"\"\"\n",
    "    if len(X) <= cap:\n",
    "        return X, y, np.arange(len(X))\n",
    "    idx = np.random.RandomState(seed).choice(len(X), size=cap, replace=False)\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        Xs = X.iloc[idx]\n",
    "    else:\n",
    "        Xs = X[idx]\n",
    "    ys = y[idx]\n",
    "    return Xs, ys, idx\n",
    "\n",
    "def _fit_tabpfn(task, Xt, yt):\n",
    "    \"\"\"\n",
    "    Fit a TabPFN model for the given task type.\n",
    "    \"\"\"\n",
    "    if task.task_type == TaskType.REGRESSION and TabPFNRegressor is not None:\n",
    "        model = TabPFNRegressor(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    else:\n",
    "        model = TabPFNClassifier(\n",
    "            device=DEVICE,\n",
    "            #n_estimators=int(N_ESTIMATORS),\n",
    "            ignore_pretraining_limits=True,\n",
    "        )\n",
    "    model.fit(Xt, yt)\n",
    "    return model\n",
    "\n",
    "def _predict_for_task(task, model, X):\n",
    "    \"\"\"\n",
    "    Make predictions using the fitted model for the given task type.\n",
    "    \"\"\"\n",
    "    # align with RelBench evaluators: AUROC expects probabilities for the positive class\n",
    "    if task.task_type == TaskType.REGRESSION:\n",
    "        return model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    if task.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "        return proba[:, 1]\n",
    "    else:\n",
    "        # multiclass/multilabel: pass full probability matrix\n",
    "        return proba"
   ],
   "id": "5c53f649ce01b948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run TabPFN on Selected Tasks\n",
    "\n",
    "Runs TabPFN on a specified dataset and task, handling both single-table and merged-table modes. It vectorizes the data, fits the model, makes predictions, and evaluates performance using RelBench’s evaluators. Returns a dictionary with results."
   ],
   "id": "21448305df117a22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display\n",
    "dataset = get_dataset(DATASET, download=DOWNLOAD)\n",
    "\n",
    "for task_name in TASKS:\n",
    "    task, splits = fetch_splits(DATASET, task_name, download=DOWNLOAD)\n",
    "\n",
    "    frames_single = build_single_table_frames(task, splits)\n",
    "    frames_merged = build_merged_table_frames(dataset, task, splits)\n",
    "\n",
    "    print(f\"Task: {task_name} | Single-table vs Merged-table comparison\")\n",
    "    print(\"Single-table (train) head:\")\n",
    "    display(frames_single[\"train\"][2].head(5))\n",
    "\n",
    "    print(\"\\nMerged-table (train) head:\")\n",
    "    display(frames_merged[\"train\"][2].head(5))"
   ],
   "id": "1a124faf7a2ca60d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_tabpfn_on_task(dataset_name: str, task_name: str, mode: str = \"single\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run TabPFN on a specified dataset and task, handling both single-table and merged-table modes.\n",
    "    \"\"\"\n",
    "    # Load dataset and task splits\n",
    "    dataset = get_dataset(dataset_name, download=DOWNLOAD)\n",
    "    task, splits = fetch_splits(dataset_name, task_name, download=DOWNLOAD)\n",
    "\n",
    "    # Ensure the task is compatible with TabPFN\n",
    "    if mode == \"single\":\n",
    "        frames = build_single_table_frames(task, splits)\n",
    "    elif mode == \"merged\":\n",
    "        try:\n",
    "            frames = build_merged_table_frames(dataset, task, splits)\n",
    "        except Exception as e:\n",
    "            print(f\"merged mode failed: {e}, falling back to single-table mode.\")\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'single' or 'merged'\")\n",
    "\n",
    "    # Extract features and targets for each split\n",
    "    (Xtr, ytr, _dftr) = frames[\"train\"]\n",
    "    (Xva, yva, dfva)  = frames[\"val\"]\n",
    "    (Xte, yte, dfte)  = frames[\"test\"]\n",
    "\n",
    "    # Vectorize\n",
    "    tv, Xt, Xv, Xs = vectorize_splits(Xtr, Xva, Xte)\n",
    "\n",
    "    # Respect TabPFN's sample cap\n",
    "    Xt_cap, yt_cap, _ = _subsample(Xt, ytr, cap=TABPFN_MAX, seed=SEED)\n",
    "\n",
    "    # Fit\n",
    "    model = _fit_tabpfn(task, Xt_cap, yt_cap)\n",
    "\n",
    "    # Predict & Evaluate with RelBench evaluators\n",
    "    val_pred  = _predict_for_task(task, model, Xv)\n",
    "    test_pred = _predict_for_task(task, model, Xs)\n",
    "\n",
    "    # Align predictions with original DataFrame indices for evaluation\n",
    "    val_metrics  = task.evaluate(val_pred,  splits[\"val\"])\n",
    "    test_metrics = task.evaluate(test_pred, splits[\"test\"])\n",
    "\n",
    "    # Convert metrics to a dictionary, ensuring all values are floats\n",
    "    out = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"task\": task_name,\n",
    "        \"mode\": mode,\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"n_train_used\": len(Xt_cap),\n",
    "        \"n_train_total\": len(Xt),\n",
    "        \"n_val\": len(Xv),\n",
    "        \"n_test\": len(Xs),\n",
    "    }\n",
    "    return out"
   ],
   "id": "52860c3ba39daf4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Orchestrator for Benchmark Runs\n",
    "\n",
    "Iterates over all discovered tasks and runs TabPFN in both **single** and **merged** modes. Collects performance metrics for validation and test splits into a results table, handling failures gracefully. Sorts results for easier comparison.\n"
   ],
   "id": "67ce1925dce06a6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODES = globals().get(\"MODES\", [\"single\", \"merged\"])\n",
    "\n",
    "records = []\n",
    "failures = []\n",
    "\n",
    "# Run TabPFN on all tasks in both modes and collect results\n",
    "for task_name in TASKS:\n",
    "    for mode in MODES:\n",
    "        try:\n",
    "            res = run_tabpfn_on_task(DATASET, task_name, mode=mode)\n",
    "            # Flatten metrics for val and test, one metric per row\n",
    "            for split in [\"val\", \"test\"]:\n",
    "                metrics = res.get(f\"{split}_metrics\") or {}\n",
    "                for metric_name, metric_value in metrics.items():\n",
    "                    # Only add rows with non-empty metric_value\n",
    "                    if metric_value is not None and not (isinstance(metric_value, float) and np.isnan(metric_value)):\n",
    "                        records.append({\n",
    "                            \"dataset\": res.get(\"dataset\", DATASET),\n",
    "                            \"task\": res.get(\"task\", task_name),\n",
    "                            \"split\": split,\n",
    "                            \"mode\": res.get(\"mode\", mode),\n",
    "                            \"method\": \"TabPFN_experimental_v1.0\",\n",
    "                            \"metric\": metric_name,\n",
    "                            \"score\": metric_value,\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            msg = f\"[{DATASET} | {task_name} | {mode}] failed: {e!s}\"\n",
    "            print(msg)\n",
    "            failures.append(msg)\n",
    "\n",
    "# Convert collected records into a DataFrame\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# If no successful runs were recorded, display a message and create an empty DataFrame\n",
    "if results_df.empty:\n",
    "    print(\"No successful runs were recorded. Check the failure messages above.\")\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"dataset\", \"task\", \"split\", \"mode\", \"method\", \"metric\", \"score\"]\n",
    "    )\n",
    "else:\n",
    "    # Ensure required sort keys exist even if some rows missed them\n",
    "    for col in [\"task\", \"mode\"]:\n",
    "        if col not in results_df.columns:\n",
    "            results_df[col] = pd.NA\n",
    "    # Sort only by the columns that exist to avoid KeyError\n",
    "    sort_keys = [c for c in [\"task\", \"mode\", \"metric\"] if c in results_df.columns]\n",
    "    if sort_keys:\n",
    "        results_df = results_df.sort_values(sort_keys)\n",
    "\n",
    "results_df"
   ],
   "id": "8119d8844ebded86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Results to CSV",
   "id": "77a4dc93cb1858d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify output directory\n",
    "out_dir = globals().get(\"OUT_DIR\", \"outputs\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Change timestamp format to \"dd.mm.yyyy-hh:mm\"\n",
    "timestamp = time.strftime(\"%d.%m.%Y-%H:%M\")\n",
    "csv_name = f\"tabpfn_{DATASET}_{timestamp}.csv\"\n",
    "csv_path = os.path.join(out_dir, csv_name)\n",
    "\n",
    "# Round all numerical results to 4 decimal places before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(results_df[\"score\"]):\n",
    "        results_df[\"score\"] = results_df[\"score\"].round(4)\n",
    "    else:\n",
    "        # Optionally, try to convert to numeric first\n",
    "        results_df[\"score\"] = pd.to_numeric(results_df[\"score\"], errors=\"coerce\").round(4)\n",
    "\n",
    "# Filter out rows with empty score values before saving\n",
    "if \"score\" in results_df.columns:\n",
    "    results_df = results_df[results_df[\"score\"].notnull()]\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved results to: {csv_path}\")\n"
   ],
   "id": "c13a29742326995c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
