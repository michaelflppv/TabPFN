{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T11:56:36.126189Z",
     "start_time": "2025-08-13T11:56:36.122056Z"
    }
   },
   "source": [
    "# %%\n",
    "import os\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "# RelBench\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# Device preference\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T11:56:36.144693Z",
     "start_time": "2025-08-13T11:56:36.141606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = time.perf_counter()\n",
    "    yield lambda: time.perf_counter() - start\n",
    "\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        out[\"roc_auc\"] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def regression_metrics(y_true, y_pred) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "    }\n"
   ],
   "id": "4f09b9768ee9fdcb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T11:56:36.219317Z",
     "start_time": "2025-08-13T11:56:36.154573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "dataset = get_dataset(\"rel-f1\")\n",
    "db = dataset.get_db()\n",
    "\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Load key tables\n",
    "tables = {}\n",
    "for name in db.table_dict:\n",
    "    tables[name] = to_pandas(db.table_dict[name])\n",
    "\n",
    "for t in tables.values():\n",
    "    for col in t.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            t[col] = pd.to_datetime(t[col], errors=\"coerce\")\n"
   ],
   "id": "830e3b724db7392",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T11:56:36.230494Z",
     "start_time": "2025-08-13T11:56:36.227447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "def run_single_table_experiment(task_name: str):\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    X_train, y_train = task.get_X_y(\"train\")\n",
    "    X_val, y_val     = task.get_X_y(\"val\")\n",
    "    X_test, y_test   = task.get_X_y(\"test\")\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": task.evaluate(prob_val if prob_val is not None else y_val_pred, \"val\")\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": task.evaluate(prob_test if prob_test is not None else y_test_pred)\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "dea407ba0ff8f22f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T12:06:28.253399Z",
     "start_time": "2025-08-13T12:06:28.232032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "def engineer_driver_features():\n",
    "    results = tables[\"results\"].merge(\n",
    "        tables[\"races\"][[\"raceId\", \"date\"]],\n",
    "        on=\"raceId\", how=\"left\"\n",
    "    ).dropna(subset=[\"driverId\", \"date\"])\n",
    "\n",
    "    results[\"dnf_flag\"] = (~results[\"positionOrder\"].isna()).astype(int)\n",
    "    feats = results.groupby(\"driverId\").expanding().agg({\n",
    "        \"positionOrder\": \"mean\",\n",
    "        \"points\": \"mean\",\n",
    "        \"dnf_flag\": \"mean\",\n",
    "        \"laps\": \"mean\"\n",
    "    }).reset_index()\n",
    "    feats = feats.rename(columns={\n",
    "        \"positionOrder\": \"avg_position\",\n",
    "        \"points\": \"avg_points\",\n",
    "        \"dnf_flag\": \"dnf_rate\",\n",
    "        \"laps\": \"avg_laps\"\n",
    "    })\n",
    "    feats[\"date\"] = results[\"date\"].values\n",
    "    return feats\n",
    "\n",
    "driver_feats = engineer_driver_features()\n"
   ],
   "id": "15446aa30203650c",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['date']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yl/k2ptpp6s2ms3m1kvq65cr07m0000gn/T/ipykernel_7671/144304565.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     24\u001B[0m     })\n\u001B[1;32m     25\u001B[0m     \u001B[0mfeats\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"date\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"date\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mfeats\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m \u001B[0mdriver_feats\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mengineer_driver_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/yl/k2ptpp6s2ms3m1kvq65cr07m0000gn/T/ipykernel_7671/144304565.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mengineer_driver_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     results = tables[\"results\"].merge(\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0mtables\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"races\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"raceId\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"date\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mon\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"raceId\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"left\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     ).dropna(subset=[\"driverId\", \"date\"])\n",
      "\u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001B[0m\n\u001B[1;32m   6673\u001B[0m             \u001B[0max\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6674\u001B[0m             \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6675\u001B[0m             \u001B[0mcheck\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindices\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6676\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcheck\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6677\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcheck\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6678\u001B[0m             \u001B[0magg_obj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6679\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6680\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mthresh\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_default\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: ['date']"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "def run_merged_table_experiment(task_name: str):\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    X_train, y_train = task.get_X_y(\"train\")\n",
    "    X_val, y_val     = task.get_X_y(\"val\")\n",
    "    X_test, y_test   = task.get_X_y(\"test\")\n",
    "\n",
    "    idx_train = task.get_index(\"train\")  # (entity_id, date)\n",
    "    idx_val   = task.get_index(\"val\")\n",
    "    idx_test  = task.get_index(\"test\")\n",
    "\n",
    "    # Merge features by driverId and date (backward asof join)\n",
    "    def enrich(X, idx):\n",
    "        df = X.copy()\n",
    "        idx_df = pd.DataFrame(idx, columns=[\"driverId\", \"date\"])\n",
    "        idx_df[\"date\"] = pd.to_datetime(idx_df[\"date\"])\n",
    "        merged = pd.merge_asof(\n",
    "            idx_df.sort_values(\"date\"),\n",
    "            driver_feats.sort_values(\"date\"),\n",
    "            on=\"date\", by=\"driverId\",\n",
    "            direction=\"backward\", tolerance=pd.Timedelta(\"36500D\")\n",
    "        )\n",
    "        merged = merged.drop(columns=[\"driverId\", \"date\"])\n",
    "        df = pd.concat([df.reset_index(drop=True), merged.reset_index(drop=True)], axis=1)\n",
    "        return df\n",
    "\n",
    "    X_train_en = enrich(X_train, idx_train)\n",
    "    X_val_en   = enrich(X_val, idx_val)\n",
    "    X_test_en  = enrich(X_test, idx_test)\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train_en, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val_en)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test_en)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val_en)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test_en)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": task.evaluate(prob_val if prob_val is not None else y_val_pred, \"val\")\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": task.evaluate(prob_test if prob_test is not None else y_test_pred)\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "a83a2661d3059bc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "TASKS = [\"driver-dnf\", \"driver-top3\", \"driver-position\"]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"=== {task} | Single Table ===\")\n",
    "    res_single = run_single_table_experiment(task)\n",
    "    for split, metrics in res_single.items():\n",
    "        all_results.append({\"task\": task, \"setting\": \"single\", \"split\": split, **metrics})\n",
    "\n",
    "    print(f\"=== {task} | Merged Table ===\")\n",
    "    res_merged = run_merged_table_experiment(task)\n",
    "    for split, metrics in res_merged.items():\n",
    "        all_results.append({\"task\": task, \"setting\": \"merged\", \"split\": split, **metrics})\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df\n"
   ],
   "id": "deda7044b39dafda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "def plot_metric(metric):\n",
    "    sub = results_df[(results_df[\"split\"] == \"test\") & results_df[metric].notna()]\n",
    "    if sub.empty:\n",
    "        return\n",
    "    pivot = sub.pivot(index=\"task\", columns=\"setting\", values=metric)\n",
    "    pivot.plot(kind=\"bar\", figsize=(8, 4), title=metric)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"roc_auc\", \"f1_macro\", \"mae\", \"mse\", \"fit_time\", \"predict_time\"]:\n",
    "    plot_metric(m)\n"
   ],
   "id": "6013122562f73f86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
