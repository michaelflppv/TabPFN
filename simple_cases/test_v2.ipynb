{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.659069Z",
     "start_time": "2025-08-13T16:40:51.654647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "# RelBench\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "import relbench.metrics\n",
    "import inspect\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# Device preference\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ],
   "id": "57624fe02c838842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.678362Z",
     "start_time": "2025-08-13T16:40:51.676082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse"
   ],
   "id": "46fcd0d47afb30c1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.707729Z",
     "start_time": "2025-08-13T16:40:51.691958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = time.perf_counter()\n",
    "    yield lambda: time.perf_counter() - start\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        out[\"roc_auc\"] = np.nan\n",
    "    return out\n",
    "\n",
    "def regression_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    # Accepts y_prob for compatibility, but ignores it\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "dataset = get_dataset(\"rel-f1\")\n",
    "db = dataset.get_db()\n",
    "\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Load key tables\n",
    "tables = {}\n",
    "for name in db.table_dict:\n",
    "    tables[name] = to_pandas(db.table_dict[name])\n",
    "\n",
    "for t in tables.values():\n",
    "    for col in t.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            t[col] = pd.to_datetime(t[col], errors=\"coerce\")"
   ],
   "id": "4da5c0d65181834d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.723113Z",
     "start_time": "2025-08-13T16:40:51.718672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_single_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    df = train_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_train = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df[task.target_col]\n",
    "\n",
    "    df = val_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_val = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df[task.target_col]\n",
    "\n",
    "    df = test_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_test = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df[task.target_col]\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE, ignore_pretraining_limits=True)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    # Get only the primary metric value (not dict)\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res"
   ],
   "id": "f430cf6e11811564",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.760363Z",
     "start_time": "2025-08-13T16:40:51.733431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def engineer_driver_features():\n",
    "    results = tables[\"results\"].merge(\n",
    "        tables[\"races\"][[\"raceId\", \"date\"]],\n",
    "        on=\"raceId\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"results columns after merge:\", results.columns.tolist())\n",
    "    print(\"Number of rows after merge:\", results.shape[0])\n",
    "    results = results.dropna(subset=[\"driverId\", \"date_y\"])\n",
    "    print(\"Number of rows after dropna:\", results.shape[0])\n",
    "\n",
    "    results[\"dnf_flag\"] = (~results[\"positionOrder\"].isna()).astype(int)\n",
    "    feats = results.groupby(\"driverId\").expanding().agg({\n",
    "        \"positionOrder\": \"mean\",\n",
    "        \"points\": \"mean\",\n",
    "        \"dnf_flag\": \"mean\",\n",
    "        \"laps\": \"mean\"\n",
    "    }).reset_index()\n",
    "    feats = feats.rename(columns={\n",
    "        \"positionOrder\": \"avg_position\",\n",
    "        \"points\": \"avg_points\",\n",
    "        \"dnf_flag\": \"dnf_rate\",\n",
    "        \"laps\": \"avg_laps\"\n",
    "    })\n",
    "    feats[\"date\"] = results[\"date_y\"].values\n",
    "    return feats\n",
    "\n",
    "driver_feats = engineer_driver_features()"
   ],
   "id": "de1f9fe2a4bd02ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results columns after merge: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionOrder', 'points', 'laps', 'milliseconds', 'fastestLap', 'rank', 'statusId', 'date_x', 'date_y']\n",
      "Number of rows after merge: 20323\n",
      "Number of rows after dropna: 20323\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:51.769844Z",
     "start_time": "2025-08-13T16:40:51.764737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_merged_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    df_train = train_table.df\n",
    "    df_train = df_train.sample(n=min(1000, len(df_train)), random_state=42)\n",
    "    idx_train = list(zip(df_train[\"driverId\"], df_train[\"date\"]))\n",
    "    X_train = df_train.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df_train[task.target_col]\n",
    "\n",
    "    df_val = val_table.df\n",
    "    df_val = df_val.sample(n=min(1000, len(df_val)), random_state=42)\n",
    "    idx_val   = list(zip(df_val[\"driverId\"], df_val[\"date\"]))\n",
    "    X_val = df_val.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df_val[task.target_col]\n",
    "\n",
    "    df_test = test_table.df\n",
    "    df_test = df_test.sample(n=min(1000, len(df_test)), random_state=42)\n",
    "    idx_test  = list(zip(df_test[\"driverId\"], df_test[\"date\"]))\n",
    "    X_test = df_test.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df_test[task.target_col]\n",
    "\n",
    "    # Merge features by driverId and date (backward asof join)\n",
    "    def enrich(X, idx):\n",
    "        df = X.copy()\n",
    "        idx_df = pd.DataFrame(idx, columns=[\"driverId\", \"date\"])\n",
    "        idx_df[\"driverId\"] = idx_df[\"driverId\"].astype(\"int64\")\n",
    "        idx_df[\"date\"] = pd.to_datetime(idx_df[\"date\"])\n",
    "        driver_feats_fixed = driver_feats.copy()\n",
    "        driver_feats_fixed[\"driverId\"] = driver_feats_fixed[\"driverId\"].astype(\"int64\")\n",
    "        merged = pd.merge_asof(\n",
    "            idx_df.sort_values(\"date\"),\n",
    "            driver_feats_fixed.sort_values(\"date\"),\n",
    "            on=\"date\", by=\"driverId\",\n",
    "            direction=\"backward\", tolerance=pd.Timedelta(\"3650D\")\n",
    "        )\n",
    "        merged = merged.drop(columns=[\"driverId\", \"date\"])\n",
    "        df = pd.concat([df.reset_index(drop=True), merged.reset_index(drop=True)], axis=1)\n",
    "        return df\n",
    "\n",
    "    X_train_en = enrich(X_train, idx_train)\n",
    "    X_val_en   = enrich(X_val, idx_val)\n",
    "    X_test_en  = enrich(X_test, idx_test)\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train_en, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val_en)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test_en)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val_en)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test_en)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "2213d3092cc43fd0",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:45:45.002386Z",
     "start_time": "2025-08-13T16:40:51.785772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TASKS = [\"driver-position\"]\n",
    "# \"driver-dnf\"\n",
    "# \"driver-top3\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"=== {task} | Single Table ===\")\n",
    "    res_single = run_single_table_experiment(task)\n",
    "    single_results = []\n",
    "    for split, metrics in res_single.items():\n",
    "        result = {\"task\": task, \"setting\": \"single\", \"split\": split, **metrics}\n",
    "        all_results.append(result)\n",
    "        single_results.append(result)\n",
    "    single_df = pd.DataFrame(single_results)\n",
    "    print(\"Table Contents (Single Table):\")\n",
    "    print(single_df)\n",
    "    single_df.to_csv(f\"results_{task}_single.csv\", index=False)\n",
    "\n",
    "    print(f\"=== {task} | Merged Table ===\")\n",
    "    res_merged = run_merged_table_experiment(task)\n",
    "    merged_results = []\n",
    "    for split, metrics in res_merged.items():\n",
    "        result = {\"task\": task, \"setting\": \"merged\", \"split\": split, **metrics}\n",
    "        all_results.append(result)\n",
    "        merged_results.append(result)\n",
    "    merged_df = pd.DataFrame(merged_results)\n",
    "    print(\"Table Contents (Merged Table):\")\n",
    "    print(merged_df)\n",
    "    merged_df.to_csv(f\"results_{task}_merged.csv\", index=False)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"results_summary.csv\", index=False)\n",
    "results_df"
   ],
   "id": "4ebb21a39e26d553",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== driver-position | Single Table ===\n",
      "Table Contents (Single Table):\n",
      "              task setting split       mae        mse  fit_time  predict_time  \\\n",
      "0  driver-position  single   val  4.011105  22.971113   0.11201     63.715133   \n",
      "1  driver-position  single  test  4.161918  25.052051   0.11201     67.299632   \n",
      "\n",
      "   primary_metric_relbench  \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "=== driver-position | Merged Table ===\n",
      "Table Contents (Merged Table):\n",
      "              task setting split       mae        mse  fit_time  predict_time  \\\n",
      "0  driver-position  merged   val  4.043314  23.450175  0.108428     80.156649   \n",
      "1  driver-position  merged  test  4.182119  25.224003  0.108428     81.798125   \n",
      "\n",
      "   primary_metric_relbench  \n",
      "0                      NaN  \n",
      "1                      NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              task setting split       mae        mse  fit_time  predict_time  \\\n",
       "0  driver-position  single   val  4.011105  22.971113  0.112010     63.715133   \n",
       "1  driver-position  single  test  4.161918  25.052051  0.112010     67.299632   \n",
       "2  driver-position  merged   val  4.043314  23.450175  0.108428     80.156649   \n",
       "3  driver-position  merged  test  4.182119  25.224003  0.108428     81.798125   \n",
       "\n",
       "   primary_metric_relbench  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>setting</th>\n",
       "      <th>split</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>primary_metric_relbench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>single</td>\n",
       "      <td>val</td>\n",
       "      <td>4.011105</td>\n",
       "      <td>22.971113</td>\n",
       "      <td>0.112010</td>\n",
       "      <td>63.715133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>single</td>\n",
       "      <td>test</td>\n",
       "      <td>4.161918</td>\n",
       "      <td>25.052051</td>\n",
       "      <td>0.112010</td>\n",
       "      <td>67.299632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>merged</td>\n",
       "      <td>val</td>\n",
       "      <td>4.043314</td>\n",
       "      <td>23.450175</td>\n",
       "      <td>0.108428</td>\n",
       "      <td>80.156649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>merged</td>\n",
       "      <td>test</td>\n",
       "      <td>4.182119</td>\n",
       "      <td>25.224003</td>\n",
       "      <td>0.108428</td>\n",
       "      <td>81.798125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:45:45.064810Z",
     "start_time": "2025-08-13T16:45:45.032265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_metric(metric):\n",
    "    sub = results_df[(results_df[\"split\"] == \"test\") & results_df[metric].notna()]\n",
    "    if sub.empty:\n",
    "        return\n",
    "    pivot = sub.pivot(index=\"task\", columns=\"setting\", values=metric)\n",
    "    pivot.plot(kind=\"bar\", figsize=(8, 4), title=metric)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"roc_auc\", \"f1_macro\", \"mae\", \"fit_time\", \"predict_time\"]:\n",
    "    plot_metric(m)"
   ],
   "id": "8e2bb976df5d5820",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'roc_auc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3811\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'roc_auc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1_macro\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_time\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict_time\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m---> 11\u001B[0m     \u001B[43mplot_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m, in \u001B[0;36mplot_metric\u001B[0;34m(metric)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mplot_metric\u001B[39m(metric):\n\u001B[0;32m----> 2\u001B[0m     sub \u001B[38;5;241m=\u001B[39m results_df[(results_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m&\u001B[39m \u001B[43mresults_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mnotna()]\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sub\u001B[38;5;241m.\u001B[39mempty:\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4107\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4109\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3815\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3816\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3817\u001B[0m     ):\n\u001B[1;32m   3818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3819\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3821\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3822\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3823\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'roc_auc'"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
