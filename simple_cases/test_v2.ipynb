{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.164359Z",
     "start_time": "2025-08-13T16:29:25.158628Z"
    }
   },
   "source": [
    "# %%\n",
    "import os\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "# RelBench\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# Device preference\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Patch relbench.metrics.rmse to avoid 'squared' argument error\n",
    "import relbench.metrics\n",
    "import inspect\n",
    "\n",
    "# Patch relbench.metrics.skm.mean_squared_error to local mean_squared_error\n",
    "relbench.metrics.skm.mean_squared_error = mean_squared_error\n",
    "\n",
    "def patched_rmse(true, pred):\n",
    "    if \"squared\" in inspect.signature(mean_squared_error).parameters:\n",
    "        return mean_squared_error(true, pred, squared=False)\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "relbench.metrics.rmse = patched_rmse\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.181463Z",
     "start_time": "2025-08-13T16:29:25.178510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = time.perf_counter()\n",
    "    yield lambda: time.perf_counter() - start\n",
    "\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        out[\"roc_auc\"] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def regression_metrics(y_true, y_pred, y_prob=None) -> Dict[str, float]:\n",
    "    # Accepts y_prob for compatibility, but ignores it\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "    }\n"
   ],
   "id": "4f09b9768ee9fdcb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.208062Z",
     "start_time": "2025-08-13T16:29:25.192540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "dataset = get_dataset(\"rel-f1\")\n",
    "db = dataset.get_db()\n",
    "\n",
    "def to_pandas(table):\n",
    "    if hasattr(table, \"to_pandas\"):\n",
    "        return table.to_pandas()\n",
    "    if hasattr(table, \"df\"):\n",
    "        return table.df\n",
    "    raise ValueError(\"Unknown table type\")\n",
    "\n",
    "# Load key tables\n",
    "tables = {}\n",
    "for name in db.table_dict:\n",
    "    tables[name] = to_pandas(db.table_dict[name])\n",
    "\n",
    "for t in tables.values():\n",
    "    for col in t.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            t[col] = pd.to_datetime(t[col], errors=\"coerce\")\n"
   ],
   "id": "830e3b724db7392",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.221707Z",
     "start_time": "2025-08-13T16:29:25.217316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_single_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    df = train_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_train = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df[task.target_col]\n",
    "\n",
    "    df = val_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_val = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df[task.target_col]\n",
    "\n",
    "    df = test_table.df\n",
    "    df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "    X_test = df.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df[task.target_col]\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE, ignore_pretraining_limits=True)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    # Get only the primary metric value (not dict)\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res"
   ],
   "id": "dea407ba0ff8f22f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.257627Z",
     "start_time": "2025-08-13T16:29:25.230390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Python\n",
    "def engineer_driver_features():\n",
    "    results = tables[\"results\"].merge(\n",
    "        tables[\"races\"][[\"raceId\", \"date\"]],\n",
    "        on=\"raceId\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"results columns after merge:\", results.columns.tolist())\n",
    "    print(\"Number of rows after merge:\", results.shape[0])\n",
    "    results = results.dropna(subset=[\"driverId\", \"date_y\"])\n",
    "    print(\"Number of rows after dropna:\", results.shape[0])\n",
    "\n",
    "    results[\"dnf_flag\"] = (~results[\"positionOrder\"].isna()).astype(int)\n",
    "    feats = results.groupby(\"driverId\").expanding().agg({\n",
    "        \"positionOrder\": \"mean\",\n",
    "        \"points\": \"mean\",\n",
    "        \"dnf_flag\": \"mean\",\n",
    "        \"laps\": \"mean\"\n",
    "    }).reset_index()\n",
    "    feats = feats.rename(columns={\n",
    "        \"positionOrder\": \"avg_position\",\n",
    "        \"points\": \"avg_points\",\n",
    "        \"dnf_flag\": \"dnf_rate\",\n",
    "        \"laps\": \"avg_laps\"\n",
    "    })\n",
    "    feats[\"date\"] = results[\"date_y\"].values\n",
    "    return feats\n",
    "\n",
    "driver_feats = engineer_driver_features()\n"
   ],
   "id": "15446aa30203650c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results columns after merge: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionOrder', 'points', 'laps', 'milliseconds', 'fastestLap', 'rank', 'statusId', 'date_x', 'date_y']\n",
      "Number of rows after merge: 20323\n",
      "Number of rows after dropna: 20323\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.267334Z",
     "start_time": "2025-08-13T16:29:25.262108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "def run_merged_table_experiment(task_name: str):\n",
    "    global prob_val, prob_test\n",
    "    task = get_task(\"rel-f1\", task_name)\n",
    "\n",
    "    train_table = task.get_table(\"train\")\n",
    "    val_table = task.get_table(\"val\")\n",
    "    test_table = task.get_table(\"test\", mask_input_cols=False)\n",
    "\n",
    "    df_train = train_table.df\n",
    "    df_train = df_train.sample(n=min(1000, len(df_train)), random_state=42)\n",
    "    idx_train = list(zip(df_train[\"driverId\"], df_train[\"date\"]))\n",
    "    X_train = df_train.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_train = df_train[task.target_col]\n",
    "\n",
    "    df_val = val_table.df\n",
    "    df_val = df_val.sample(n=min(1000, len(df_val)), random_state=42)\n",
    "    idx_val   = list(zip(df_val[\"driverId\"], df_val[\"date\"]))\n",
    "    X_val = df_val.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_val = df_val[task.target_col]\n",
    "\n",
    "    df_test = test_table.df\n",
    "    df_test = df_test.sample(n=min(1000, len(df_test)), random_state=42)\n",
    "    idx_test  = list(zip(df_test[\"driverId\"], df_test[\"date\"]))\n",
    "    X_test = df_test.drop(columns=[task.target_col]).select_dtypes(include=[np.number])\n",
    "    y_test = df_test[task.target_col]\n",
    "\n",
    "    # Merge features by driverId and date (backward asof join)\n",
    "    def enrich(X, idx):\n",
    "        df = X.copy()\n",
    "        idx_df = pd.DataFrame(idx, columns=[\"driverId\", \"date\"])\n",
    "        idx_df[\"driverId\"] = idx_df[\"driverId\"].astype(\"int64\")\n",
    "        idx_df[\"date\"] = pd.to_datetime(idx_df[\"date\"])\n",
    "        driver_feats_fixed = driver_feats.copy()\n",
    "        driver_feats_fixed[\"driverId\"] = driver_feats_fixed[\"driverId\"].astype(\"int64\")\n",
    "        merged = pd.merge_asof(\n",
    "            idx_df.sort_values(\"date\"),\n",
    "            driver_feats_fixed.sort_values(\"date\"),\n",
    "            on=\"date\", by=\"driverId\",\n",
    "            direction=\"backward\", tolerance=pd.Timedelta(\"3650D\")\n",
    "        )\n",
    "        merged = merged.drop(columns=[\"driverId\", \"date\"])\n",
    "        df = pd.concat([df.reset_index(drop=True), merged.reset_index(drop=True)], axis=1)\n",
    "        return df\n",
    "\n",
    "    X_train_en = enrich(X_train, idx_train)\n",
    "    X_val_en   = enrich(X_val, idx_val)\n",
    "    X_test_en  = enrich(X_test, idx_test)\n",
    "\n",
    "    if task_name == \"driver-position\":\n",
    "        model = TabPFNRegressor(device=DEVICE)\n",
    "        metric_fn = regression_metrics\n",
    "        prob_val = prob_test = None\n",
    "    else:\n",
    "        model = TabPFNClassifier(device=DEVICE)\n",
    "        metric_fn = classification_metrics\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        model.fit(X_train_en, y_train)\n",
    "    fit_time = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_val_pred = model.predict(X_val_en)\n",
    "    pred_time_val = t()\n",
    "\n",
    "    with elapsed_timer() as t:\n",
    "        y_test_pred = model.predict(X_test_en)\n",
    "    pred_time_test = t()\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        try:\n",
    "            prob_val  = model.predict_proba(X_val_en)[:, 1]\n",
    "            prob_test = model.predict_proba(X_test_en)[:, 1]\n",
    "        except Exception:\n",
    "            prob_val = prob_test = None\n",
    "\n",
    "    if task_name != \"driver-position\":\n",
    "        primary_metric_val = list(task.evaluate(\n",
    "            prob_val if prob_val is not None else y_val_pred,\n",
    "            target_table=task.get_table(\"val\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "        primary_metric_test = list(task.evaluate(\n",
    "            prob_test if prob_test is not None else y_test_pred,\n",
    "            target_table=task.get_table(\"test\", mask_input_cols=False)\n",
    "        ).values())[0]\n",
    "    else:\n",
    "        primary_metric_val = np.nan\n",
    "        primary_metric_test = np.nan\n",
    "\n",
    "    res = {\n",
    "        \"val\": {\n",
    "            **metric_fn(y_val, y_val_pred, prob_val),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_val,\n",
    "            \"primary_metric_relbench\": primary_metric_val,\n",
    "        },\n",
    "        \"test\": {\n",
    "            **metric_fn(y_test, y_test_pred, prob_test),\n",
    "            \"fit_time\": fit_time,\n",
    "            \"predict_time\": pred_time_test,\n",
    "            \"primary_metric_relbench\": primary_metric_test,\n",
    "        }\n",
    "    }\n",
    "    return res\n"
   ],
   "id": "a83a2661d3059bc3",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:29:25.280707Z",
     "start_time": "2025-08-13T16:29:25.279560Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "de82238dba8c2502",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:34:16.892404Z",
     "start_time": "2025-08-13T16:29:25.289380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "TASKS = [\"driver-position\"]\n",
    "# \"driver-dnf\"\n",
    "# \"driver-top3\"\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"=== {task} | Single Table ===\")\n",
    "    res_single = run_single_table_experiment(task)\n",
    "    single_results = []\n",
    "    for split, metrics in res_single.items():\n",
    "        result = {\"task\": task, \"setting\": \"single\", \"split\": split, **metrics}\n",
    "        all_results.append(result)\n",
    "        single_results.append(result)\n",
    "    single_df = pd.DataFrame(single_results)\n",
    "    print(\"Table Contents (Single Table):\")\n",
    "    print(single_df)\n",
    "    single_df.to_csv(f\"results_{task}_single.csv\", index=False)\n",
    "\n",
    "    print(f\"=== {task} | Merged Table ===\")\n",
    "    res_merged = run_merged_table_experiment(task)\n",
    "    merged_results = []\n",
    "    for split, metrics in res_merged.items():\n",
    "        result = {\"task\": task, \"setting\": \"merged\", \"split\": split, **metrics}\n",
    "        all_results.append(result)\n",
    "        merged_results.append(result)\n",
    "    merged_df = pd.DataFrame(merged_results)\n",
    "    print(\"Table Contents (Merged Table):\")\n",
    "    print(merged_df)\n",
    "    merged_df.to_csv(f\"results_{task}_merged.csv\", index=False)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"results_summary.csv\", index=False)\n",
    "results_df\n"
   ],
   "id": "deda7044b39dafda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== driver-position | Single Table ===\n",
      "Table Contents (Single Table):\n",
      "              task setting split       mae        mse  fit_time  predict_time  \\\n",
      "0  driver-position  single   val  4.011105  22.971113  0.108722     63.227628   \n",
      "1  driver-position  single  test  4.161918  25.052051  0.108722     66.124904   \n",
      "\n",
      "   primary_metric_relbench  \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "=== driver-position | Merged Table ===\n",
      "Table Contents (Merged Table):\n",
      "              task setting split       mae        mse  fit_time  predict_time  \\\n",
      "0  driver-position  merged   val  4.043314  23.450175  0.104249     80.033619   \n",
      "1  driver-position  merged  test  4.182119  25.224003  0.104249     81.974540   \n",
      "\n",
      "   primary_metric_relbench  \n",
      "0                      NaN  \n",
      "1                      NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              task setting split       mae        mse  fit_time  predict_time  \\\n",
       "0  driver-position  single   val  4.011105  22.971113  0.108722     63.227628   \n",
       "1  driver-position  single  test  4.161918  25.052051  0.108722     66.124904   \n",
       "2  driver-position  merged   val  4.043314  23.450175  0.104249     80.033619   \n",
       "3  driver-position  merged  test  4.182119  25.224003  0.104249     81.974540   \n",
       "\n",
       "   primary_metric_relbench  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>setting</th>\n",
       "      <th>split</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>primary_metric_relbench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>single</td>\n",
       "      <td>val</td>\n",
       "      <td>4.011105</td>\n",
       "      <td>22.971113</td>\n",
       "      <td>0.108722</td>\n",
       "      <td>63.227628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>single</td>\n",
       "      <td>test</td>\n",
       "      <td>4.161918</td>\n",
       "      <td>25.052051</td>\n",
       "      <td>0.108722</td>\n",
       "      <td>66.124904</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>merged</td>\n",
       "      <td>val</td>\n",
       "      <td>4.043314</td>\n",
       "      <td>23.450175</td>\n",
       "      <td>0.104249</td>\n",
       "      <td>80.033619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>driver-position</td>\n",
       "      <td>merged</td>\n",
       "      <td>test</td>\n",
       "      <td>4.182119</td>\n",
       "      <td>25.224003</td>\n",
       "      <td>0.104249</td>\n",
       "      <td>81.974540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:34:17.544338Z",
     "start_time": "2025-08-13T16:34:16.910913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "def plot_metric(metric):\n",
    "    sub = results_df[(results_df[\"split\"] == \"test\") & results_df[metric].notna()]\n",
    "    if sub.empty:\n",
    "        return\n",
    "    pivot = sub.pivot(index=\"task\", columns=\"setting\", values=metric)\n",
    "    pivot.plot(kind=\"bar\", figsize=(8, 4), title=metric)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"roc_auc\", \"f1_macro\", \"mae\", \"fit_time\", \"predict_time\"]:\n",
    "    plot_metric(m)\n"
   ],
   "id": "6013122562f73f86",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'roc_auc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3811\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'roc_auc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1_macro\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_time\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict_time\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m---> 12\u001B[0m     \u001B[43mplot_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m, in \u001B[0;36mplot_metric\u001B[0;34m(metric)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mplot_metric\u001B[39m(metric):\n\u001B[0;32m----> 3\u001B[0m     sub \u001B[38;5;241m=\u001B[39m results_df[(results_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m&\u001B[39m \u001B[43mresults_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mnotna()]\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sub\u001B[38;5;241m.\u001B[39mempty:\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4107\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4109\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TabPFN/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3815\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3816\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3817\u001B[0m     ):\n\u001B[1;32m   3818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3819\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3821\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3822\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3823\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'roc_auc'"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
